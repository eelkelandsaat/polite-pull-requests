repo_api_url,pull_number,regression_score,class_label,message
https://api.github.com/repos/appium/python-client,831,-0.24571342766284943,0,"`set_text` and `set_value` would not work, without these changes, on the latest beta56 of Appium. These are the values that Appium corrected me with, that I have replaced in the code. Is there any place where one would validate the parameters that should be sent? Either some documentation, or a reference library? EDIT: is this the reference to use? https://w3c.github.io/webdriver/#element-send-keys"
https://api.github.com/repos/appium/python-client,820,-0.008233380503952503,0,"I'll eventually add this endpoint in the selenium project, but let me add this endpoint in the Appium client so far. https://w3c.github.io/webdriver/#dfn-statusv"
https://api.github.com/repos/appium/python-client,797,-0.05733856186270714,0,"add detailed information to long_press duration param"
https://api.github.com/repos/appium/python-client,787,-0.25871190428733826,0,"https://github.com/pre-commit/mirrors-isort is archived. The readme mentioned to use https://github.com/PyCQA/isort directly. ``` [INFO] Initializing environment for https://github.com/PyCQA/isort. [INFO] Initializing environment for https://github.com/pre-commit/mirrors-mypy. [INFO] Initializing environment for https://github.com/psf/black. [INFO] Installing environment for https://github.com/PyCQA/isort. [INFO] Once installed this environment will be reused. [INFO] This may take a few minutes... [INFO] Installing environment for https://github.com/pre-commit/mirrors-mypy. [INFO] Once installed this environment will be reused. [INFO] This may take a few minutes... [INFO] Installing environment for https://github.com/psf/black. [INFO] Once installed this environment will be reused. [INFO] This may take a few minutes... isort................................................(no files to check)Skipped mypy.................................................(no files to check)Skipped black................................................(no files to check)Skipped ```"
https://api.github.com/repos/appium/python-client,786,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,773,0.2987532913684845,0,"Moving unit tests to GH Actions. I'll do Win one as another PR."
https://api.github.com/repos/appium/python-client,772,-0.44711852073669434,0,"Related to https://github.com/appium/python-client/issues/771"
https://api.github.com/repos/appium/python-client,768,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,767,0.36341118812561035,0,"It turns out timedelta class normalises its seconds, microseconds and days properties as mentioned in https://docs.python.org/3/library/datetime.html#datetime.timedelta Thus we need to use the total_seconds() property in order to avoid unexpected normalization side effects in case longer deltas are provided"
https://api.github.com/repos/appium/python-client,764,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,759,-0.2335733026266098,0,"For https://github.com/appium/python-client/pull/756 to fix the lint"
https://api.github.com/repos/appium/python-client,751,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,750,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,744,0.21526703238487244,0,"- Fixed handling the duration argument in swipe() and scroll() helpers - Functionality is now the same as in older versions using TouchActions Fixes #743"
https://api.github.com/repos/appium/python-client,740,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,739,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,738,0.057488854974508286,0,"Selenium lib did remove find_by methods in its 4.3 release"
https://api.github.com/repos/appium/python-client,737,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,735,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,734,0.3723609447479248,0,"just to reduce the amount of classes"
https://api.github.com/repos/appium/python-client,732,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,731,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,730,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,728,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,727,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,724,0.5265553593635559,1,"Hi! I faced with an issue while using `appium.find_element` with locators, that I used for my selenium tests. Is it possible to uncomment [that block](https://github.com/appium/python-client/pull/724/files#diff-646299ef4dd5d3b0e5d58632c99871ba450a1481e017654f4e95b11a2847c945R340) and use him in `web view` context only ? "
https://api.github.com/repos/appium/python-client,723,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,722,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,721,-1.203924536705017,-1,"None"
https://api.github.com/repos/appium/python-client,720,0.5384132862091064,1,"This is just POC to demonstrate my vision for W3C Options support in Python client.  If we accept it then it would be necessary to add all the supported capabilities like we did in Java, although this could be done gradually in multiple PRs."
https://api.github.com/repos/appium/python-client,719,0.050918858498334885,0,"It looks like pylint cannot properly parse the module source and thus throws many false positives"
https://api.github.com/repos/stanfordnlp/stanza,1190,0.407126247882843,0,"A version of the classifier that uses the constituency parser to build its embeddings"
https://api.github.com/repos/stanfordnlp/stanza,1186,0.38725587725639343,0,"Includes basic test file using a supplementary folder (stored in a zip) for AWS labeling tracker "
https://api.github.com/repos/stanfordnlp/stanza,1185,-0.4365435838699341,0," ## Description Add language Code for extremaduran language https://iso639-3.sil.org/code/ext "
https://api.github.com/repos/stanfordnlp/stanza,1178,0.0923866555094719,0,"When a comment is added to a sentence with a constituency tree, parse that comment into the tree object This involves refactoring the StanzaObject, since it is used in both doc and parse_tree "
https://api.github.com/repos/stanfordnlp/stanza,1177,0.07776988297700882,0,"Add comments to the serialized format when saving a document.  This will keep any user added comments, but at the cost of making the files larger because they now have the text in a couple different places. "
https://api.github.com/repos/stanfordnlp/stanza,1175,0.07184050232172012,0,"Add a pipeline depparse variant which talks to the CoreNLP constituency converter"
https://api.github.com/repos/stanfordnlp/stanza,1171,-0.0875730961561203,0,"Add a constituency comment to sentences in the doc (this makes the constituency tree output in the CoNLL format) "
https://api.github.com/repos/stanfordnlp/stanza,1170,0.19872573018074036,0," ## Description `prepare_depparse_treebank` does not use the pretrained file passed via `wordvec_pretrain_file` option. `wordvec_args` expects the list of options as the last argument, but `args` is a namespace object. Now if `wordvec_pretrain_file` is set we add it to the `base_args`, otherwise invoke `wordvec_args` function "
https://api.github.com/repos/stanfordnlp/stanza,1169,-0.1587129533290863,0,"Add a `""{:C}""` format to `Document` and `Sentence` by rearranging some of the code from `conll`"
https://api.github.com/repos/stanfordnlp/stanza,1165,0.4215349853038788,0,"Add a script to process a collection of English newswire from non-US sources into a 4 class dataset similar to the conll dataset.  Will allow for testing & retraining of those models using the new data."
https://api.github.com/repos/stanfordnlp/stanza,1164,0.15246917307376862,0,"Add charlm as an option to depparse, especially the en_combined model"
https://api.github.com/repos/stanfordnlp/stanza,1162,-0.31761041283607483,0," Avoid excessive copying of the full-text on each paragraph check. `stanza.utils.datasets.prepare_tokenizer_treebank` took around 2 hours on my custom treebank (~60 MiB .txt file).  After this fix it finished in 2 minutes.   Results for other large UD treebanks: |                      | before | after | |----------------------|--------|---------| | UD_Russian-SynTagRus | 46s    | 23s     | | UD_German-HDT        | 6m 12s | 50s     | "
https://api.github.com/repos/stanfordnlp/stanza,1161,0.022074561566114426,0,"## Description When using `stanza.utils.datasets.prepare_tokenizer_treebank` on custom treebank, I stumbled on an error ``` Traceback (most recent call last):   File ""/nix/store/9srs642k875z3qdk8glapjycncf2pa51-python3-3.10.7/lib/python3.10/runpy.py"", line 196, in _run_module_as_main     return _run_code(code, main_globals, None,   File ""/nix/store/9srs642k875z3qdk8glapjycncf2pa51-python3-3.10.7/lib/python3.10/runpy.py"", line 86, in _run_code     exec(code, run_globals)   File ""/home/dvzubarev/installed_thirdparty/stanza/stanza/utils/datasets/prepare_tokenizer_treebank.py"", line 1140, in <module>     main()   File ""/home/dvzubarev/installed_thirdparty/stanza/stanza/utils/datasets/prepare_tokenizer_treebank.py"", line 1137, in main     common.main(process_treebank, add_specific_args)   File ""/home/dvzubarev/installed_thirdparty/stanza/stanza/utils/datasets/common.py"", line 257, in main     process_treebank(treebank, paths, args)   File ""/home/dvzubarev/installed_thirdparty/stanza/stanza/utils/datasets/prepare_tokenizer_treebank.py"", line 1127, in process_treebank     process_ud_treebank(treebank, udbase_dir, tokenizer_dir, short_name, short_language, args.augment)   File ""/home/dvzubarev/installed_thirdparty/stanza/stanza/utils/datasets/prepare_tokenizer_treebank.py"", line 1023, in process_ud_treebank     prepare_ud_dataset(treebank, udbase_dir, tokenizer_dir, short_name, short_language, ""train"", augment)   File ""/home/dvzubarev/installed_thirdparty/stanza/stanza/utils/datasets/prepare_tokenizer_treebank.py"", line 1012, in prepare_ud_dataset     write_augmented_dataset(input_conllu, output_conllu, augment_punct)   File ""/home/dvzubarev/installed_thirdparty/stanza/stanza/utils/datasets/prepare_tokenizer_treebank.py"", line 674, in write_augmented_dataset     new_sents = augment_function(sents)   File ""/home/dvzubarev/installed_thirdparty/stanza/stanza/utils/datasets/prepare_tokenizer_treebank.py"", line 657, in augment_punct     new_sents = augment_comma_separations(new_sents)   File ""/home/dvzubarev/installed_thirdparty/stanza/stanza/utils/datasets/prepare_tokenizer_treebank.py"", line 293, in augment_comma_separations     if sentence[idx+1].split(""\t"")[1] != ',': IndexError: list index out of range ```  ## Fixes Issues This PR fixes this issue ## Unit test coverage I added a test for the sentence that caused this issue. "
https://api.github.com/repos/stanfordnlp/stanza,1159,0.23417291045188904,0,"All models now work via the pipeline.  Need to double check that they work everywhere Temporary fix for constituency unit tests?  Need to come up with a good default for no device in args.  Need to double check other situations where device is passed in "
https://api.github.com/repos/stanfordnlp/stanza,1152,0.20784692466259003,0,"The numbers for the optimizers will come out later."
https://api.github.com/repos/stanfordnlp/stanza,1150,0.5560035705566406,1,"Add a few various options for customizing the tagger optimizer.  Doesn't seem to move the needle much, if at all, though"
https://api.github.com/repos/stanfordnlp/stanza,1149,0.08267851173877716,0,"Here is a list of the additional nonlinearities that are present for our experiments:  1. ELU  2. Hardshrink 3. Hardsigmoid 4. Hardtanh 5. Hardswish 6. LogSigmoid 7. PReLU 8. ReLU6 9. RReLU 10. SELU 11. CELU 12. SiLU 13. Softplus 14. Softshrink 15. Softsign 16. Tanhshrink 17. GLU"
https://api.github.com/repos/stanfordnlp/stanza,1148,0.32837429642677307,0,"Allow constituency training from a silver dataset Probably should train some fraction of the words as delta words"
https://api.github.com/repos/stanfordnlp/stanza,1144,0.11460477858781815,0,"A module to connect to the CoreNLP version of the lemmatizer"
https://api.github.com/repos/stanfordnlp/stanza,1140,0.47513478994369507,0,"## Description Added a check to find & replace excessively-long tokens with ""UNK"", in order to avoid downstream GPU memory in `POS`. See issue #1137  ## Approach To avoid having to modify positions of downstream tokens and such, the easiest approach that came to mind was to check for long whitespace-bound tokens and remove them prior to running the tokenizer. this approach replaces the excessively long tokens with the string literal ""unk"", which may not be desired. i  ## Questions Some things that I wasn't sure about, and thought I would mention here: 1. should anything be done to handle the pre-tokenized case? the same token length issue could arise,    but it's less clear to me whether we should be modifying tokens that the user has already    manually created. (long term, this could also be an argument for addressing the issue at the    pos level, although this is probably good enough for now..) 2. since the max length check is being handled in `tokenize_processor.py`, would it make sense to    remove that logic from `output_predictions`? 3. in `stanza.models.tokenization.utils.output_predictions`, the max_seqlen is set to `max(1000,    max_seqlen)`, which would ignore a users specified value if it's less than 1000.. is this    necessary? and if so, would it make sense to at least emit a warning when the user's setting is    overriden? another potential long-term approach you could consider would be to add another processer that gets run before others (~""preprocessor""?..), where logic along these lines could be included and tuned by the user. ## Fixes Issues - #1137  ## Unit test coverage Yes. Just a simple test with a string with length >> `TokenizeProcessor.MAX_SEQ_LENGTH_DEFAULT` ## Known breaking changes/behaviors I hope not! "
https://api.github.com/repos/stanfordnlp/stanza,1139,0.6167401075363159,1,"Some more classifier tests, along with small upgrades for readability"
https://api.github.com/repos/stanfordnlp/stanza,1138,0.13501279056072235,0,"Remove some cuda() calls in favor of getting the device instead.  Will make it easier to use metal "
https://api.github.com/repos/stanfordnlp/stanza,1136,0.29751092195510864,0,"Minor change to the pipeline to accommodate the usage of TokenizeProcessor, then add a script to process raw text files with an arbitrary tokenizer model"
https://api.github.com/repos/stanfordnlp/stanza,1135,-0.09344549477100372,0,"Address one of the oldest remaining issues by adding a utility function to resplit tokens"
https://api.github.com/repos/stanfordnlp/stanza,1133,0.07789864391088486,0,"Make the number of hidden layers an option and start from zeros Generalize the num_layers for Phobert and XLNet.  Keep old models alive "
https://api.github.com/repos/stanfordnlp/stanza,1132,0.27746257185935974,0,"Add a transformer as an optional input to the POS model.  Would need to handle long sentences before making this the default. Add a couple options to the constituency parser to allow for using a better POS model than the default."
https://api.github.com/repos/stanfordnlp/stanza,1130,0.14400659501552582,0,"Turn the LSTM stack into an attention stack"
https://api.github.com/repos/stanfordnlp/stanza,1128,0.2504923641681671,0,"use an LSTM over the max of tree inputs to build the next tree.  Some experiments show an improvement, others are neutral"
https://api.github.com/repos/stanfordnlp/stanza,1127,0.502424955368042,1,"Refactor the LSTM for transitions and constituents into a separate class.  The intention is to make it easier to build a Transformer Stack and then replace the existing LSTMs with one, as long as we make the Transformer use the same interface."
https://api.github.com/repos/stanfordnlp/stanza,1125,-0.42188799381256104,0,"The release that burns twice as bright burns half as long, and you have burned so very very brightly, 1.4.1"
https://api.github.com/repos/stanfordnlp/stanza,1124,0.2033737152814865,0,"## Description Breaks up all dependency groups onto separate lines. Adds a `transformers` extra with a sanity bottom pin ## Fixes Issues - addresses parts of #1120 ## Unit test coverage - n/a ## Known breaking changes/behaviors - n/a"
https://api.github.com/repos/stanfordnlp/stanza,1122,0.04959736764431,0,"Address issues in #1120, specifically `pytest` and having upgraded `transformers`"
https://api.github.com/repos/stanfordnlp/stanza,1119,0.11174831539392471,0,"Bugfixes, constituency parser improvements, more NER models, a couple more Sentiment models"
https://api.github.com/repos/stanfordnlp/stanza,1117,0.05421680584549904,0,"Process tokenizer files for Sindhi provided by Isra University"
https://api.github.com/repos/stanfordnlp/stanza,1113,0.00317168515175581,0,"Add a unit test.  Remove click as a dependency & make lxml optional."
https://api.github.com/repos/stanfordnlp/stanza,1111,0.38218817114830017,0,"Add support for elmoformanylangs to sentiment Inclues a matrix trained to connect the 3 layers of elmo instead of using the default averaging Also, a projection from elmo dim to a lower dimension (although this was less useful) Add a comment on how the sentiment processor doesn't load Elmo "
https://api.github.com/repos/stanfordnlp/stanza,1110,-0.2975863516330719,0,"Co-authored-by: ryszardtuora <ryszardtuora@gmail.com> Co-authored-by: Karol Saputa <32554739+k-sap@users.noreply.github.com> ## Description This PR adds Polish NER dataset, I also link a trained model. ## Fixes Issues I mentioned Polish NER in #1070. ## Model BERT-based model is [here](http://mozart.ipipan.waw.pl/~ksaputa/stanza/pl_ner/ner/polish_ner_bert.tar.gz) "
https://api.github.com/repos/stanfordnlp/stanza,1108,0.6783916354179382,1,"A few minor improvements to the NER output, including sorting confusion matrices by type first, and outputting the results to a file if requested"
https://api.github.com/repos/stanfordnlp/stanza,1104,0.007903325371444225,0,"process TASS2020"
https://api.github.com/repos/stanfordnlp/stanza,1100,0.11320322006940842,0,"Add a preparation script for Masakhane"
https://api.github.com/repos/stanfordnlp/stanza,1099,0.32478973269462585,0,"A couple modifications to pattn & lattn - add a projection matrix to make the lattn fit in memory when using all inputs.  move the layer norm from the inputs from the timing to the transformer.  adjust the timing layers to use the exact size rather than size/2"
https://api.github.com/repos/stanfordnlp/stanza,1098,0.1553879678249359,0,"Add a unit test and implement (some of?) the ideas in  ```Text Classification Improved by Integrating Bidirectional LSTM with Two-dimensional Max Pooling``` "
https://api.github.com/repos/stanfordnlp/stanza,1093,-1.2039239406585693,-1,"None"
https://api.github.com/repos/stanfordnlp/stanza,1092,0.02746792510151863,0,"wandb config logging & logging learning rate for charlm"
https://api.github.com/repos/stanfordnlp/stanza,1091,0.24726630747318268,0,"KK NER dataset"
https://api.github.com/repos/stanfordnlp/stanza,1090,0.3453386723995209,0,"Add a trainer for the charlm - useful for saving and loading everything for checkpoints Save checkpoint files as part of the eval iterations.  Load checkpoints back in when starting Includes option to ignore checkpointing "
https://api.github.com/repos/stanfordnlp/stanza,1086,0.10318286716938019,0,"Load the pretrained charlm, adds it as inputs to the POS model This improves accuracy on almost all POS models Doing the same thing for depparse would also make sense, but is currently not done.  However, the downstream scores of depparse don't seem to be negatively affected by using the different (better) POS tags produced by models using the pretrained charlm Add a pos-specific charlm map for the medical EN datasets and the one dataset which appears to be hurt by the charlm (tr_boun) craft, genia -> None Produces resources.json with pos charlms Make the Pipeline pass in charlm paths if present in resources.json TODO: use the foundation_cache to load them "
https://api.github.com/repos/stanfordnlp/stanza,1085,0.48260918259620667,0,"Add feature to read .csv files when reading a pretrain"
https://api.github.com/repos/stanfordnlp/stanza,1083,-0.5426644086837769,-1,"Replaces the original PR with a version where all the commits are squashed into one"
https://api.github.com/repos/stanfordnlp/stanza,1082,0.3328975439071655,0,"Rewrite `xpos_vocab_factory` so that it looks at the raw data if the dataset isn't already known. Open question: better to check a dataset against the known version of that dataset's xpos?  Might save some headache in the future"
https://api.github.com/repos/stanfordnlp/stanza,1081,-0.10770139843225479,0,"There is a small typo in stanza/utils/datasets/ner/convert_bsf_to_beios.py. Should read `containing` rather than `cotaining`. Semi-automated pull request generated by https://github.com/timgates42/meticulous/blob/master/docs/NOTE.md"
https://api.github.com/repos/stanfordnlp/stanza,1080,0.3985550105571747,0,"Document visualization with Spacy.  Processes completed docs or raw strings Includes right-to-left support (in the NER viz in particular, tags are flipped, for example) Added more documentation for usage, including necessary spaCy installations Includes Jupyter examples for visualization; spacy.render() functions well here Adding new Jupyter examples with support for new functions to visualize several strings with the same language pipeline "
https://api.github.com/repos/stanfordnlp/stanza,1078,0.2375384122133255,0,"… the combined / test datasets automatically **BEFORE YOU START**: please make sure your pull request is against the `dev` branch.  We cannot accept pull requests against the `main` branch.  See our [contributing guide](https://github.com/stanfordnlp/stanza/blob/main/CONTRIBUTING.md) for details. ## Description A brief and concise description of what your pull request is trying to accomplish. ## Fixes Issues A list of issues/bugs with # references. (e.g., #123) ## Unit test coverage Are there unit tests in place to make sure your code is functioning correctly? (see [here](https://github.com/stanfordnlp/stanza/blob/master/tests/test_tagger.py) for a simple example) ## Known breaking changes/behaviors Does this break anything in Stanza's existing user interface? If so, what is it and how is it addressed? "
https://api.github.com/repos/stanfordnlp/stanza,1077,0.12215055525302887,0,"…l languages can be chosen if all legal languages were negative Addresses #1076 "
https://api.github.com/repos/stanfordnlp/stanza,1074,0.03250882402062416,0,"Read in a pretrain even if it doesn't have a row/col header.  This applies to a lot of glove produced vectors, for example Adds a test of the no-header pretrain "
https://api.github.com/repos/stanfordnlp/stanza,1073,0.6887997984886169,1,"## Description It's my proposal for the returned value of `get_known_feats` - returning all values as a dictionary instead of only feats types as a list (omitting possible values). ## Fixes Issues #1066  ## Unit test coverage I extended the test of the method to test also the feat value - `Yes`. ## Known breaking changes/behaviors The feature has not been added to main yet, so I think it's fine. "
https://api.github.com/repos/stanfordnlp/stanza,1071,-0.20819811522960663,0,"Add a Bangla NER model"
https://api.github.com/repos/stanfordnlp/stanza,1068,0.5661368370056152,1,"….  Thanks to Allan https://datatables.net/forums/discussion/73237/datatable-on-just-the-docs-github-page/ with a refinement from qipeng "
https://api.github.com/repos/stanfordnlp/stanza,1061,0.08491173386573792,0,"## Description Makes CoreNLPClient not check if the server is alive when start_server=StartServer.DONT_START ## Fixes Issues #1059  ## Unit test coverage test_external_server renamed to test_external_server_available (and modified) test_external_server_timeout added test_external_server_unavailable added pytest executed successfully on stanza/tests/server/test_client.py ## Known breaking changes/behaviors Now when start_server=StartServer.DONT_START the clients must be sure the server is running. Otherwise (if they launched a server instance but didn't wait for enough) they could get a connection error. "
https://api.github.com/repos/stanfordnlp/stanza,1056,-1.2039239406585693,-1,"None"
https://api.github.com/repos/stanfordnlp/stanza,1054,-0.26407480239868164,0,"Make a version of the lattn out of all the inputs, not just the pattn"
https://api.github.com/repos/stanfordnlp/stanza,1053,-1.2039239406585693,-1,"None"
https://api.github.com/repos/stanfordnlp/stanza,1051,0.15085472166538239,0,"Train using AdaDelta for a while w/ no pattn, then switch to AdamW or some other optimizer with the full model"
https://api.github.com/repos/stanfordnlp/stanza,1050,0.5148929953575134,1,"Load the pt directly in Trainer.load().  Will simplify other operations, such as loading or creating models from a foundation_cache "
https://api.github.com/repos/stanfordnlp/stanza,1049,0.400968998670578,0,"Add a learning rate scheduler.  Do some futzing with the tests, especially the conparse tests"
https://api.github.com/repos/stanfordnlp/stanza,1047,0.025930017232894897,0,"Finally, a method that successfully trains pattn layers (seriously, the scores go up compared to adadelta or adamw by themselves)"
https://api.github.com/repos/stanfordnlp/stanza,1043,-0.09192529320716858,0,"Use the recent L3Cube dataset release to add NER and sentiment for Marathi to Stanza"
https://api.github.com/repos/stanfordnlp/stanza,1040,0.07994215935468674,0,"Optional integration with wandb for NER"
https://api.github.com/repos/stanfordnlp/stanza,1039,0.3265073895454407,0,"Try to generalize wikiner reading - currently the download format is a bz2 file with one thing in it, but an older layout I have had the text itself in a ""raw"" subdirectory ignore leftover bz2 files Some of the input files are Windows encoded ffs "
https://api.github.com/repos/stanfordnlp/stanza,1038,-0.07620654255151749,0,"Add a conversion of the Megagon GSD dataset"
https://api.github.com/repos/stanfordnlp/stanza,1033,0.06121765449643135,0,"Update NER to keep pretrain & delta word embeddings separate"
https://api.github.com/repos/stanfordnlp/stanza,1031,0.37111639976501465,0,"Refactor the tokenizer data module to use a torch DataLoader at eval time.  Train time is not changed at all. Between version 1.4.0 and dev branch as of this pull request, some optimizations were added to pass around numpy or torch items sooner.  This improved the runtime some already.  Switching to a pytorch dataloader further improves the runtime.  Timing on a 2080ti and a CPU that was top of the line a couple years ago: ``` main branch: real    0m53.964s user    0m51.178s sys     0m4.205s dev branch: real    0m46.744s user    0m44.220s sys     0m4.028s refactor_dataloader branch: real    0m38.706s user    0m46.471s sys     0m6.985s ``` Most of the timing improvements wound up being portable to the dev branch without the Dataloader.  However, there are a few circumstances where lots of docs of mixed sizes can be faster by spawning multiple workers.  Also, in general it's basically the same speed if you go with num_workers=0, which is the default.  At least merging this in will make it easier to optimize the multiple worker case in the future..."
https://api.github.com/repos/stanfordnlp/stanza,1029,0.4089236855506897,0,"Refactor some pieces of the tokenizer and make some optimizations on the way.  In particular, passing around numpy or torch arrays is faster than making lists of numbers. Add some tests of the data object as well. When parsing one large data file, this makes the tokenizer about 10% faster by simplifying some of the logic to go from raw letters -> numbers"
https://api.github.com/repos/stanfordnlp/stanza,1028,0.13874675333499908,0,"Cache the charlms in a pipeline, especially for sentiment and conparse Also, add bert models to the bottom layer of sentiment"
https://api.github.com/repos/stanfordnlp/stanza,1027,-1.2039239406585693,-1,"None"
https://api.github.com/repos/stanfordnlp/stanza,1026,0.05271616950631142,0,"Refactor loading files for the charlm.  Cleaner and even slightly faster"
https://api.github.com/repos/stanfordnlp/stanza,1025,-0.28316348791122437,0,"Reuse the conparser's charlm code in the sentiment model"
https://api.github.com/repos/stanfordnlp/stanza,1024,0.2478654831647873,0,"More updates to sentiment: use json instead of text to store sentences, which allows for pretokenizing VI sentiment"
https://api.github.com/repos/stanfordnlp/stanza,1023,0.1256076544523239,0,"Rewrite the sentiment conversion scripts to be entirely in python (except for the parts which use Java, of course)"
https://api.github.com/repos/stanfordnlp/stanza,1022,-0.06523261964321136,0,"Do some various refactoring of bert operations, compensate for a DE bert tokenizer issue, and use these changes to produce a German NER bert model."
https://api.github.com/repos/stanfordnlp/stanza,1021,-0.051705874502658844,0,"Refactor a bunch of the sentiment scripts.  Move all the scripts/sentiment stuff to stanza/utils"
https://api.github.com/repos/stanfordnlp/stanza,1016,-0.19780974090099335,0,"wrap files in tqdm so we don't stare at the screen for a while wondering what is happening "
https://api.github.com/repos/stanfordnlp/stanza,1014,-0.5890761017799377,-1,"(do not merge - unfinished)"
https://api.github.com/repos/stanfordnlp/stanza,1012,-0.3395923376083374,0,"V1.4.0 release, tons of changes big & small"
https://api.github.com/repos/stanfordnlp/stanza,1011,0.1524316668510437,0,"**BEFORE YOU START**: please make sure your pull request is against the `dev` branch.  We cannot accept pull requests against the `master` branch.  See our [contributing guide](https://github.com/stanfordnlp/stanza/blob/master/CONTRIBUTING.md) for details. ## Description A brief and concise description of what your pull request is trying to accomplish. ## Fixes Issues A list of issues/bugs with # references. (e.g., #123) ## Unit test coverage Are there unit tests in place to make sure your code is functioning correctly? (see [here](https://github.com/stanfordnlp/stanza/blob/master/tests/test_tagger.py) for a simple example) ## Known breaking changes/behaviors Does this break anything in Stanza's existing user interface? If so, what is it and how is it addressed? "
https://api.github.com/repos/stanfordnlp/stanza,1008,-0.4056576192378998,0,"Use the EN handparsed treebank as a data source without augmentation.  Use the same mechanism to not augment the IT MWT, since that seems a little silly"
https://api.github.com/repos/stanfordnlp/stanza,1002,-0.8079236149787903,-1,"## Description Moving a tensor to a particular device is not an in-place operation. To move `pe` to another device, it needs to be re-assigned with the returned tensor.  ## Fixes Issues #989  ## Unit test coverage ``` nlp = stanza.Pipeline(lang=model, logging_level=""DEBUG"") sent = ""Over and over again Dorian used to read this fantastic chapter, and the two chapters immediately following, in which, as in some curious tapestries or cunningly-wrought enamels, were pictured the awful and beautiful forms of those whom Vice and Blood and Weariness had made monstrous or mad: Filippo, Duke of Milan, who slew his wife, and painted her lips with a scarlet poison that her lover might suck death from the dead thing he fondled; Pietro Barbi, the Venetian, known as Paul the Second, who sought in his vanity to assume the title of Formosus, and whose tiara, valued at two hundred thousand florins, was bought at the price of a terrible sin; Gian Maria Visconti, who used hounds to chase living men, and whose murdered body was covered with roses by a harlot who had loved him; the Borgia on his white horse, with Fratricide riding beside him, and his mantle stained with the blood of Perotto; Pietro Riario, the young Cardinal Archbishop of Florence, child and minion of Sixtus IV., whose beauty was equalled only by his debauchery, and who received Leonora of Aragon in a pavilion of white and crimson silk, filled with nymphs and centaurs, and gilded a boy that he might serve at the feast as Ganymede or Hylas; Ezzelin, whose melancholy could be cured only by the spectacle of death, and who had a passion for red blood, as other men have for red wine--the son of the Fiend, as was reported, and one who had cheated his father at dice when gambling with him for his own soul; Giambattista Cibo, who in mockery took the name of Innocent, and into whose torpid veins the blood of three lads was infused by a Jewish doctor; Sigismondo Malatesta, the lover of Isotta, and the lord of Rimini, whose effigy was burned at Rome as the enemy of God and man, who strangled Polyssena with a napkin, and gave poison to Ginevra d'Este in a cup of emerald, and in honour of a shameful passion built a pagan church for Christian worship; Charles VI., who had so wildly adored his brother's wife that a leper had warned him of the insanity that was coming on him, and who, when his brain had sickened and grown strange, could only be soothed by Saracen cards painted with the images of Love and Death and Madness; and, in his trimmed jerkin and jewelled cap and acanthus-like curls, Grifonetto Baglioni, who slew Astorre with his bride, and Simonetto with his page, and whose comeliness was such that, as he lay dying in the yellow piazza of Perugia, those who had hated him could not choose but weep, and Atalanta, who had cursed him, blessed him."" nlp(sent) ``` ## Known breaking changes/behaviors No "
https://api.github.com/repos/stanfordnlp/stanza,1001,0.14277535676956177,0,"Download files to a tempdir created underneath the expected destination, then use os.replace to move the files (atomically if supported by the file system).  The goal is to ensure that two processes downloading the same file don't clobber each other with partially downloaded junk.  https://github.com/stanfordnlp/stanza/issues/213 "
https://api.github.com/repos/stanfordnlp/stanza,996,0.24500493705272675,0,"Read/write NER on the Tokens TODO: perhaps this needs to be on the Words instead"
https://api.github.com/repos/stanfordnlp/stanza,995,0.023098144680261612,0,"Process sentence ids from the corpus, if available.  Change sentence.id to a string (and incidentally make it match the documentation regarding being 1 indexed) "
https://api.github.com/repos/cvxpy/cvxpy,2047,-0.12288455665111542,0,"## Description The ``conv`` operator was extremely broken, and gave incorrect shape information. This PR fixes bugs in ``conv``, deprecates ``conv``, and adds a ``convolve`` atom that matches np.convolve. @PTNobel  ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,2046,0.09844221919775009,0,"## Description Exposes the `compilation_time` attribute as a property of the `Problem`. I wanted to be able to access this programmatically in a project I was working on. ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,2044,-0.19564834237098694,0,"## Description I found a small typo in the documentation.  It is in the ""derivative fundamental"" sub-section.  ""sensitvity"" -> ""sensitivity"" ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,2043,0.1090998575091362,0,"## Description There was a bug in the canonicalization chain with mosek that failed when both power cones and exponential cones were present. Issue link (if applicable): #2042 ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,2041,0.4032227098941803,0,"## Description Adds support for mixed-integer geometric programs, via the FiniteSet constraint. Issue link (if applicable): #1590 @adishavit The canonicalization is straightforward. I am not allowing the values of the finite set to be parameterized right now, because ``is_pos`` is only supported for leafs but it's needed here for more complex expressions, since theoretically the set values could be something like param1 + param2. I could hack around this though if the functionality is desired. ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,2029,-0.027930211275815964,0,"## Description Tries to make Mosek parameters systematic. See https://github.com/cvxpy/cvxpy/issues/2023 Adds proper handling of the case where both parameter name and value are strings. Deprecates the use of constants from the Python API. Adapts the documentation and test accordingly. Documentation mentions https://docs.mosek.com/latest/faq/faq.html#cvxpy  That link will be separately updated in the same style next time new Mosek docs are uploaded. "
https://api.github.com/repos/cvxpy/cvxpy,2028,0.21846450865268707,0,"## Description Ran into the following bug with p-norms in DGP problems. In particular, the below assertion fails:  ``` x = cp.Variable(pos=True) norm_expr = cp.norm(cp.Constant([3,4]), p=2) prob = cp.Problem(cp.Minimize(norm_expr * x ** 2), [x >= 1]) solution = prob.solve(gp=True) # Correctly returns 5  print(prob.solution.opt_val) # Incorrectly prints 5.8 assert np.isclose(prob.solution.opt_val, solution) ``` Looks like it's due to two issues: 1. In the DGP canon functions dict, the key for pnorms is the pnorm function wrapper, not the Pnorm class.  2. Should be multiplication instead of exponentiation during the canonicalization process.  $\ln\(||x||_p\) = \ln\(\(\sum |x_i|^p \)^\frac{1}{p} \) = \frac{1}{p} \ln \(\sum |x_i|^p\)$  Since we take the logs of all the leaves first and pass that in as args, we are given $z = \ln (x)$. Then, our expr becomes  $\frac{1}{p} \ln \(\sum e^{zp} \) = \frac{1}{p} \text{log-sum-exp} (z * p)$.  Added some tests in `test_dgp2dcp.py` for $p = 2$ and $p = 3$, as well as a matrix fro norm.   ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression. "
https://api.github.com/repos/cvxpy/cvxpy,2022,0.20433086156845093,0,"## Description Unpins setuptools so the latest version can be installed. Issue link (if applicable): #2021 ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [ ] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,2017,0.4838467836380005,0,"Changes the order of operations when initializing the Mosek task: first process options and, in particular, attach the log handler (if verbose), then input data, then optimize. Attaching the log handler before inputting allows the user to see if Mosek produces any warnings about the magnitude of the data which could be a potential hint in case of numerical issues later in the solver."
https://api.github.com/repos/cvxpy/cvxpy,2016,-0.10156363248825073,0,"## Description Change `x` to `X` in second `tv` function definition Issue link (if applicable): N/A ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,2008,0.0658729076385498,0,"## Description Our current build process only builds wheels when we release. Often, failures of these builds are unrelated to the code changes. When wheels are partially released to PyPI, we have to push a fix in a subsequent release.  This change builds whenever we merge to master or a release branch (but not on every PR commit). Regarding changes to the procedures, @h-vetinari you [mentioned](https://github.com/cvxpy/cvxpy/pull/1998#issuecomment-1370662440) that its possible to test pre-releases against your infrastructure. Could you create an example PR on the cvxpy feedstock repo that shows how this is done, then I could add a reference to that in the PROCEDURES document. ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,2007,0.059956666082143784,0,"## Description Changes all atom_canonicalizers folders to canonicalizers, so there is greater uniformity in naming. ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,2001,-0.1675570160150528,0,"Per @aszekMosek's [comment](https://github.com/cvxpy/cvxpy/pull/1978#issuecomment-1373480307) on the last operator relative entropy PR, our test case for ``xexp`` that fixes the input ``x = 0`` in ``xexp(x)`` results in an ill-posed conic formulation. That is, an arbitrarily small perturbation to the conic formulation can change the problem from feasible to infeasible. This change keeps the spirit of the test while avoiding that particular case. ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [X] Bug fix - [ ] Other (Documentation, CI, ...) "
https://api.github.com/repos/cvxpy/cvxpy,1998,0.1688467115163803,0,"Same fix for PyPy as in #1208; also remove a relative import that makes the test suite fail to run against an out-of-tree `cvxpy`. From https://github.com/conda-forge/cvxpy-feedstock/pull/75"
https://api.github.com/repos/cvxpy/cvxpy,1996,0.036507099866867065,0,"## Description Please include a short summary of the change. Issue link (if applicable): ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1994,-0.25565046072006226,0,"## Description Adding the release notes for 1.3 to the web docs. ![image](https://user-images.githubusercontent.com/44360364/210420639-f446ff30-c60a-4f46-9cf0-3cbaba94f7c5.png) ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1992,-0.31152868270874023,0,"## Description Sphinx recently stopped automatically including jQuery, which is required by our site for the version selector. This PR adds jQuery back to the build. https://www.sphinx-doc.org/en/master/changes.html ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1991,-0.047091275453567505,0,"## Description Mention CVXPYgen in related projects. ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1987,0.10110108554363251,0,"### Background on this PR PR #1978 (targeting CVXPY 1.3) included bugfixes for dual variable recovery in problems with complex expressions. The fixes involved adding tuples called ``UNIMPLEMENTED_REAL_DUALS`` and ``UNIMPLEMENTED_COMPLEX_DUALS`` to the ``Complex2Real`` class. These tuples consisted of certain Constraint classes. If the type of a Constraint object belonged to one of these tuples then dual variable recovery for that Constraint would be skipped. @SteveDiamond started the process of porting this bugfix to CVXPY 1.1 and 1.2 ([link](https://github.com/cvxpy/cvxpy/pull/1955/commits/5be035253739bf6b0a0a76a14a264e7f3831ac62#diff-06ac9467275a4f02950ff75e8cc0f196fae9c2475e68ea88beb0b80606966a5aR38-R39)). It seemed to Steven that _additional_ constraint classes were needed in these new tuples.  At Steven's suggestion I ran some tests and found that the code introduced in PR #1978 could still break.  This led me to look into this in more detail. The result of my investigation is that changes are needed on both master (for CVXPY 1.3) as well as CVXPY 1.1 and 1.2. This PR is targeting master. ### Changes in this PR The main change in this PR is to go through all the Constraint classes and make sure that the list returned by ``constr.get_data()`` satisfies ``constr.get_data()[-1] == constr.id``. This has long been the default behavior for the Constraint class, but it was ""lost"" in subclasses that overrode the ``get_data`` function. Such classes included ExpCone, PowCone3D, PowConeND, SOC, and the quadrature-based approximate cones (to appear in 1.3). After making this change it was possible for me to get rid of the ``UNIMPLEMENTED_REAL_DUALS`` tuple introduced in PR #1978. Note: the change to the SOC class wasn't strictly necessary, since SOC has a dedicated complex2real canonicalizer that copies the constraint ID ([see here](https://github.com/cvxpy/cvxpy/blob/1c94aad38d961c754c7c097f66d60f7a62fe10ea/cvxpy/reductions/complex2real/canonicalizers/soc_canon.py#L22)). No change was needed to PSD because the PSD class did not override ``Constraint.get_data()``. I also added input checks for real data to several Constraint classes. This is necessary for CVXPY 1.3 since all Constraint classes are now being exposed in CVXPY's top-level namespace. ### Are these changes really necessary? This PR includes two new unittests in ``test_complex.py``. These tests will fail if run on master or if run on Steven's pending PR for 1.1 and 1.2 (including if you modify to account for different import structures in these branches). The tests will also fail before either my fix or Steven's version, when the repo was at [this state](https://github.com/cvxpy/cvxpy/tree/f216089ef53a8496b18643211997e00a83cef9d3)."
https://api.github.com/repos/cvxpy/cvxpy,1986,0.3775459825992584,0,"Hi -- small QOL upgrade for my personal cvxpy usage to automatically turn native matmul into quadratic forms where applicable. See issue #1762. When expressions are being constructed, then some MulExpression are automatically turned into a QuadForm, when certain criteria hold.  Notes:  1) Does not handle associativity. If we have a constant vector c, then `1/2 * c.T @ c @ x.T @ A @ x` is technically a quadratic form `(1/2 * c.T @ c) * QuadForm(x, A)`, but will not be converted in the below change.  Reasoning here is that the expression tree leading up to the quadratic form can be arbitrarily tall and would require a search for the right-most leaf (to avoid QuadForms in cases like `1/2 * (c.T @ (c @ (d.T @ (d @ x.T)))) @ A @ y`).  However, as long as parantheses are included around `x.T @ A @ x`, the Expr will have a correct QuadForm leaf.   2) Does not handle asymmetric/non-hermitian matrices. I noticed that the default QuadForm behavior currently is to throw an error if QuadForm(x, A) is called with A being asymmetric/nonhermitian. Could simply replace A with (A + A.H) / 2 but saw that was removed a while back.  Let me know if these are not the desired behavior -- thanks!  Best, Jeffrey ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. (N/A)  - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression. "
https://api.github.com/repos/cvxpy/cvxpy,1984,-0.029867205768823624,0,"The build failures in https://github.com/cvxpy/cvxpy/actions/runs/3772470280/jobs/6413421816 happened even though ``(cp.xexp, cp.MOSEK)`` were added to the list of known solver errors in ``test_constant_atoms.py``. Upon further inspection, that's because the ``KNOWN_SOLVER_ERRORS`` list wasn't being checked in the appropriate way. This PR addresses that; I've confirmed that it correctly skips the case of ``('xexp', cp.MOSEK)`` (note the problematic atom has to be specified as a string now)."
https://api.github.com/repos/cvxpy/cvxpy,1979,-0.18611566722393036,0,"## Description Numpy just released a new version that deprecated `np.int`. Removing two non-urgent cases in CVXPY codebase. More urgent ecos PR is here: https://github.com/embotech/ecos-python/pull/45 Not marking this one as a bug fix, as it only affects one example Issue link (if applicable): https://discord.com/channels/845323972962549790/845327242456203295/1054122743001526413 ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1978,0.1756579428911209,0,"@SteveDiamond @phschiele this is ready for review. Once this PR is merged we will have all the functionality I wanted ready for CVXPY 1.3. (There's still more to do, but it's reasonable to hold until CVXPY 1.4.) ### Main changes The quadrature-based approximation of the operator relative entropy cone: ``OpRelEntrConeQuad``. * This constraint class now accepts Hermitian input. Previously, it only accepted symmetric input. * The ``TestOpRelConeQuad`` class  in ``tests/test_cone2cone.py`` has been rewritten. The ``von_neumann_entr`` atom. * This now accepts Hermitian input. Previously it only accepted symmetric input. * The ``Test_von_neumann_entr`` class in ``tests/test_von_neumann_entr.py`` has been rewritten. * Since its introduction into cvxpy's master branch,``von_neumann_entr``'s default canonicalization codepath has used PSD + ExpCone constraints. It also had the option of using a quadrature-based approximation technique to remove the ExpCone constraints and replace them with more PSD constraints. This reformulation was very inefficient. This PR makes it so that if the user provides approximation parameters to ``von_neumann_entr``, then the ExpCone constraints will be replaced with SOC constraints. ### Bigger incidental changes I changed the ``canonicalize_expr()`` function in ``complex2real/complex2real.py``, see [here](https://github.com/cvxpy/cvxpy/pull/1978/files#diff-06ac9467275a4f02950ff75e8cc0f196fae9c2475e68ea88beb0b80606966a5aR180-R188). The change makes sure that any Constraint objects are wrapped by a list before being returned. Previously this hasn't been necessary because most other Constraint objects had canonicalizers in ``complex2real/canonicalizers`` that were called _even when their inputs were exclusively real-valued_. However, that existing approach has a longstanding bug where someone using ``ExpCone`` or ``PowCone3D`` _anywhere_ in a model with complex-valued expressions would result in an error. That change isn't sufficient to address all bugs. I added a ``REAL_DUALS_IMPLEMENTED`` attribute to the ``Constraint`` class. It defaults to True, but I've set it to False in a handful of classes: ``PowConeND`` and both quadrature-based approximation cones. This change should be propagated to earlier CVXPY releases, since it amounts to a bugfix for models that use ``PowConeND` alongside complex expressions. ### Small incidental changes * The trace atom now recognizes that the trace of a Hermitian matrix (or a real matrix) is real. Making this change involved moving the complex2real canonicalization path for trace from ``separable_canon()`` in ``complex2real/canonicalizers/aff_canon.py`` into a new ``trace_canon()`` function in ``complex2real/canonicalizers/matrix_canon.py``. * MOSEK encounters a solver failure when testing the composite atom ``xexp(pos(expr))`` in ``test_constant_atoms.py``. I've added that atom-solver pair to the list of known solver errors, so that test won't run. It's an esoteric test, but the folks at @aszekMosek might want to investigate if the latest release of MOSEK has some numerical problems. * I renamed the file ``utilities/eigvals.py`` to ``utilities/linalg.py``, and added some functions to the renamed file. One new function computes an orthonormal basis for the range of an input matrix. Another function computes an orthonormal basis for the orthogonal complement of the range of an input matrix."
https://api.github.com/repos/cvxpy/cvxpy,1977,0.323244571685791,0,"This renames the ``OpRelConeQuad`` and ``RelEntrQuad`` constraint classes to ``OpRelEntrConeQuad`` and ``RelEntrConeQuad``. It also introduces more informative warning messages."
https://api.github.com/repos/cvxpy/cvxpy,1976,0.15240605175495148,0,"### The problem Here is CVXPY's current code for canonicalizing a complex Variable into real and imaginary parts: ``` def variable_canon(expr, real_args, imag_args, real2imag):     if expr.is_real():         return expr, None     imag = Variable(expr.shape, var_id=real2imag[expr.id])     if expr.is_imag():         return None, imag     elif expr.is_complex() and expr.is_hermitian():         return Variable(expr.shape, var_id=expr.id, symmetric=True), (imag - imag.T)/2     else:  # Complex.         return Variable(expr.shape, var_id=expr.id), imag ``` The parameterization of Hermitian matrices is higher-dimensional than necessary, as explained below. > The standard representation an $n \times n$ Hermitian matrix in terms of real quantities consists of an $n \times n$ symmetric part and an $n \times n$ skew-symmetric part. (Recall that a square matrix $A$ is called skew-symmetric if $A^T = -A$.)  The dimension of this representation is exactly $n^2$. However, the implementation above uses an unstructued complex variable for the imaginary part of the Hermitian matrix, which adds $n(n+1)/2$ unnecessary free parameters. This PR resolves the above inefficiency and its downstream effects. (It's a subset of the changes originally proposed in PR #1969. That PR will be closed once this PR and a couple others are merged.) ### The solution The first step in addressing the inefficiency above is to define ``imag = Variable(expr.shape[0] * (expr.shape[0]-1) // 2)`` when ``expr.is_hermitian()``. Then, instead of returning ``(imag - imag.T)/2`` for the imaginary part of ``expr``, we return the skew-symmetric Expression ``strict_upper_tri(imag) - strict_upper_tri(imag).T``.  This solution requires modest changes to the ``Complex2Real`` reduction defined in ``reductions/complex2real.py``. This PR goes a step further. Its main user-facing change is a new skew-symmetric property for Expression objects.  By default, an expression ``expr`` will have ``expr.is_skew_symmetric() == False``. However, if ``expr`` is a Constant then ``expr.is_skew_symmetric()`` will be determined by inspecting ``expr.value``. One can also assert that an Expression is skew-symmetric by using a new wrap atom: ``skew_symmetric_wrap``. The ``skew_symmetric_wrap`` atom helps with canonicalization of matrix atoms that accept complex input. When many such atoms are applied to a complex matrix $C = X + iY$ (with $X$ and $Y$ real), they canonicalize by applying a real version of the atom to the lifted representation $$Z(X, Y) = \\begin{bmatrix} X & Y \\\ -Y & X \\end{bmatrix}.$$ This lifted representation is important because it is easy to express its singular values and singular vectors in terms of those of $C$. (This is true even when $C$ is not square!) In the special case when $C = X + i Y$ is Hermitian, we must have that $X$ is symmetric and $Y$ is skew-symmetric. It is easy to show that when this happens, $Z(X, Y)$ is symmetric, and in fact one can represent its eigenvalues and eigenvectors in terms of the eigenvalues of eigenvectors of $C$.  This PR includes a new ``expand_complex`` function in ``complex2real/canonicalizers/matrix_canon.py`` that preserves the facts above for purposes of DCP checks. This new function replaces the old ``hermitian_canon`` function. Its main change is to check that if ``X.is_symmetric()`` and ``Y.is_skew_symmetric()``, then it forms ``Z(X, Y)`` and returns ``symmetric_wrap(Z(X,Y))``. ### Smaller changes This PR also includes minor changes to other wrap atoms: * It introduces a ``symmetric_wrap`` atom. * It requires that certain DCP properties hold in order to use a given wrap. For example: ``symmetric_wrap(M)``, ``hermitian_wrap(M)``, and ``psd_wrap(M)`` now explicitly check that the provided matrix ``M`` is square."
https://api.github.com/repos/cvxpy/cvxpy,1966,0.13573090732097626,0,"## Description Fix a typo in Dgp2Dcp example for the dcp_problem variable name. ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1962,0.07245011627674103,0,"## Description APIs for adding constraints has changed with gurobipy version 10, this PR has the necessary updates.  Also I removed references to a non-documented API in gurobipy version 8.1.1, which is no longer supported. ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [x] Check that your code adheres to our coding style. - [ ] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1955,0.09455837309360504,0,"## Description Cherry picks to prepare for new patch #1931  #1951  #1866  #1962  Elements of #1978  #1984 #1987 ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1952,0.06614798307418823,0,"## Description Cherry picking to prepare for a new patch. #1931  #1951  #1866  #1962  Elements of #1978 #1987  ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1951,-0.13514061272144318,0,"## Description This PR pins the setuptools version to the latest version that's used in the project's CI. Resolves #1950 that was introduced due to https://github.com/pypa/setuptools/issues/3693 ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - ~~[ ] Add our license to new files.~~ - [x] Check that your code adheres to our coding style. - ~~[ ] Write unittests.~~ - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression. Test procedure: - Install package from source with `python setup.py develop && pip install .` - Run unit tests with `cd cvxpy/tests && pytest` - Run benchmarks with `` Test results: - Unit tests: `852 passed, 289 skipped, 543 warnings in 41.25s` - Benchmark: `9 passed, 3 skipped, 1 warning in 6.43s` "
https://api.github.com/repos/cvxpy/cvxpy,1937,0.011273934505879879,0,"## Description When running the test suite with SciPy 1.9, the `TestMIPVariable` test fails, blocking #1936. ~We should probably investigate the root cause beyond excluding it from the tests, happy to create an issue for tracking this investigation.~ See #1938 ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1936,0.13808806240558624,0,"## Description Get the new backend workflow working (it only executed the first time after merging the backend PR). ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1935,0.34071093797683716,0,"This change introduces option ""save_iis"" for the FICO Xpress conic solver. For infeasible problems, the user can choose if and how many IIS (Irreducible Infeasible Subsystems) should be returned together with the infeasibility result. Returning IIS is now off by default because of its performance impact. If solver_opts['save_iis'] is positive, at most as many IISs are returned. If negative, all IIS are returned. If zero or not specified, no IIS is returned. "
https://api.github.com/repos/cvxpy/cvxpy,1933,-0.14170727133750916,0,"## Description Fixes #1932  Note: I have changed the symbol of the argument from `A` to `X` to indicate that it is a variable, not a constant (more consistent with other atoms). Docs: ![image](https://user-images.githubusercontent.com/44360364/200141545-9a023369-f221-4e1e-9415-35c9969c31fb.png) and ![image](https://user-images.githubusercontent.com/44360364/200141562-bc6f10c3-40ad-48f5-93ae-4f2b3a5b365a.png) ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1931,-0.14891646802425385,0,"## Description Fixes #1930  ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1929,0.3798835575580597,0,"## Description Python 3.11 brings significant speed improvements, better exception messages, and more. It's reasonable to expect that the adoption rate will pick up soon. This PR sets up the CI from our side.  Still, most solvers do not yet support 3.11. This PR is meant to collect the availability of dependencies. - [x] NumPy (starting with 1.23 on PyPI) - [x] SciPy (starting with 1.9.2 on PyPI) - [x] SCS (through conda) - [x] ECOS (through conda) - [x] OSQP Other solvers: - [x] Gurobi - [x] Clarabel - [ ] Mosek TODO: check solvers ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1927,-0.21212118864059448,0,"Signed-off-by: Joyce Brum <joycebrum@google.com> ## Description Upgraded the scorecard-action to 2.0.6 Issue link (if applicable): Closes #1925  ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [X] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [X] Add our license to new files. - [X] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1922,0.16288653016090393,0,"## Description Allow shapes to be passed as lists to be consistent with the NumPy API.  Issue link (if applicable): #1921  ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1909,-0.1700260192155838,0,"## Description There was some discussion recently about how FiniteSet should be importable at the top level. I was making a PR to address that, and noticed many other constraints are not importable at the top level. This PR imports more constraints in the top level ``__init__`` file. Issue link (if applicable): ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [ ] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1899,0.7844399213790894,1,"This PR implements an alternate, approximate canonicalization pathway for the `von_neumann_entr` atom.  I adapted the same series of semi-definite approximations that I have been implementing so far for the previous `Constraint` classes to get a representation for `von_neumann_entr`.  The API for `von_neumann_entr` remains unchanged --- if the user wants to employ this approximate formulation in their program, then they can just pass in the usual parameters for the approximation along with the input matrix, like so: `atom=von_neumann_entr(N, (m, k))`. Some documentation in `von_neumann_entr`'s docstring still remains, but other than that, this is mostly complete! Thanks!"
https://api.github.com/repos/cvxpy/cvxpy,1898,0.011488418094813824,0,"## Description This interface works with the latest pyscipopt and SCIP. It does not provide dual variables for SOCPs, only for LPs. Issue link (if applicable): https://github.com/cvxpy/cvxpy/issues/1889 ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1897,0.154400035738945,0,"## Description This pull request adds a new example that shows how to optimize the kurtosis of an investment portfolio using DCP rules as shown in __[Cajas (2022)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4202967)__. ## Type of change - [ x] Other (Example)"
https://api.github.com/repos/cvxpy/cvxpy,1896,-0.020945992320775986,0,"## Description When setting `use_quad_obj=False` a `TypeError` is raised for Clarabel.  Like in the SCS interface, we need to delete the key before parsing the options. ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1894,-0.2932369112968445,0,"## Description Implements cvxpy interface to the proxqp solver. Main repo for the solver: https://github.com/simple-robotics/proxsuite Documentation: https://simple-robotics.github.io/proxsuite/ ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests (unittests for proxqp solver are run by `test_qp_solvers.py`). - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1893,0.6221367120742798,1,"## Description Tiny follow up to #1888 , allowing the usage `cp.CLARABEL`. Also just a small note on adding CLARABEL at index 0 of `CONIC_SOLVERS` in `solvers/defines.py`: This implicitly makes CLARABEL (if installed) the default solver for supported problems. As soon as CLARABEL is being  added as a dependency, this _could_ cause some regressions for users simply calling `.solve()`, which we should be aware of. Again, many thanks to @goulart-paul for the great contribution. ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1892,-0.038504671305418015,0,"## Description I've configured the OpenSSF Scorecard Github Action with the scorecard.yml file in the .github/workflow folder. Besides, I've added the [badge](https://openssf.org/blog/2022/09/08/show-off-your-security-score-announcing-scorecards-badges/) to readme file, which is completely optional but could be intersting to keep. Issue link (if applicable): Closes #1891  ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [x] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1888,-0.15217645466327667,0,"## Description Implements cvxpy interface to the Clarabel solver.    Main repo for the solver:  https://github.com/oxfordcontrol/Clarabel.rs Documentation, including native python interface : https://oxfordcontrol.github.io/ClarabelDocs/stable/ ## Type of change - [x] New feature (backwards compatible) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression. Supports nonnegative, second order, exponential and power cones with linear or quadratic objectives.    Binaries are available here: https://pypi.org/project/clarabel/    "
https://api.github.com/repos/cvxpy/cvxpy,1887,-0.39262837171554565,0,"## Description > The ubuntu-18.04 environment is deprecated, consider switching to ubuntu-20.04(ubuntu-latest), or ubuntu-22.04 instead. For more details see https://github.com/actions/virtual-environments/issues/6002 Noted by @SteveDiamond  ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1886,-0.13652877509593964,0,"## Description Minor test formatting fix. ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1885,0.1269412487745285,0,"## Description Fixes tests that started failing once Mosek 10 was deployed. Issue link (if applicable): ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1884,-0.37741905450820923,0,"## Description Cherry picks the following PRs: https://github.com/cvxpy/cvxpy/pull/1882 https://github.com/cvxpy/cvxpy/pull/1880 https://github.com/cvxpy/cvxpy/pull/1852 https://github.com/cvxpy/cvxpy/pull/1851 https://github.com/cvxpy/cvxpy/pull/1844 https://github.com/cvxpy/cvxpy/pull/1835 https://github.com/cvxpy/cvxpy/pull/1829 #1855  #1886  #1898  #1922  #1854  #1871  ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1883,-0.37777072191238403,0,"## Description Cherry picks the following PRs into 1.2. https://github.com/cvxpy/cvxpy/pull/1882  https://github.com/cvxpy/cvxpy/pull/1880 https://github.com/cvxpy/cvxpy/pull/1852  https://github.com/cvxpy/cvxpy/pull/1851  https://github.com/cvxpy/cvxpy/pull/1844 https://github.com/cvxpy/cvxpy/pull/1835  https://github.com/cvxpy/cvxpy/pull/1829  #1872  #1885  #1886  #1898  #1922  #1854  #1871  #1859  ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1882,-0.17928816378116608,0,"## Description [Warm start example](https://www.cvxpy.org/tutorial/advanced/index.html#warm-start) with osqp is currently not working with the same speed as in the docs. The problem is the incorrect comparison of the shapes of A, which leads to a new factorization even if the problem did not change at all. ``` import cvxpy as cp import numpy # Problem data. m = 2000 n = 1000 numpy.random.seed(1) A = numpy.random.randn(m, n) b = cp.Parameter(m) # Construct the problem. x = cp.Variable(n) prob = cp.Problem(cp.Minimize(cp.sum_squares(A @ x - b)),                    [x >= 0]) b.value = numpy.random.randn(m) prob.solve() print(""First solve time:"", prob.solver_stats.solve_time) prob.solve(warm_start=True) print(""Second solve time:"", prob.solver_stats.solve_time) ``` leads currently to ``` First solve time: 9.593317918 Second solve time: 4.873378319 ``` while after this fix it is ``` First solve time: 9.829249348000001 Second solve time: 0.175010187 ``` ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1880,0.045788902789354324,0,"## Description Switches SCS timings from milliseconds to seconds. Issue link (if applicable): #1878  ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1877,0.34997203946113586,0,"## Description This adds the ability to specify an initial guess for Gurobi from #1664. Issue link (if applicable): #1664  ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1875,0.5366551280021667,1,"In this PR, I add support for the ""Full"" operator relative entropy cone (specifically, the approximation scheme for the same as defined in [FSP17](https://arxiv.org/abs/1705.00812)), which is the epigraph associated with the _operator relative entropy_, which in turn, is defined as the _non-commutative perspective_ of the negative logarithm The _Operator Relative Entropy_ is defined as so: $$ D_{\text{op}}(X||Y)=-X^{1/2} \log(X^{-1/2} Y X^{-1/2}) X^{1/2}  $$ The corresponding ""Full"" Operator Relative Entropy Cone is defined as follows: $$ K_{\text{re}}^{n}=\text{cl}\\{(X,Y,T)\in {\mathbb{H}}_{\scriptsize{++}}^{n}\times \mathbb{H}_{\scriptsize{++}}^{n}\times \mathbb{H}^{n}: D_{\text{op}}(X||Y)\preceq T\\} $$ The PR implements a well motivated approximation to the above set, where instead of working with the non-commutative perspective of the negative logarithm, we operate over an approximate proxy for the same (which is defined in terms of two key ideas i.e. an integral representation of the logarithm and the functional equation: $\log(x)=\frac{1}{h}\log(x^h)$ ), and hence; instead, we observe the epigraph of the non-commutative perspective of this approximate construction. The current implementation is largely complete. Web documentation is still needed and the implementation needs to support complex (i.e., actually Hermitian, rather than symmetric) inputs. Thank you!"
https://api.github.com/repos/cvxpy/cvxpy,1874,-0.11903385072946548,0,"## Description Starting by simplification of dependency installation. Many cases are meanwhile obsolete. Issue link (if applicable): CI failing, e.g. in #1840 #1867 #1872  ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1872,0.3391993045806885,0,"The code remains compatible with both 9.3 and 9.4. Also place conservative upper bounds on the supported version because the ortools API may change in any point release. Closes #1868"
https://api.github.com/repos/cvxpy/cvxpy,1871,-0.11023663729429245,0,"Signed-off-by: KerimovEmil  ## Description Raising an error for non-supported string arguments into norm atom, and handling the fro norm. Addressing issue: https://github.com/cvxpy/cvxpy/issues/1865 ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1869,0.10461448132991791,0,"## Description Improve sign analysis for trace when argument is PSD/NSD.  Issue link (if applicable): NA ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1867,0.10146326571702957,0,"## Description Support for generic handling of the perspective transform has been a longstanding issue dating back to pre 1.0 days. We (@phschiele  and I) use the fact that the perspective transform of a function with a given graph form is trivially obtained. We implement this functionality as a new atom called `perspective` which takes in a (convex) scalar expression `f ` and a nonnegative affine scalar `s`. Under the hood, the canonicalization computes `f`'s graph form, adds the new variable `s`, and represents the perspective of `f` by returning the epigraph variable `t`. For further reference on the graph form perspective rule, see @moehle's [paper](https://www-sciencedirect-com.stanford.idm.oclc.org/science/article/pii/S0167691115001747). This is still a work in progress and we hope to get some feedback on the general implementation idea. We provide extensive tests for problems involving the second order cone, the exponential cone, the power cone, and the psd cone. There is still some minor additions: dealing with concave functions, grad, elementwise capability, but we think the core functionality is there. Issue link (if applicable): #420 ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1866,0.09708990156650543,0,"This fixes #1816. The current ``log_det`` implementation can return wrong results if (1) the matrix was complex but not diagonal (2) the matrix is complex and diagonal, but numpy's ``slogdet`` function returns a sign with an extremely small imaginary part. The solution is simple since the atom is supposed to project onto the set of Hermtian matrices as a first step: Hermitian matrices always have real eigenvalues, so we should just check the real part of the sign returned from numpy's ``slogdet``."
https://api.github.com/repos/cvxpy/cvxpy,1862,0.3800739049911499,0,"This pull requests improves typing annotations. The main changes are: - adds `int` as a valid type for shape argument in `cp.Parameter()` and `cp.Variable()` - using [`__future__.annotations`](https://peps.python.org/pep-0563/), we can simplify the typing annotations"
https://api.github.com/repos/cvxpy/cvxpy,1861,-0.24443233013153076,0,"cvxpy requires Python 3.7+, as stated on the [Installation Guide](https://www.cvxpy.org/install/index.html) and in [setup.py](https://github.com/cvxpy/cvxpy/blob/v1.2.1/setup.py#L227)."
https://api.github.com/repos/cvxpy/cvxpy,1859,0.3200206458568573,0,"Fixes #1858 I looked for examples of tests that check that the time limit is actually hit but didn't find any. These are potentially flaky, but still useful to check that the time limit is actually enforced."
https://api.github.com/repos/cvxpy/cvxpy,1856,0.09330163896083832,0,"## Description This PR adds support for the quadratic objective + conic constraints standard form currently supported by SCS. Main changes: - Updated cone_matrix_stuffing and dcp2cone to handle quadratic objectives. - Added ``has_quadratic_term`` to check if an objective expression is compatible with the quadratic objective + conic constraints standard form. - Added some logic to construct_solving_chain to follow the new canonicalization path when appropriate. Canonicalization is only altered for problems that use SCS (or another conic solver that supports quadratic objectives) and have an objective with a quadratic term. In theory all conic problems could use the new canonicalization path, but I didn't want to risk performance regressions. I also added a new solver argument for SCS that can force cvxpy to use the old canonicalization path. Issue link (if applicable): #1605  ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1854,-0.08562526106834412,0,"## Description Implement a fix for retrieving gradient of quad_form for a two-dimensional optimization problem. Current unit test for gradient of quad_form still passes. I added an additional unittest for multidimension quad_form gradient. Fix for https://github.com/cvxpy/cvxpy/issues/1837 New test would fail under the original code: ![image](https://user-images.githubusercontent.com/74955560/182374967-6905c49d-63b9-4fe3-ba9b-ffd16f7166a3.png) ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1853,0.18376104533672333,0,"## Description This PR points to the `bugfix/soc_resid` branch and adds handling for the edge cases, taking inspiration from @rileyjmurray 's code in the issue and the mosek docs. (The linters were failing here, so I merged the master into this branch. Merge master into ``bugfix/soc_resid`` to get rid of the noise in this PR)."
https://api.github.com/repos/cvxpy/cvxpy,1852,-0.07401245087385178,0,"## Description Always compare `expression.id` instead of (implicitly) `hash(expression)` for variables and parameters. Issue link (if applicable): #1827  TODO: A question remains if cvxpy should always be two instances to be the same if they have the same `.id`. E.g. what is the expected behavior of the following (a similar example can be constructed for parameters): ```py     x = cp.Variable(nonneg=True)     y = copy.deepcopy(x)     obj = cp.Minimize((x + y))     prob = cp.Problem(obj)     prob.solve() ``` There are also the `.copy()` functions, which do not deepcopy the leaves, presumably for this very reason. Should `deepcopy(expression)` be generally discouraged?  ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1851,-0.13371138274669647,0,"## Description Looks like there was a new release of flake8 that requires a few small changes to make the linters pass again: ![image](https://user-images.githubusercontent.com/44360364/182042839-34a86949-9f4c-48f8-9a7f-995d4abbeec7.png) ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1846,-0.10215433686971664,0,"## Description Tests are failing bc our current macOS runner is deprecated and will be removed soon. ![image](https://user-images.githubusercontent.com/44360364/181384938-a183074f-cfbb-4406-9f96-1f6096e0a3c2.png) ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) "
https://api.github.com/repos/cvxpy/cvxpy,1844,0.19401104748249054,0,"## Description I fixed the computation of the SOC residual. Issue link (if applicable): #1841  ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1840,0.3973163366317749,0,"## Description This PR attempts to bring a new backend to CVXPY that no longer relies on CVXCORE. I.e., the code in `lin_ops/parser.py` should contain all functionality currently in the C++ code. Preliminary testing shows that it is usually faster when no/few parameters are involved.  For problems with many parameters, the stacking of 2D sparse matrices is slow. A follow-up with ND-sparse libraries is in progress. The main idea is to make this feature `opt-in` now to get more feedback on its performance in different applications. Issue link (if applicable): #1521 Some questions @cvxpy/maintainers: 1. What's the best way to pipe the backend choice through? Obviously, the current implementation is just for demonstration 2. What about testing? For development, I added a special flag that would test all backends and ensure the result is the same across backends, but I was not sure if we would like to have such a flag exposed. TODOs: - [x] Documentation - [x] Remove some code duplication - [x] Unit tests - [x] Regression tests (i.e., running all tests under the new backend) ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1839,-0.14332972466945648,0,"## Description Add two badges to point to: - Sonarcloud (coverage) - Benchmark page ![image](https://user-images.githubusercontent.com/44360364/180487126-1f17d7f6-f6ec-4181-9ed5-532ed63379fc.png) ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1838,-0.03327198699116707,0,"## Description Failing test creates downstream issues like no coverage reports. Issue link (if applicable): #1815 ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1836,0.16815520823001862,0,"## Description Please include a short summary of the change. Issue link (if applicable): ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [x] Check that your code adheres to our coding style. - [ ] Write unittests. - [x] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1835,0.028335582464933395,0,"## Description There was a bug in diff that made it impossible to use on some arrays with dimension 1. Issue link (if applicable): #1834  ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1833,0.4056471586227417,0,"In this PR, I add support for the scalar relative entropy cone via the approximation method that was defined in Theorem-3 of [THIS paper](https://arxiv.org/abs/1705.00812).  The sREC also happens to be directly connected (under a permutation and sign change of the arguments) to the exponential cone, and @rileyjmurray added a method for conversion from `ExpCone` to `ExpConeQuad` to that end.  As it stands now, the biggest shortcoming in the current state of the PR, are two things: 1. Lack of support for elementwise application of `ExpConeQuad` to vector variables --- this is due to the usage of the `quad_over_lin` atom for implementing the semidefinite approximation (currently, one of the test cases has been explicitly modified to make it pass) 2. Lack of proper experimentation for arriving at a sensible set of defaults for the parameters $(m,k)$ in the approximation --- while $m$ is related to the quadrature approximation used in the procedure, $k$ doesn't lend itself to any kind of an obvious intuitive interpretation. There's also some documentation missing, but I will add that in the next few commits. Thank you!"
https://api.github.com/repos/cvxpy/cvxpy,1830,-0.02258799597620964,0,"## Description This pull request will close #1443 by adding support for solving mixed-integer programs via SciPy functionality that will be available in version 1.9.0. Please see [this discussion](https://github.com/scipy/scipy/issues/16609#issuecomment-1186266704) about HiGHS/SciPy updates that should resolve test instances that currently do not pass but are marked with `TODO`. ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing.   - Two tests fail for me that are not related to these changes: ``` FAILED test_grad.py::TestGrad::test_huber - ValueError: Inexact indices into sparse matrices are not allowed FAILED test_grad.py::TestGrad::test_partial_problem - ValueError: Inexact indices into sparse matrices are not allowed ``` - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression.   - I don't think these changes affect the benchmarks."
https://api.github.com/repos/cvxpy/cvxpy,1829,-0.15450593829154968,0,"## Description The sign function is only quasilinear when applied to univariate input. Currently the function is marked as quasilinear for inputs of any dimension. Issue link (if applicable): #1828  ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1822,0.08848463743925095,0,"## Description Hello, since the current cvxpy does not support the atomic operation  $$\operatorname{trace}\left( \operatorname{inv}\left( X \right) \right)$$ where $X$ is PSD, but I need that feature in my research work. I designed the atomic operation and contributed it to the cvxpy community. Our main work is to demonstrate that  $$\operatorname{trace}\left( \operatorname{inv}\left( X \right) \right)$$ is convex and to implement an equivalent cone form of it. In addition, we provided an example in ""examples/ex_tr_inv.py"" The code we submitted in 1. ""cvxpy/atoms/tr_inv.py"" 2. ""cvxpy/reductions/dcp2cone/atom_canonicalizers/tr_inv_canon.py"" 3. ""cvxpy/reductions/dcp2cone/atom_canonicalizers/tr_inv_canon.py"" 4. ""cvxpy/atoms/__init__.py"" 5. ""cvxpy/reductions/dcp2cone/atom_canonicalizers/__init__.py"" 6. ""examples/ex_tr_inv.py"" ## Type of change - [ ] New feature (backwards compatible) - [*] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [*] Add our license to new files. - [*] Check that your code adheres to our coding style. - [*] Write unittests. - [*] Run the unittests and check that they’re passing. - [*] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1820,0.05118345096707344,0,"## Description I made a small mistake in the tests. ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1818,0.009728911332786083,0,"## Description Adds an argument to quad_form to skip checking that P is PSD. Issue link (if applicable):  ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1814,-0.10909450054168701,0,"## Description In the table of elementwise functions, clarify that CVXPY's `abs()` function supports complex numbers. See: https://www.cvxpy.org/_modules/cvxpy/atoms/elementwise/abs.html Issue link (if applicable): N/A ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist): N/A"
https://api.github.com/repos/cvxpy/cvxpy,1810,0.07653536647558212,0,"## Description Added a new file `pr_benchmarks.yml` to run benchmarks on pull request commits and then comment on the pull request with the results. ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1807,-0.029344554990530014,0,"## Description This PR addresses fixes a typo and hides the warning for having the wrong version of SCIP on import. Issue link (if applicable): #1805 ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [x] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [ ] Write unittests. - [x] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1804,-0.012089242227375507,0,"## Description The exclusion of examples did not extend to subdirectories.  Issue link (if applicable): #1801  ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [ ] Add our license to new files. - [ ] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1803,-0.010568265803158283,0,"## Description This PR implements the `dotsort` atom. While @ericlux and I were looking at a weighted _generalization_ of `sum_largest`, @stephenpboyd pointed out that this is in fact a _special case_ of `dotsort`, i.e., $\langle sort\left(vec(X)\right), sort\left(vec(W)\right) \rangle$. A derivation for `sum_largest` is given e.g. in example 2.7 [here](https://docs.mosek.com/modeling-cookbook/linear.html#weak-and-strong-duality). I'll note that the implementation of `sum_largest` uses a different notation in the dual, which makes translating from this reference to the implementation a bit confusing. In the PR description and implementation, I will stick to the notation used in `sum_largest`. A reference for the implementation (in Julia) can be found [here](https://github.com/jump-dev/Convex.jl/blob/e3ca4249495b836e437043f37f34d86163297ef2/src/atoms/lp_cone/dotsort.jl). One can think of extending the primal form of `sum_largest` to  $$ \begin{split}\begin{array}{ll} \mbox{maximize}      &  x^TZw \\ \mbox{subject to}    &  0\leq Z_{ij}\leq 1, & i=1,\ldots,n, j=1,\ldots,k,\\                      &  \sum_i Z_{ij} = 1, & i=1,\ldots,n,\\                      &  \sum_j Z_{ij} \leq 1, & j=1,\ldots,k \end{array}\end{split} $$ When this problem is solved, $Z$ is used to assign the largest value of $w$ to the largest value of $x$, etc.. I.e., it will look something like this: ![image](https://user-images.githubusercontent.com/44360364/173454206-1c8b20d1-55c9-4882-9cac-ab042bb56136.png) The dual looks like this and thus allows to have non-constant $x$: $$ \begin{split}\begin{array}{ll} \mbox{minimize}   & \sum_j q_j +\sum_i t_i &      & \\ \mbox{subject to }& t_i+q_j         & \geq & w_j * x_i, & i=1,\ldots,n, j=1,\ldots,k\\                   & t_i           & \geq & 0, & i=1,\ldots,n, \end{array}\end{split} $$ I have left some implementation details as comments in the code below. ## Tasks - [x] main code - [x] tests - [x] docs - [x] grad implementation   ## Type of change - [x] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [ ] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [x] Write unittests. - [x] Run the unittests and check that they’re passing. - [x] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/cvxpy/cvxpy,1802,0.019093003123998642,0,"## Description This will not upload files if they already exist on pypi. As a result, the upload jobs will pass rather than fail. ## Type of change - [ ] New feature (backwards compatible) - [ ] New feature (breaking API changes) - [ ] Bug fix - [x] Other (Documentation, CI, ...) ## [Contribution checklist](https://www.cvxpy.org/contributing/index.html#contribution-checklist) - [x] Add our license to new files. - [x] Check that your code adheres to our coding style. - [ ] Write unittests. - [ ] Run the unittests and check that they’re passing. - [ ] Run the benchmarks to make sure your change doesn’t introduce a regression."
https://api.github.com/repos/skulpt/skulpt,1490,-0.058150116354227066,0,"The [blog post link](http://reputablejournal.com/adding-a-module-to-skulpt.html) seems to be dead. This commit merely removes it from the readme."
https://api.github.com/repos/skulpt/skulpt,1480,0.15711234509944916,0,"Hard to test exactly since it will still throw an IndexError, but the message is corrected in this PR ```python >>> x = (1, 2, 3, 4) >>> x[2**75] IndexError: cannot fit 'int' into an index-sized integer ``` This PR brings tuple.js inline with what's already there in list.js If an error class isn't supplied to `asIndexSized` then then if the index is too large it will be returned as `±Number.MAX_SAFE_INTEGER`. So this PR doesn't change the ultimately thrown IndexError, but it does fix the error message, since it gets thrown on line 85 rather than a few lines later. "
https://api.github.com/repos/skulpt/skulpt,1473,0.7108775973320007,1,"implements `uuid4()` which is probably the more common use of the uuid module partial support for `int.from_bytes()` and `int.to_bytes()` (`signed=True` not supported) Tests added for the above The tests also highlighted an issue with our parsing of numbers - see ast.js for the change Skulpt fails with a number like `0x000102030405060708090a0b0c0d0e0f` where it gets compiled as `float(0.0)` 😬  This is tested in the uuid module but happy to add an additional test - and or make this fix a separate pr. "
https://api.github.com/repos/skulpt/skulpt,1472,0.73689866065979,1,"I had some code where a python string leaked into a keyword array when it should have been a javascript string This tweak accounts for that leak The leak itself was our own doing, but it's probably best to handle it nicely. "
https://api.github.com/repos/skulpt/skulpt,1471,-0.4150279760360718,0,"close #1470  Probably the result of a bad rebase Removes duplicate code The exact code removed was refactored into `this.cunpackkwstoarray`, so ends up being called twice."
https://api.github.com/repos/skulpt/skulpt,1457,-0.054524410516023636,0,"@bnmnetp This should close #1455  "
https://api.github.com/repos/skulpt/skulpt,1456,0.24825231730937958,0,"For internal calls to `tp$descr_get` we should send both the instance and the type argument. Whilst most builtins that use `__get__` cope without the second argument, it's possible that a custom `__get__` will expect it to be there. (I found this recently with another library). Quite a small change, I don't think it really needs any additional tests since the call signature to `__get__` is typically `def __get__(self, __obj: Any, __type: type | None = None) -> Any:` "
https://api.github.com/repos/skulpt/skulpt,1454,0.5772204995155334,1,"I found a use case for being able to override `__defaults__`. This PR makes `__defaults__` a writable attribute. I added the tests from the cpython test module `test_funcattrs.py` Any other tests commented out in that file are beyond the scope of this PR But should probably be addressed at some point"
https://api.github.com/repos/skulpt/skulpt,1452,0.4419984221458435,0,"A couple of dunders were not entirely suspension aware. This is mostly ok, because skulpt doesn't use suspensions for these internally - e.g. a skulpt dictionary never suspends. However it's not great for user code with a `@property` decorator and anything that calls `object.__getattribute__` in a way that might lead to a suspension. I added tests for these two cases that failed. I also added suspension awareness to the other dunders that can take a `canSuspend` argument. These can't be tested internally because we don't have native classes that care about suspension for say the `__len__`/`sq$length`. But it's feasible others might want to make use of suspensions in this way."
https://api.github.com/repos/skulpt/skulpt,1451,0.049690134823322296,0,"printing a frozenset causes an error since the `in$repr` property was non writable. This pr fixes that."
https://api.github.com/repos/skulpt/skulpt,1450,-0.346147358417511,0,"Following on from #1442 "
https://api.github.com/repos/skulpt/skulpt,1447,0.097782664000988,0,"Fix a bug from recent PRs In a previous PR we declared a variable for the instance that would be passed to `super()` (previous to that PR the instance to `super()` was always assumed to be variable named `self` but it could easily be `cls` for a classmethod). But the compile code ended up with a bug ```js var $sup = self = args[0], ...; ``` Now fixed to be ```js var self = args[0], ..., $sup = self; ``` The former overrides the global self - i.e. window.self! 😬 The latter uses the locally scoped self ☑"
https://api.github.com/repos/skulpt/skulpt,1445,-0.11601227521896362,0,"See #1393. close #1392"
https://api.github.com/repos/skulpt/skulpt,1443,0.3826504349708557,0,"…of auto generated string Standardizes with other asserts.  Especially for use in contexts like Runestone, it is important to be able to specify novice readable feedback messages."
https://api.github.com/repos/skulpt/skulpt,1442,0.1204691082239151,0,"Not particularly easy to add tests for this since python attribute access, when compiled to javascript, checks for suspensions But it will be an issue for any internal code that expects `tp$gettattr` or `Sk.abstr.gattr` to not suspend unexpectedly. "
https://api.github.com/repos/skulpt/skulpt,1440,0.6889614462852478,1,"This fixes the order in which decorators are applied to classes. Previously this was fixed for functions in #1149. The same fix is applied in this PR. I also added a test for this, and extended the existing test for functions. "
https://api.github.com/repos/skulpt/skulpt,1439,0.13972917199134827,0,"namedtuples in CPython are python classes rather than C or Native classes in Skulpt they're Native classes On a regular Python class you can dynamically add attributes to your class ```python class A: pass A.foo = 'bar' ``` But in a native class this is disallows ```python dict.foo = 'bar' # TypeError ``` There's a flag for this in `type.protoype.tp$setattr` We check if the class is an `sk$klass`. If it is, then we consider the class a python class for attribute setting If not then it's a native class and we throw a `TypeError` error: https://github.com/skulpt/skulpt/blob/1103d4a475276ca325599fae68e68344c3e3f88e/src/type.js#L252-L259 By adding this flag to the namedtuple class we support setting class attributes dynamically "
https://api.github.com/repos/skulpt/skulpt,1438,0.05025167763233185,0,"colormode() only works in Screen Class. fixed #1437"
https://api.github.com/repos/skulpt/skulpt,1435,0.033589135855436325,0,"We currently have a hack for object identity with floats and ints in python only the ints `-5 <= x <= 256` are interned floats are not interned so we shouldn't expect object identity there ```python >>> x = 300; y = 300 >>> x is y False ``` In python you will often get identity because the compiler does interning of constants This is also the case in skulpt But we don't have constant folding like cpython does ```python print(3.0 is 3.0) # True for both skulpt and cpython print(-2.0 is -2.0) # False for skulpt (this branch) True for cpython # in skulpt this becomes Sk.abstr.numberUnaryOp($scope0.$const6, 'USub'); # because we don't have constant folding  ``` _(Note that @albertjan and I have implemented constant folding in https://github.com/skulpt/skulpt_parser/pull/109)_ --- This PR means we can inline the ""Is"" and ""IsNot"" operator to just be `===` and `!==` in compiled code. "
https://api.github.com/repos/skulpt/skulpt,1434,-0.3868888020515442,0,"Probably better to use a WeakMap in these two places so that we don't hold onto references unnecessarily"
https://api.github.com/repos/skulpt/skulpt,1433,0.8378049731254578,1,"Whenever my Python program times out, I get the following error: `ExternalError: TypeError: Sk.builtin.TimeLimitError is not a constructor on line undefined`. This happens because `TimeLimitError` has been changed to `TimeoutError`. A very small change but this fixes the problem."
https://api.github.com/repos/skulpt/skulpt,1430,-0.3256658911705017,0,"address #1146  "
https://api.github.com/repos/skulpt/skulpt,1429,-0.07813356071710587,0,"close #1428"
https://api.github.com/repos/skulpt/skulpt,1427,-1.2039240598678589,-1,"None"
https://api.github.com/repos/skulpt/skulpt,1425,0.245289608836174,0,"close #1396 This fixes the failing tests for me The bumped version of strftime adjusts the implementation to account for changes to `Date.prototype.toString()` in the latest versions of V8."
https://api.github.com/repos/skulpt/skulpt,1424,0.3163636028766632,0,"yes - it probably would have been better to make `locale` work and just use cpython's calendar.py but where's the fun in that? some minor changes to the core: - I added `valueOf()` methods to the core types, which essentially returns `this.v`   - (note a couple of the core classes already had this method)  - `str.centre` was adjusted   - it didn't fully match the cpython implementation and it is used and tested heavily within the calendar implementation This implementation supports any of the locales that `strftime.js` has predefined - e.g. `fr_Fr`, `it_IT` etc. "
https://api.github.com/repos/skulpt/skulpt,1422,0.05787879601120949,0,"tests taken from cpython I think the the `__import__` implementation is fairly well tested since it's part of our compile code, so really this pr just supports actually calling `__import__` from python code. Which currently just breaks because it expects javascript types. I do some type checking but also do the lazy thing of just remapping the objects to javascript since: - from list should be a tuple/list of strings, and - level should be an integer "
https://api.github.com/repos/skulpt/skulpt,1420,0.003215278498828411,0,"fix regression from #1419  Javascript scoping rules meant that the formName was not scoped correctly This Pr fixes that (prior to #1419 we nested the call at each iteration, which meant we didn't need to worry about scoping in the same way)"
https://api.github.com/repos/skulpt/skulpt,1419,0.2838743329048157,0,"In cpython import lib checks a module's spec to see if it's initializing If it's initializing then a `""most likely due to a circular import""` error message is thrown. We don't have specs in skulpt. Instead, I add a `.$initializing` attribute to modules before we eval them. Since a `relativePackage` is responsible for importing its leaf modules, I add the same attribute to the `relativePackage` (if it's not already in the initializing state). I added the Circular Import tests from Cpython and tweaked them slightly. Most tests failed because skulpt thought there were circular imports going on that weren't That seemed to be because the `relativePackage` didn't know anything about the module it was importing early enough. To fix this I add the module as an attribute to the `relativePackage` at the same time we put it in `sys.modules` If the import fails, at the same time as removing the module from `sys.modules`, I also remove the module from the `relativePackage`'s attributes. Since our internal `tp$getattr` implementations are supposed to return `undefined`, To ensure that the `""most likely due to a circular import""` error message is thrown, I adjust the `sk$attrError()` callback. This gets called from compile code to throw a somewhat correct `AttributeError`. In the compile code I also removed a fixReseverd call, which was no longer needed (and actually a little bit broken) since the names for __import__ get converted to `Sk.builtin.str` when  we do `tp$getattr` and `tp$setattr`. Keeping it around meant relative modules would have a `_$rw$` in their python name. Finally I adjust the `testunit.js` file - since it didn't support packages. 😅 "
https://api.github.com/repos/skulpt/skulpt,1416,-0.05746481940150261,0,"See python docs: https://docs.python.org/3/reference/datamodel.html#object.__hash__ Uncomments a test that previously failed. Plus another one that was already passing on master "
https://api.github.com/repos/skulpt/skulpt,1414,0.4355510175228119,0,"close #1413  tests added from cpython - i found the ones that seemed relevant with `__index__` and added them."
https://api.github.com/repos/skulpt/skulpt,1411,0.13705994188785553,0,"changes: ``` foo() takes 2 positional arguments but 1 was  given foo() takes 2 positional arguments but 1 was given ```"
https://api.github.com/repos/skulpt/skulpt,1409,0.09591139853000641,0,"If you like reading c - here are the implementations that I was following `type__dir__`: https://github.com/python/cpython/blob/fea7290a0ecee09bbce571d4d10f5881b7ea3485/Objects/typeobject.c#L4280-L4291 `object__dir__`: https://github.com/python/cpython/blob/fea7290a0ecee09bbce571d4d10f5881b7ea3485/Objects/typeobject.c#L5564-L5609 `merge_class_dict`: https://github.com/python/cpython/blob/fea7290a0ecee09bbce571d4d10f5881b7ea3485/Objects/typeobject.c#L4215-L4267 It's probably a slower implementation - but looking up the `__dir__` is mostly for introspection. It's also more correct - I was able to uncomment a test that would have previously failed. It came up when overriding the `__dict__` property and discovered that cpython uses the return value from `__dict__`, rather than the internal dict attribute, when resolving the dir."
https://api.github.com/repos/skulpt/skulpt,1395,-0.006407563574612141,0,"1st Commit: This pr adds missing tests for the operator module. Copied and pasted from cpython minus pickle tests (which are not included) 2nd Commit: I added the `Sk.abstr.sequenceInPlaceConcat` method to match the `Sk.abstr.sequenceConcat` method and updated both to match cpython's implementation. I also changed a `TypeError` to an `Sk.builtin.TypeError` in `Sk.builtin.abs`. There were a couple of minor bugs in the operator module also fixed in this commit. 3rd Commit: I used object destructing on the relevant `Sk` namespace methods/attributes.  And used arrow functions for some of the one liners in the module. This should make for a slightly smaller minified module. "
https://api.github.com/repos/skulpt/skulpt,1389,0.3878021240234375,0,"Currently the breakpoint in a while loop is set to be after the test. This means that when implementing a line by line debugger, the final test that causes the while loop to terminate is not shown. By changing the position of the debug block, the final test will be shown."
https://api.github.com/repos/skulpt/skulpt,1386,0.4008556306362152,0,"in tokenize.py the `Name` variable is `\w+`. But a Name in python is not `\w+`. This pr adjusts our implementation of tokenize so that the `Name` variable matches a the regex for a python identifier. close #637"
https://api.github.com/repos/skulpt/skulpt,1383,0.04802931845188141,0,"With SuspensionErrors, we throw the error at the location where we couldn't handle a Suspension. This might be incredibly frustrating to debug e.g.  ```python from time import sleep def foo():    sleep(.1) class A:    def __iter__(self):         foo() # I block         return iter([1,2,3]) a = A() for _ in a: # SuspensionError: you can't call a function that blocks or suspends here     pass ``` If the user got an error at line 12 they'd have little idea how to deal with it. But whenever a Suspension occurs in Python we have traceback information based on the child suspensions. So we can fill our traceback with information that can then be reported to the user. e.g. ```text SuspensionError: Cannot call a function that blocks or suspends here at Form1, line 4 called from Form1, line 8 called from Form1, line 12 ```"
https://api.github.com/repos/skulpt/skulpt,1382,0.2681572735309601,0,"Oops - when injecting python Exceptions in #1343 SuspensionError got lost. Added a test."
https://api.github.com/repos/skulpt/skulpt,1378,-0.13685595989227295,0,"The value is never instantiated and since we're about to throw anyway just get the value at runtime"
https://api.github.com/repos/skulpt/skulpt,1377,0.004434171132743359,0,"_strptime.js is now implemented so _strptime.py should be deleted."
https://api.github.com/repos/skulpt/skulpt,1376,-1.2039240598678589,-1,"None"
https://api.github.com/repos/skulpt/skulpt,1374,0.07430548965930939,0,"After #1369 cpython updated their tests in https://github.com/python/cpython/pull/28595 This pr updates our own set of prod tests to match."
https://api.github.com/repos/skulpt/skulpt,1373,-0.1272183507680893,0,"close #1201 "
https://api.github.com/repos/skulpt/skulpt,1372,-1.2039240598678589,-1,"None"
https://api.github.com/repos/skulpt/skulpt,1371,-1.2039240598678589,-1,"None"
https://api.github.com/repos/skulpt/skulpt,1369,-1.2039240598678589,-1,"None"
https://api.github.com/repos/skulpt/skulpt,1368,0.28508812189102173,0,"While developing for this lib I found that testing could be hard since it runs tests on all modules. This pr adds option to choose which module to test. Usage: `node test/testunit.js --python3 --module math`"
https://api.github.com/repos/skulpt/skulpt,1367,-0.32679256796836853,0,"docs: https://docs.python.org/3/library/math.html#math.lcm closes #1366"
https://api.github.com/repos/skulpt/skulpt,1365,0.07061024755239487,0,"fix #931"
https://api.github.com/repos/skulpt/skulpt,1363,-1.2039240598678589,-1,"None"
https://api.github.com/repos/skulpt/skulpt,1362,0.15769430994987488,0,"This pr implements `test_long.py` and updates `test_pow.py`. Adding the tests exposed some problems (mostly) with BigInts and I adjust our implementations accordingly. close #1325 --- The **[final commit](https://github.com/skulpt/skulpt/commit/993e19bdfe1511b7191c128bbfc25ee5baf95112)** in this pr is the one that's worth looking at, since that's where the changes are made. The bulk of the changes are in int.js. - commit 1 - minor formatting and a small tweak to the int slots (minor cosmetic changes) - commit 2 - copy and paste cpython tests into our test suite. - commit 3 - update JSBI (our BigInt polyfill) to the latest version, which includes bug fixes - commit 4 - adjust the cpython tests for skulpt and fix the issues that arose. --- **Some of the bug fixes:** - pow didn't work for negative bigints - round wasn't correctly implemented for bigints - division for bigints where both ints convert to inf as floats but their division results in a finite float.  - comparisons with floats and bigints - bit xor/or/and for integers larger than `2**31` might give the js value rather than the python value. - domain error not thrown for math log functions when `x = 0`. --- Note - we have two versions of the `JSBI.BigInt` polyfill. We use native `BigInt`s under the hood if they are available and if we're in an older browser we use the `JSBI` library as is. To ensure that the changes work in both cases I also ran tests locally after deleting `window.BigInt`."
https://api.github.com/repos/skulpt/skulpt,1361,0.3498288094997406,0,"This pr updates the `test/unit3/test_grammar.py` file. Since our grammar is taken from 3.7 it seemed to make sense to use cpython's test_grammar from the 3.7 branch. I add this in the first commit. In the second commit I comment out some tests that didn't pass.  And make the very minor changes for other tests to pass."
https://api.github.com/repos/skulpt/skulpt,1358,0.2824925184249878,0,"it's possible to get negative timestamp differences in skulpt But all timestamps should really be monotonically increasing  (unless the system time was changed between calls) ```python from time import time t = time() for _ in range(1000):   if time() < t:     print('back in time!')   t = time() ``` This pr fixes that with an implementation that entirely depends on the browser `performance` api. (falling back to the `Date.now()` api if the `performance` api is not available) The previous implementation combined the two apis which led to negative timings since the fractional offset was not accurate with respect to `Date.now()`. I've added comments for browser compatibility links to mdn. I haven't added additional tests since node doesn't support `performance` without a `require('perf_hooks')`. --- I also replace `this` with `Sk.global` in a few places which I think is safer. "
https://api.github.com/repos/skulpt/skulpt,1357,-0.08604735136032104,0,"The following code: ```python print(f'{-0.003:6.3f}') print(f'{0.003:6.3f}') print(f'{-1.234:6.3f}') print(f'{1.234:6.3f}') ``` Produces the following output: ```python 0.003  0.003 1.234  1.234 ``` Instead of. ```python -0.003  0.003 -1.234  1.234 ``` Test taken from cpython. I took the whole test class and commented out the tests that are beyond the scope of this pr. This bug is covered by `FormatTestCase.test_issue35560`. "
https://api.github.com/repos/skulpt/skulpt,1356,0.04884388670325279,0,"the compile code assumed `Sk.builtin.bool` could suspend but i don't think that's ever been the case. This pr fixes this by only calling `Sk.builtin.bool` after the call to `__contains__` has completed any suspensions."
https://api.github.com/repos/skulpt/skulpt,1355,-1.2039240598678589,-1,"None"
https://api.github.com/repos/skulpt/skulpt,1349,-0.1779019683599472,0,"I didn't realise that Ellipsis were part of `__builtins__` This pr puts `Ellipsis` in the skulpt builtindict. It also changes the name of `Sk.builtin.ellipsis` -> `Sk.builtin.Ellipsis`. I can't see this as breaking since it was only introduced 4 weeks ago. Reason: In python the constant is `Ellipsis` and `type(Ellipsis)` is `ellipsis`. "
https://api.github.com/repos/skulpt/skulpt,1348,0.37158727645874023,0,"Moving datetime.js to a native class meant it could no longer be copied or deepcopied. This pr fixes that. I adjusted copy.py to only complain about special methods if we are using the custom copy method to do so. I adjusted bytes.js to support a `valueOf` js method, which returns it's `.v` property. I implemented the `__reduce__` methods based on python's datetime.py module which takes an identical approach. The `tp$new` methods are adjusted inline with the equivalent `__new__` methods in datetime.py. For testing I was able to uncomment one set of tests. I added a test at the end of `test_datetime.py` since copying was primarily tested via pickling... And skulpt doesn't do pickling. "
https://api.github.com/repos/skulpt/skulpt,1347,0.26307326555252075,0,"a couple of places we throw a js SyntaxError when we should throw a python SyntaxError."
https://api.github.com/repos/skulpt/skulpt,1346,0.14555121958255768,0,"The bug happens becuase `__str__` gets called before the instance is instantiated. Because calling `toString` on a skulpt object calls it's repr. (it's a 1 line change the rest are tests) close #1345 "
https://api.github.com/repos/skulpt/skulpt,1343,0.2547818422317505,0,"This pr does a few things 1. changes the flag `sk$acceptable_as_base_class` to `sk$unacceptableBase`  2. Allows Errors to support multiple inheritance close #1342  3. Uses the cpython approach to construct python Error classes 4. Replaces all `NotImplementedError`s with `NotImplementedImportError` for our stdlib stubs close #1341  5. Don't cache modules in sys.modules that raise exceptions ### 1. `sk$acceptable_as_base_class` -> `sk$unacceptableBase` it seems better to have a positive flag here based on the context it's checked It's a relatively new flag and internal so this shouldn't be breaking See `type.js` for when this is checked. ### 2. Allows Errors to be support multiple inheritance adds a flag `sk$solidBase` which all builtin native classes are assigned by default layout conflicts in the `type.js` `best_base` function are checked against this flag. This can be overridden when building a native class. Which is what the Exception classes now do. ### 3. Uses the cpython approach to construct python Error classes See cpython's exceptions.c They have 3 subclass creator functions `ComplexExtendsException`, `SimpleExtendsException` `MiddlingExtendsException`. We take a similar approach and construct the Exceptions this way. The exceptions constructed by `simpleExtends` can be subclassed with other similar exceptions. The major change in this pr is `errors.js`. ### 4. Replaces all `NotImplementedError`s with `NotImplementedImportError` for our stdlib stubs We might break code if we change the Error type. But using multiple inheritance works well. (as suggested in this https://github.com/skulpt/skulpt/pull/276#issuecomment-850090989) It's a very common pattern to catch an `ImportError` and use a fallback so we should support that. ### 5. Don't cache modules in sysmodules that raise exceptions This is consistent with cpython's importlib At the moment in skulpt you can import a not implemented module but only get the error the first time you try to import. All subsequent times you get the cached import This could be bad if you have fallback imports The next time you try to import the module you'd get the cached module rather than the fallback 😬  "
https://api.github.com/repos/skulpt/skulpt,1338,0.22156597673892975,0,"Because in python2 rounding a float returns a float - it becomes a problem when we assert that certain values are python integers if we happen to be in python2 mode. `timedelta(minutes=0)` will fail in python2 mode... "
https://api.github.com/repos/skulpt/skulpt,1337,-1.2039240598678589,-1,"None"
https://api.github.com/repos/skulpt/skulpt,1336,-0.7646039128303528,-1,"As title says."
https://api.github.com/repos/skulpt/skulpt,1335,0.1040298193693161,0,"brings error messages up to date with cpython error messages for `format` and `__format__`"
https://api.github.com/repos/skulpt/skulpt,1334,-0.09595416486263275,0,"I have no idea why this makes any difference to the repl.js speed.  It only affects the repl and doesn't affect running in the browser. It also only affects devbuild and not build. The cause of slowness was from commit 6100446677f755384c64e4ec3bae30ed068688b4 which added `var` before `$compiledmod`.  Removing the `var` also fixed the slow speed of repl.js. Adding `""use strict"";` before `var $compiledmod` also fixed the speed. (but we can't add `""use strict"";` because of the way skulpt handles local variables in compiled python functions) I only found this fix because `Sk.importMainWithBody` was fast in `repl.js` and experimenting with a few differences between `Sk.builtin.exec` and `Sk.importMainWithBody` I stumbled across using `Sk.global[""eval""]` instead of `eval`. Which doesn't make sense to me because they are the same object. In terms of performance - repl.js was 5 times slower from the commit above! Tested on fields.py --- I also found an undeclared variable in our compile code so I changed that `$free`. "
https://api.github.com/repos/skulpt/skulpt,1332,0.45670557022094727,0,"Helps with error propagation when using exec"
https://api.github.com/repos/skulpt/skulpt,1330,0.23571830987930298,0,"When the skulpt tokenizer produces a `NUMBER` token we know it's positive and: - a valid int literal - or float - or purely imaginary complex number We don't need to do quite as much work to turn it into the correct python type.  "
https://api.github.com/repos/skulpt/skulpt,1324,0.17084741592407227,0,"string.py is implemented as string.js breaking changes was a reference that can be found in the version release information for 1.3.0 "
https://api.github.com/repos/skulpt/skulpt,1323,0.09997357428073883,0,"This piece of api snuck in with #1216 and shouldn't be there. I think it was just a hangover from some initial experiments."
https://api.github.com/repos/skulpt/skulpt,1322,0.29760056734085083,0,"Our current implementation of ordered dict can break if you try to do something like ```python from collections import OrderedDict >>> a = OrderedDict() >>> a.set_default('foo', 'bar') >>> a # error dict changed size during iteration ``` That's because not all the methods are overridden for ordered dict  so things in `ordered_keys` are not set for certain methods We could extend the ordered dict to override all the necessary methods (basically all of them). or we could just remove `ordered_keys` and let ordered dict use dict (which is now ordered). The benefits of this approach is reducing the code size. We then only need to override the 3 methods that are different `$r`, `tp$richcompare`, `move_to_end`. "
https://api.github.com/repos/skulpt/skulpt,1321,0.45215123891830444,0,"Only so that it doesn't need to be compiled. It's used in collections. I also change the constructor for `frozenset` to allow a python iterable to be used as the argument. (the change matches the constructor for `set` which also allows an iterable). The keywords are copied from python (3.9)."
https://api.github.com/repos/skulpt/skulpt,1320,0.15360639989376068,0,"After #1212 I encountered a problem when trying to import a module in the repl.  The code in this pr fixes it I couldn't find a failing test for the unittest but in the repl importing any module failed."
https://api.github.com/repos/skulpt/skulpt,1313,0.06844279170036316,0,"We already parse annotations from the function definition.  But they aren't stored in the `__annotations__` descriptor. This pr implements that mechanism. The code in compile.js and symtable.js is adapted from cpython's implementation and is fairly close. I've added a few tests and included the mechanism for posonly args (although we don't yet parse those) The lack of `__annotations__` was a reason I couldn't include `single_dispatch` in the functools implementation. "
https://api.github.com/repos/skulpt/skulpt,1312,-0.19286902248859406,0,"Anvil has been meaning to do this for a while. "
https://api.github.com/repos/skulpt/skulpt,1309,-1.2039240598678589,-1,"None"
https://api.github.com/repos/skulpt/skulpt,1303,0.12773095071315765,0,"The release notes on the ""Using Skulpt"" page are currently showing up as raw Markdown text, this change causes them to be transformed to HTML."
https://api.github.com/repos/skulpt/skulpt,1302,0.00557336863130331,0,"I noticed that next wasn't suspension aware - a small pr to make it so."
https://api.github.com/repos/skulpt/skulpt,1301,0.38953059911727905,0,"This extends the functools implementation to include `lru_cache`. It also adds the `@cache` decorator which was included in python 3.9 I used the cpython tests and adjusted for skulpt. As part of the pr I also assigned Sk objects into the local scope for functools. "
https://api.github.com/repos/skulpt/skulpt,1299,0.6210798621177673,1,"fixes an issue with the TypeError in the bytes constructor.  Improves the internal error message for using `new Sk.builtin.bytes` "
https://api.github.com/repos/skulpt/skulpt,1298,0.2807065546512604,0,"This fixes a couple of typos, and one case where the Markdown syntax was not working due to use of HTML tags."
https://api.github.com/repos/skulpt/skulpt,1297,0.04072673246264458,0,"Fix #1294"
https://api.github.com/repos/PyThaiNLP/pythainlp,772,0.039240434765815735,0,"- Add pythainlp.util.nectec_to_ipa - Add pythainlp.util.ipa_to_rtgs ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,770,-0.4061816930770874,0,"Fix from  ""ก.w."" to ""ก.พ."" ### What does this changes แก้ Typo ใน thai_full_month_lists ของเดือน ก.พ. ### What was wrong เดิม พิมพ์ว่า ก.w. ### How this fixes it แก้เป็น ก.พ. Fixes #... ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [ ] Passed code styles and structures - [ ] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,767,0.21745581924915314,0,"Add thai_strptime from #766 ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,763,-0.13872946798801422,0,"Add new science word"
https://api.github.com/repos/PyThaiNLP/pythainlp,757,-0.02736743912100792,0,"UDgoeswith Author: Prof. Koichi Yasuoka This tagger is provided under the terms of the apache-2.0 License. The source: https://huggingface.co/KoichiYasuoka/deberta-base-thai-ud-goeswith GitHub: https://github.com/KoichiYasuoka ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,754,0.019875049591064453,0,"PyThaiNLP v3.1.1 is the releases updates of PyThaiNLP v3.1.0. ## What is new? - `pythainlp.tools.misspell` changed to `pythainlp.tools.misspell.misspell`. -  Add Reduce import time #719 to PyThaiNLP 3.1.1 #753 -  Doc: Lst20 deprecation warning for 3.1.1 (#749) #752 **Full Changelog**: https://github.com/PyThaiNLP/pythainlp/compare/v3.1.0...v3.1.1 You can install by `pip install pythainlp` or upgrade by `pip install -U pythainlp`. Documentation: [https://pythainlp.github.io/docs/3.1](https://pythainlp.github.io/docs/3.1) Report bug: [https://github.com/PyThaiNLP/pythainlp/issues](https://github.com/PyThaiNLP/pythainlp/issues) See [PyThaiNLP 3.1 change log](https://github.com/PyThaiNLP/pythainlp/issues/643) See [3.1 Milestone](https://github.com/PyThaiNLP/pythainlp/milestone/16). ## Contributors <a href=""https://github.com/PyThaiNLP/pythainlp/graphs/contributors"">   <img src=""https://contributors-img.firebaseapp.com/image?repo=PyThaiNLP/pythainlp"" /> </a> Thanks all the [contributors](https://github.com/PyThaiNLP/pythainlp/graphs/contributors). (Image made with [contributors-img](https://contributors-img.firebaseapp.com/))"
https://api.github.com/repos/PyThaiNLP/pythainlp,753,0.05182547867298126,0,"After https://github.com/PyThaiNLP/pythainlp/pull/719, I think I will add reduce import time https://github.com/PyThaiNLP/pythainlp/pull/719 to PyThaiNLP 3.1.1 because we needs to long time for develop PyThaiNLP 4.0 and to improve efficacy. #750  ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,752,0.1154404878616333,0,"### What does this changes - Add a deprecation message generator - Add deprecation messages to modules that use LST20 dataset ### What was wrong LST20 is going to be removed in version 4.0.0. Currently no warning message. ### How this fixes it Add a deprecation warning message to inform user. Fixes #749  ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [✓] Passed code styles and structures - [✓] Passed code linting checks ~~and unit test~~ **no unit test for this PR, let me know if you need one.** "
https://api.github.com/repos/PyThaiNLP/pythainlp,751,0.12280966341495514,0,"### What does this changes Implement keyword extraction feature and unit test. (#145 ) The engine has two options, namely 'keybert' and 'frequency' for KeyBERT and naive frequency ranking respectively. KeyBERT is an algorithm to rank keywords by cosine similarity between embedding of each ngram in a document to embedding of the whole document. Embeddings are produced by a large language model. I use `airesearch/wangchanberta-base-att-spm-uncased` in this work. The original implementation has more variety to rank keywords. Please check https://github.com/MaartenGr/KeyBERT for more details and better explanations 🙂 . I'm re-implementing core features and making it support Thai. ```python from pythainlp.summarize import extract_keywords text = (     ""เบียร์ เป็นหนึ่งในเครื่องดื่มแอลกอฮอล์ที่เก่าแก่ที่สุดและบริโภคกันอย่างแพร่หลายมากที่สุดในโลก ""     ""และเป็นเครื่องดื่มยอดนิยมอันดับสามทั้งหมด รองจากน้ำดื่มและชา ""     ""ถูกผลิตขึ้นโดยการกลั่นเบียร์ (brewing) และกระบวนการหมักของแป้ง ซึ่งส่วนใหญ่ได้มาจากธัญพืช - ""     ""ส่วนมากมาจากมอลต์ข้าวบาร์เลย์ แม้กระทั่งข้าวสาลี ข้าวโพด ข้าว และข้าวโอ๊ตก็ใช้ได้เช่น ในช่วงขั้นตอนการกลั่นเบียร์ ""     ""กระบวนการหมักของแป้งนั้น น้ำตาลในวอร์ต(wort)จะก่อให้เกิดเอทานอลและคาร์บอนเนชั่นในเบียร์ที่ได้ออกมา ""     ""เบียร์สมัยใหม่ส่วนใหญ่จะกลั่นด้วยฮอปส์ ซึ่งจะเป็นการเพิ่มความขมและรสชาติอื่น ๆ ""     ""และทำหน้าที่เป็นสารกันบูดและสารคงตัวตามธรรมชาติ สารแต่งกลิ่นรสอื่น ๆ ""     ""เช่น กรู๊ต สมุนไพรหรือผลไม้ซึ่งอาจจะรวมทั้งหรือการใช้แทนฮอปส์ ในการกลั่นเบียร์เชิงพาณิชย์ ""     ""ผลของการเกิดคาร์บอนเนชั่นตามธรรมชาติมักจะถูกขจัดออกในช่วงกระบวนการผลิตและแทนที่ด้วยการอัดลมด้วยคาร์บอนเนชั่นแบบบังคับ"" ) keywords = extract_keywords(text) # output: ['wort)', 'brewing)', 'ที่เก่าแก่', 'ขจัดออก', 'อัดลมด้วย'] keywords = extract_keywords(text, engine='frequency') # output: ['เบียร์', 'กลั่น', 'คาร์บอน', 'เนชั่น', 'เครื่องดื่ม'] ``` ### What was wrong Just a brand new feature. ### How this fixes it Fixes #145  Some issues related to `airesearch/wangchanberta-base-att-spm-uncased`. It's spamming warning messages upon init. ``` - This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model). - This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model). Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing CamembertModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.bias'] ``` ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [✓] Passed code styles and structures - [✓] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,748,0.1519373506307602,0,"`pythainlp.util.count_thai_chars` is the function will give you numbers of Thai characters by type. ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,747,-0.003726956434547901,0,"Add more test for TCC https://github.com/PyThaiNLP/pythainlp/pull/741#issuecomment-1287344098 ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,746,-0.1939517706632614,0,"### What does this changes Since [pep8speaks has stopped working (temporary?)](https://github.com/OrkoHunter/pep8speaks/issues/189#issuecomment-1267106628), we may need an alternative way of checking code format for a meanwhile. ### What was wrong Resolve #744  ### How this fixes it - Format all code according to CONTRIBUTION.md - Setup black formatted as [Github action workflow](https://black.readthedocs.io/en/stable/integrations/github_actions.html) This code will throw error (stop Github workflow) as default if incorrect format detected Fixes #... ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test ## How I tested this PR I used [Act](https://github.com/nektos/act) to test Github actions locally 1. Prerequisite: `docker` 2. Install Act `curl https://raw.githubusercontent.com/nektos/act/master/install.sh | sudo bash` 3. Run `./bin/act -W .github/workflows/lint.yml` 4. Check if the workflow runs successfully "
https://api.github.com/repos/PyThaiNLP/pythainlp,743,0.541433572769165,1,"### What does this changes Add ONNX model for Thai2ROM per #639  ![image](https://user-images.githubusercontent.com/12471844/197580939-3229e29d-dcef-42f8-a861-e6872766497e.png) Initial results looks great (2 times speed up) ### What was wrong Description of what was the root cause of the issue. ### How this fixes it Description of how the changes fix the issue. Fixes #... ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [ ] Passed code styles and structures - [x] Passed code linting checks and unit test ### What I need do before this PR ready - [x] Run full code coverage test - [x] Run linting and formatter - [x] Upload ONNX file to my temporary storage - [x] Add scripts I used to convert to ONNX file - [x] Convert pytorch code to numpy from ONNX class - [x] Refactor code to another file? - [x] Others? Please suggest - [x] Add Documentation for ONNX Thai2ROM"
https://api.github.com/repos/PyThaiNLP/pythainlp,742,0.09853161126375198,0,"### What does this changes Add docs/_static/style.css and modified docs/conf.py (refer to https://github.com/PyThaiNLP/pythainlp/issues/720) ### What was wrong According to the issue, the document page's width is limited to 1100px. ### How this fixes it 1. add css file to modify class `.wy-nav-content` width. ```css .wy-nav-content {     max-width: none; } ``` 2. add custom configuration inside conf.py ```python html_css_files = [""style.css""] ``` ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,741,0.18135401606559753,0,"### What does this changes Add <Cons> <Karan> rule to TCC  ### What was wrong I try to tokenize text with ""ทดสอบตัดคำภาษาไทยจอก์น"" but It be `['ทดสอบ', 'ตัด', 'คำ', 'ภาษาไทย', 'จอก', '์น'] `. I checked TCC from @bact think PyThaiNLP's TCC regex doesn't cover that case and I found we forget `C์ ` rule from `<Cons> <TCC1> <Karan>` rule. The `<TCC1>` can be `NULL`. It mean ก์ should be 'ก์'. **Update**: I found many `<Karan>` rules are missing and I added `<Karan>` rules. `Theeramunkong, Thanaruk & Sornlertlamvanich, Virach & Tanhermhong, Thanasan & Chinnan, Wirat. (2004). Character Cluster Based Thai Information Retrieval. 10.1145/355214.355225` https://www.researchgate.net/publication/2853284_Character_Cluster_Based_Thai_Information_Retrieval ### How this fixes it I add `<Karan>` rules to `TCC`. Fixes #662  Thanks @lalital for advice about Karan rule and @c4n for reference. ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,736,-0.08455456793308258,0,"Update perceptron.py"
https://api.github.com/repos/PyThaiNLP/pythainlp,735,0.1466759890317917,0,"### What does this changes Add [Thai-English transliteration dictionary v1.4](https://github.com/wannaphong/thai-english-transliteration-dictionary) to `pythainlp.transliterate.romanize`. ### What was wrong Nothing's wrong. A new feature to improve new transliteration quality. ### How this fixes it Instead of algorithmically generating transliteration (which can be wrong), find one from a predefined look up table. Fixes #681  ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [/] Passed code styles and structures - [/] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,734,0.0364692322909832,0,"Add blackboard pos_tag to cls"
https://api.github.com/repos/PyThaiNLP/pythainlp,733,0.1239912360906601,0,"Add blackboard pos_tag, to resolve #731 It needs - Delete all LST20 model #728 "
https://api.github.com/repos/PyThaiNLP/pythainlp,732,0.1697116196155548,0,"Add blackboard CLS, to resolve #729 It needs - Delete all LST20 model #728 - Add blackboard pos_tag #733 "
https://api.github.com/repos/PyThaiNLP/pythainlp,728,0.45824724435806274,0,"To resolve #727, I think we should remove all model that trained from LST20 Corpus. See discussion in #725"
https://api.github.com/repos/PyThaiNLP/pythainlp,723,-0.014146325178444386,0,"### What does this changes Fix incorrectly word_tokenize-d  numeric data formats such as time, comma-separated numbers, decimal number, and ip address. ### What was wrong For some tokenizers (esp. neural nets), numbers separated with symbols (. , :) are tokenized into multiple parts. They should be atomic. **Example**: ``` ""12:34pm"" -> [""12"", "":"", ""34pm""] ``` ### How this fixes it Postprocess the tokenized tokens with regular expression. `r""(\d+[\.\,:])+\d+""`: digits followed by either "".,:"" once, possibly repeated, and ended with digits. Fixes #652  ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [O] Passed code styles and structures - [O] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,721,-0.00816441047936678,0,"Create CITATION.cff fellow https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-citation-files"
https://api.github.com/repos/PyThaiNLP/pythainlp,719,-0.13968823850154877,0,"Improve: reduce import time"
https://api.github.com/repos/PyThaiNLP/pythainlp,715,-0.20462439954280853,0,"Update 3.1 from dev"
https://api.github.com/repos/PyThaiNLP/pythainlp,713,-0.2712470293045044,0,"This is the release version for PyThaiNLP v3.1.0 You can install by `pip install pythainlp==3.1.0`. Documentation: [https://pythainlp.github.io/dev-docs/](https://pythainlp.github.io/dev-docs/) Report bug: [https://github.com/PyThaiNLP/pythainlp/issues](https://github.com/PyThaiNLP/pythainlp/issues) See [PyThaiNLP 3.1 change log](https://github.com/PyThaiNLP/pythainlp/issues/643) See [3.1 Milestone](https://github.com/PyThaiNLP/pythainlp/milestone/16). ## What is new? ### Deprecation and other API changes #687 Remove deprecated function  - pythainlp.word_vector; doesnt_match, get_model, most_similar_cosmul, sentence_vectorizer, similarity. use WordVector class instead - pythainlp.util.delete_tone. use pythainlp.util.remove_tonemark instead - Remove pythainlp.util.time_time. use pythainlp.util.time_to_thaiword instead - pythainlp.tokenize.syllable_tokenize. use pythainlp.tokenize.subword_tokenize instead ### Dependency Parsing - Now, PyThaiNLP support dependency_parsing 🎉  Add pythainlp.parse.dependency_parsing https://github.com/PyThaiNLP/pythainlp/pull/706 ### Name Entity Tagging - #665 Add Thai-NNER `pythainlp.tag.NNER` - #658 Add LST20NER onnx model. It is LST20NER model to onnx model from fine-turning by [WangchanBERTa model](https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased). ### Transliteration - #659 Add ISO 11940 transliteration - #660 Add Thai W2P v0.2 - #686 Add wunsen - #694 Wunsen Mandarin and Japanese update ### PyThaiNLP Corpus downloader - #656 Add support zip/tar.gz to download corpus ### Text normalization - #673 Add a normalising rule for Lakkhangyao ๅ ### Translate - #674 add gpu option ### Text summarize - #679 Add mt5 cpe kmutt thai sentence sum ### Util - #682 Add live-dead syllable classification - #684 Add live dead syllable classify - #690 Add tone detector ### Soundex - #699 Add Thai-English Cross-Language Transliterated Word Retrieval using Soundex Technique ### Other - #689 map NG tag to PART - #691 Remove TinyDB as a dependency - #692 Fix notifications that newer versions of corpora are available - Add warning about LST20 license ## Contributors ### New Contributors * @chameleonTK made their first contribution in https://github.com/PyThaiNLP/pythainlp/pull/673 * @vikimark made their first contribution in https://github.com/PyThaiNLP/pythainlp/pull/674 * @BLKSerene made their first contribution in https://github.com/PyThaiNLP/pythainlp/pull/691 * @cakimpei made their first contribution in https://github.com/PyThaiNLP/pythainlp/pull/694 **Full Changelog**: https://github.com/PyThaiNLP/pythainlp/compare/v3.0.10...v3.1.0 ### All Contributors <a href=""https://github.com/PyThaiNLP/pythainlp/graphs/contributors"">   <img src=""https://contributors-img.firebaseapp.com/image?repo=PyThaiNLP/pythainlp"" /> </a> Thanks all the [contributors](https://github.com/PyThaiNLP/pythainlp/graphs/contributors). (Image made with [contributors-img](https://contributors-img.firebaseapp.com/)) We build Thai NLP. PyThaiNLP"
https://api.github.com/repos/PyThaiNLP/pythainlp,706,-0.006432120688259602,0,"`pythainlp.parse.dependency_parsing` is dependency parsing for Thai and this pull request will fix #606. ```python from pythainlp.parse import dependency_parsing print(dependency_parsing(""ผมเป็นคนดี"", engine=""esupar"")) # output: # 1       ผม      _       PRON    _       _       3       nsubj   _       SpaceAfter=No # 2       เป็น     _       VERB    _       _       3       cop     _       SpaceAfter=No # 3       คน      _       NOUN    _       _       0       root    _       SpaceAfter=No # 4       ดี       _       VERB    _       _       3       acl     _       SpaceAfter=No print(dependency_parsing(""ผมเป็นคนดี"", engine=""spacy_thai"")) # output: # 1       ผม              PRON    PPRS    _       2       nsubj   _       SpaceAfter=No # 2       เป็น             VERB    VSTA    _       0       ROOT    _       SpaceAfter=No # 3       คนดี             NOUN    NCMN    _       2       obj     _       SpaceAfter=No print(dependency_parsing(""ผมเป็นคนดี"", engine=""transformers_ud"")) # output: # 1 ผม _ PRON _ _ 3 nsubj _ SpaceAfter=No # 2 เป็น _ VERB _ _ 3 cop _ SpaceAfter=No # 3 คน _ NOUN _ _ 0 root _ SpaceAfter=No # 4 ดี _ VERB _ _ 3 acl _ SpaceAfter=No ``` **TODO** - [x] Add [deberta-base-thai-ud-head](https://huggingface.co/KoichiYasuoka/deberta-base-thai-ud-head) from https://github.com/KoichiYasuoka/spaCy-Thai/issues/2 ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,705,0.12116748094558716,0,"Move model - Add about LST20 corpus. - Remove all sideload model that trained on LST20 corpus."
https://api.github.com/repos/PyThaiNLP/pythainlp,703,-0.2179790437221527,0,"Update add-word_detokenize from dev"
https://api.github.com/repos/PyThaiNLP/pythainlp,701,0.37722259759902954,0,"This pull request will fix #700. It is fix the encoding problem in Windows. - change encoding from utf-8 to utf-8-sig for load json file ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,699,-0.09590248763561249,0,"This pull request was add **Thai-English Cross-Language Transliterated Word Retrieval using Soundex Technique** to soundex function. ## Demo ```python >>> from pythainlp.soundex import soundex >>> soundex(""vp"",""prayut_and_somchaip"") '11' >>> soundex(""วีพี"",""prayut_and_somchaip"") '11' >>> soundex(""อเล็กซานเดอร์"",""prayut_and_somchaip"") '5376' >>> soundex(""ALEXANDER"",""prayut_and_somchaip"") '5376' ``` ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test ## References Prayut Suwanvisat, Somchai Prasitjutrakul. Thai-English Cross-Language Transliterated Word Retrieval using Soundex Technique. In 1998 [cited 2022 Sep 8]. Available from: https://www.cp.eng.chula.ac.th/~somchai/spj/papers/ThaiText/ncsec98-clir.pdf"
https://api.github.com/repos/PyThaiNLP/pythainlp,697,-0.4500567317008972,0,"This pull request will add `word_detokenize` and resolves #696 `word_detokenize` is Thai word detokenizer that merge list to string with whitespace. Rules: - [x] Add whitespace between number/other language and Thai words. - [x] Add whitespace between ๆ (Thai iteration mark) and Thai words Example ```python from pythainlp.tokenize import word_detokenize word_detokenize([""ผม"",""เลี้ยง"",""5"",""ตัว""]) # output: 'ผมเลี้ยง 5 ตัว' word_detokenize([""ผม"",""เลี้ยง"","" "",""5"",""ตัว""],""list"") # output: [['ผม', 'เลี้ยง', ' ', '5', ' ', 'ตัว']] ``` ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,695,-0.22904200851917267,0,"See [3.1 Milestone](https://github.com/PyThaiNLP/pythainlp/milestone/16). ## What is new? ### Deprecation and other API changes #687 Remove deprecated function  - pythainlp.word_vector; doesnt_match, get_model, most_similar_cosmul, sentence_vectorizer, similarity. use WordVector class instead - pythainlp.util.delete_tone. use pythainlp.util.remove_tonemark instead - Remove pythainlp.util.time_time. use pythainlp.util.time_to_thaiword instead - pythainlp.tokenize.syllable_tokenize. use pythainlp.tokenize.subword_tokenize instead ### Name Entity Tagging - #665 Add Thai-NNER `pythainlp.tag.NNER` - #658 Add LST20NER onnx model. It is LST20NER model to onnx model from fine-turning by [WangchanBERTa model](https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased). ### Transliteration - #659 Add ISO 11940 transliteration - #660 Add Thai W2P v0.2 - #686 Add wunsen - #694 Wunsen Mandarin and Japanese update ### PyThaiNLP Corpus downloader - #656 Add support zip/tar.gz to download corpus ### Text normalization - #673 Add a normalising rule for Lakkhangyao ๅ ### Translate - #674 add gpu option ### Text summarize - #679 Add mt5 cpe kmutt thai sentence sum ### Util - #682 Add live-dead syllable classification - #684 Add live dead syllable classify - #690 Add tone detector ### Other - #689 map NG tag to PART - #691 Remove TinyDB as a dependency - #692 Fix notifications that newer versions of corpora are available"
https://api.github.com/repos/PyThaiNLP/pythainlp,694,-0.012730580754578114,0,"### What does this changes Update WunsenTransliterate. ### What was wrong Mandarin-to-thai and new transliteration system for Japanese-to-thai are added to [Wunsen](https://github.com/cakimpei/wunsen), but not PyThaiNLP. ### How this fixes it Add Mandarin-to-thai (2 transliteration systems) and 1 new system for Japanese-to-thai. And add option for Mandarin third tone sandhi. ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,693,-0.20495164394378662,0,"This is the first development release for PyThaiNLP v3.1. You can install by `pip install --pre pythainlp==3.1.0.dev0`. Documentation: [https://pythainlp.github.io/dev-docs/](https://pythainlp.github.io/dev-docs/) Report bug: [https://github.com/PyThaiNLP/pythainlp/issues](https://github.com/PyThaiNLP/pythainlp/issues) See [PyThaiNLP 3.1 change log](https://github.com/PyThaiNLP/pythainlp/issues/643) See [3.1 Milestone](https://github.com/PyThaiNLP/pythainlp/milestone/16). ## What is new? ### Deprecation and other API changes #687 Remove deprecated function  - pythainlp.word_vector; doesnt_match, get_model, most_similar_cosmul, sentence_vectorizer, similarity. use WordVector class instead - pythainlp.util.delete_tone. use pythainlp.util.remove_tonemark instead - Remove pythainlp.util.time_time. use pythainlp.util.time_to_thaiword instead - pythainlp.tokenize.syllable_tokenize. use pythainlp.tokenize.subword_tokenize instead ### Name Entity Tagging - #665 Add Thai-NNER `pythainlp.tag.NNER` - #658 Add LST20NER onnx model. It is LST20NER model to onnx model from fine-turning by [WangchanBERTa model](https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased). ### Transliteration - #659 Add ISO 11940 transliteration - #660 Add Thai W2P v0.2 - #686 Add wunsen ### PyThaiNLP Corpus downloader - #656 Add support zip/tar.gz to download corpus ### Text normalization - #673 Add a normalising rule for Lakkhangyao ๅ ### Translate - #674 add gpu option ### Text summarize - #679 Add mt5 cpe kmutt thai sentence sum ### Util - #682 Add live-dead syllable classification - #684 Add live dead syllable classify - #690 Add tone detector ### Other - #689 map NG tag to PART - #691 Remove TinyDB as a dependency - #692 Fix notifications that newer versions of corpora are available ## Contributors <a href=""https://github.com/PyThaiNLP/pythainlp/graphs/contributors"">   <img src=""https://contributors-img.firebaseapp.com/image?repo=PyThaiNLP/pythainlp"" /> </a> Thanks all the [contributors](https://github.com/PyThaiNLP/pythainlp/graphs/contributors). (Image made with [contributors-img](https://contributors-img.firebaseapp.com/))"
https://api.github.com/repos/PyThaiNLP/pythainlp,692,-0.0107128219678998,0,"### What does this changes Fix notifications that newer versions of corpora are available ### What was wrong The current logic checks both the name and the version of the corpus, so the notification of newer versions of corpora will never be issued to users. ### How this fixes it Check the name first, if found, check the version later. ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,691,-0.004866813309490681,0,"### What does this changes This PR removes `TinyDB` as a dependency. ### What was wrong `TinyDB` is an unnecessary external dependency. ### How this fixes it Remove `TinyDB` as a dependency and use `json` in the Python standard library instead. ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [X] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,690,-0.01928827539086342,0,"This is tone detector for Thai syllables. It can output the tone. I write by [thai-language.com/ref/tone-rules](http://www.thai-language.com/ref/tone-rules) documentation. Fix #63 This is include - `syllable_length` - This function is use for find syllable's length. (long or short) ```python from pythainlp.util import sound_syllable print(sound_syllable(""มา"")) # output: live print(sound_syllable(""เลข"")) # output: dead ``` - `tone_detector` - Thai tone detector for syllables ```python from pythainlp.util import tone_detector print(tone_detector(""มา"")) # output: m print(tone_detector(""ไม้"")) # output: h ``` - `syllable_open_close_detector` - This function is use for find Thai syllable that open or closed sound. ```python from pythainlp.util import syllable_open_close_detector print(syllable_open_close_detector(""มาก"")) # output: close print(syllable_open_close_detector(""คะ"")) # output: open ``` - `thai_word_tone_detector` - Thai tone detector for word.  ```python from pythainlp.util import thai_word_tone_detector print(thai_word_tone_detector(""มือถือ"")) # output: [('มือ', 'm'), ('ถือ', 'r')] print(thai_word_tone_detector(""ราคา"")) # output: [('รา', 'm'), ('คา', 'm')] ``` ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,689,-0.08780041337013245,0,"### What does this changes map ""NG"" tag to ""PART"" when run pos tagger with `corpus=""lst20_ud""` ### What was wrong Missing `NG` tag (see https://arxiv.org/abs/2008.05055) Accoding to UnivesalDependency Guideline, it should be mapped to `PART` (see https://universaldependencies.org/u/pos/PART.html) ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [/] Passed code styles and structures - [/] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,688,-0.08369091153144836,0,"### What does this changes Add a new sentence segmentor adopted from Chumpolsathien N., 2020. https://github.com/nakhunchumpolsathien/ThaiSum It is a rule-based model from conjunction words and length of the sentences.  ### What was wrong Just another option for the sentence segmentation model. ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [/] Passed code styles and structures - [/] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,687,0.06836366653442383,0,"This pull request will remove deprecated function. **List deprecated function** - pythainlp.word_vector; doesnt_match, get_model, most_similar_cosmul, sentence_vectorizer, similarity. use WordVector class instead - pythainlp.util.delete_tone. use pythainlp.util.remove_tonemark instead - Remove pythainlp.util.time_time. use pythainlp.util.time_to_thaiword instead - pythainlp.tokenize.syllable_tokenize. use pythainlp.tokenize.subword_tokenize instead"
https://api.github.com/repos/PyThaiNLP/pythainlp,686,0.0025523481890559196,0,"### What does this changes Add `wunsen` for transliterating Japanese/Korean/Vietnamese romanization text to Thai text. `wunsen` github: [https://github.com/cakimpei/wunsen](https://github.com/cakimpei/wunsen) ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,684,0.10036631673574448,0,"### What does this changes Add live-dead syllable classification. from #682, I found that it has bug and I was fix. ## Example ```python from pythainlp.util import sound_syllable print(sound_syllable(""มา"")) # output: live print(sound_syllable(""เลข"")) # output: dead print(sound_syllable(""เพราะ"")) # output: dead ``` ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,683,0.13439568877220154,0,"Fixed CI Bug for GitHub actions"
https://api.github.com/repos/PyThaiNLP/pythainlp,682,-0.06048059090971947,0,"### What does this changes Add live-dead syllable classification. ## Example ```python from pythainlp.util import sound_syllable print(sound_syllable(""มา"")) # output: live print(sound_syllable(""เลข"")) # output: dead ``` ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,679,-0.5350260734558105,-1,"Add mt5 cpe kmutt thai sentence sum Model: https://huggingface.co/thanathorn/mt5-cpe-kmutt-thai-sentence-sum"
https://api.github.com/repos/PyThaiNLP/pythainlp,674,-0.023922149091959,0,"### What does this changes add gpu option on translate module "
https://api.github.com/repos/PyThaiNLP/pythainlp,673,0.12485247850418091,0,"### What does this change do? Add a normalising rule for Lakkhangyao `ๅ` According to [this](https://th.wikipedia.org/wiki/%E0%B8%A5%E0%B8%B2%E0%B8%81%E0%B8%82%E0%B9%89%E0%B8%B2%E0%B8%87), it should only follow, `ฤ` and `ฦ`. Apart from that it should be normalised to `า`. ### How this fixes it Add the following regex in reorder_vowels function ``` (""([^\u0e24\u0e26])\u0e45"", ""\\1\u0e32""),  # Lakkhangyao -> Sara Aa ``` ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [/] Passed code styles and structures - [/] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,672,-0.14341001212596893,0,"Update dev branche from pythainlp-3.0 branche"
https://api.github.com/repos/PyThaiNLP/pythainlp,671,0.4488081932067871,0,"@kmining found that this patch in PyThaiNLP 3.0.6 doesn't complete. I rewrite to fix and I was add there sentence to unittest for nercut. I hope this pull request will complete fix the problem. This pull request has fix #666 and PyThaiNLP v3.0.8. Issue: #666 "
https://api.github.com/repos/PyThaiNLP/pythainlp,670,-0.006249641068279743,0,"`PyThaiNLP v3.0.7` is This release is a bug fix release of `PyThaiNLP 3.0.5`. **Bug Fixed** - Fixed nercut bug. #666 Thank you @kmining for your bug report. You can install by `pip install pythainlp` or upgrade by `pip install -U pythainlp`. Documentation: https://pythainlp.github.io/docs/3.0/index.html Report bug: https://github.com/PyThaiNLP/pythainlp/issues See [PyThaiNLP 3.0 change log#545](https://github.com/PyThaiNLP/pythainlp/issues/545) ## Contributors <a href=""https://github.com/PyThaiNLP/pythainlp/graphs/contributors"">   <img src=""https://contributors-img.firebaseapp.com/image?repo=PyThaiNLP/pythainlp"" /> </a> Thanks all the [contributors](https://github.com/PyThaiNLP/pythainlp/graphs/contributors). (Image made with [contributors-img](https://contributors-img.firebaseapp.com)) "
https://api.github.com/repos/PyThaiNLP/pythainlp,669,-0.33750927448272705,0,"- Fixed #666"
https://api.github.com/repos/PyThaiNLP/pythainlp,668,-0.20732644200325012,0,"Update dev base from 3.0 base - Fixed #666"
https://api.github.com/repos/PyThaiNLP/pythainlp,667,0.0646296888589859,0,"Fixed missing any rule ### What does this changes Add any rule for store the result. ### What was wrong It doesn't store if it is in last index. ### How this fixes it Add rule for checking last index and store the result. Fixes #666 ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,665,-0.2654806971549988,0,"### What does this changes This pull request include thai-nner to PyThaiNLP. It is `pythainlp.tag.NNER` class. It was use `thai_nner` library and include model by pythainlp-corpus. This issue is #664. Thai-NNER: https://github.com/vistec-AI/Thai-NNER ```python from pythainlp.tag.named_entity import NNER nner = NNER() nner.tag(""แมวทำอะไรตอนห้าโมงเช้า"") # output: (['<s>', '', 'แมว', 'ทํา', '', 'อะไร', 'ตอน', '', 'ห้า', '', 'โมง', '', 'เช้า', '</s>'], # [{'text': ['', 'ห้า'], 'span': [7, 9], 'entity_type': 'cardinal'}, {'text': ['', 'ห้า', '', 'โมง'], 'span': [7, 11], 'entity_type': 'time'}, {'text': ['', 'โมง'], 'span': [9, 11], 'entity_type': 'unit'}]) ``` ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,660,-0.2801709473133087,0,"### What does this changes Update Thai W2P  model to v0.2 and PyThaiNLP v3.0.6dev0 Thai W2P v0.2: https://github.com/wannaphong/Thai_W2P/releases/tag/v0.2"
https://api.github.com/repos/PyThaiNLP/pythainlp,659,-0.23434194922447205,0,"I write ISO 11940 (or ISO 11940-1) transliterate function. ISO 11940 by Wikipedia: [https://en.wikipedia.org/wiki/ISO_11940](https://en.wikipedia.org/wiki/ISO_11940) ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,658,0.21130169928073883,0,"I port LST20NER model to onnx model from fine-turning by [WangchanBERTa model](https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased).  ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,657,-0.34662553668022156,0,"Update from dev"
https://api.github.com/repos/PyThaiNLP/pythainlp,656,0.010100494138896465,0,"### What does this changes I add support zip/tar.gz to download corpus. Now, We can use zip/tar.gz to packing model file and auto extract file. ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,654,-0.2179001420736313,0,"Update `3.0` branche from `dev` branche"
https://api.github.com/repos/PyThaiNLP/pythainlp,653,-0.17803673446178436,0,"from https://www.orst.go.th/iwfm_list.asp?n=g&i=0020000402001002%2F65BPM3129003, I add more words from Royal Society."
https://api.github.com/repos/PyThaiNLP/pythainlp,648,0.11120881140232086,0,"`PyThaiNLP v3.0.1` is This release is a bug fix release of `PyThaiNLP 3.0`. **Bug Fixed** - Remove warning message in pythainlp.tag.thainer. Fixed #644 - Add PYTHAINLP_READ_MODE environment variable is config PyThaiNLP to read-only mode. Fixed #645 You can install by `pip install pythainlp` or upgrade by `pip install -U pythainlp`. Documentation: https://pythainlp.github.io/docs/3.0/index.html Report bug: https://github.com/PyThaiNLP/pythainlp/issues See [PyThaiNLP 3.0 change log#545](https://github.com/PyThaiNLP/pythainlp/issues/545) ## Contributors <a href=""https://github.com/PyThaiNLP/pythainlp/graphs/contributors"">   <img src=""https://contributors-img.firebaseapp.com/image?repo=PyThaiNLP/pythainlp"" /> </a> Thanks all the [contributors](https://github.com/PyThaiNLP/pythainlp/graphs/contributors). (Image made with [contributors-img](https://contributors-img.firebaseapp.com))"
https://api.github.com/repos/PyThaiNLP/pythainlp,647,0.17951558530330658,0,"From #644, I removed warning message in `pythainlp.tag.thainer`. Fixes #644 ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [X] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,646,0.04244809225201607,0,"Add `PYTHAINLP_READ_MODE` environment variable is config PyThaiNLP to read-only mode. Fixed #645 "
https://api.github.com/repos/PyThaiNLP/pythainlp,642,0.3075232207775116,0,"After a long time of the development of PyThaiNLP 3.0, We released `PyThaiNLP 3.0`. `PyThaiNLP 3.0` has many improvements and new features to help with Thai language processing tasks. You can install by `pip install pythainlp` or upgrade by `pip install -U pythainlp`. Documentation: https://pythainlp.github.io/docs/3.0/index.html Report bug: https://github.com/PyThaiNLP/pythainlp/issues See [PyThaiNLP 3.0 change log#545](https://github.com/PyThaiNLP/pythainlp/issues/545) If you want to contribute to PyThaiNLP, you can read [Contributing to PyThaiNLP](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md). ## News > Since PyThaiNLP 3.0, We will end supporting PyThaiNLP on Python 3.6. Python 3.6 users can use PyThaiNLP 2.3.2. > We have updated the Thai word dictionary & rule for newmm. We recommend retraining your model if you use newmm for word tokenization in your model. ## What is new? ### Deprecation and other API changes - Deprecated syllable_tokenize. `syllable_tokenize` is deprecated, use `subword_tokenize` instead - `pythainlp.tag.named_entity.ThaiNameTagger` is change to `pythainlp.tag.thainer.ThaiNameTagger`. This old class will be deprecated in PyThaiNLP version 3.1. ### Augment - Add Thai Text Augmentation ### Corpus - Fix lots of misspellings in the dictionary (words_th.txt) - Add get_corpus_default_db and thainer 1.5 model. You can add corpus on `default_db.json`, and you don't load the last trainer model from the Internet. ### Tag - Add TLTK (pos_tag and ner) - add TLTK wrapper to pythainlp functions ex ner, word_tokenize and more. - Add NER class - `NER` class for Named-entity recognizer tasks. ### Translate - Add `pythainlp.translate.Translate` Class - Add Chinese-Thai Machine Translation - Add Thai-French Machine Translation ### Tokenization - Tokenize repeating dots and commas from numbers - Fix token_max_len bug that makes it always zero - Tokenize repeating dots and commas from numbers (fix #461) - Retrained sentenceseg_crfcut.model for PyThaiNLP 2.4 - Add SEFR CUT to pythainlp - Add TLTK (sentence_tokenize and word_tokenize) - add TLTK wrapper to pythainlp functions ex ner, word_tokenize, and more. - Add nlpo3 ### Transliterate - Refactor Royin Transliterate: Avoid embedded if blocks and simplified consonant replacing operations - Manually merge update-royin branch with dev branch to add O-ANG rule - Add TLTK (g2p and ipa) - add TLTK wrapper to pythainlp functions ex ner, word_tokenize, and more. - Add pythainlp.transliterate.puan ### Word Vector - Fix token_max_len bug that makes it always zero - Add `pythainlp.word_vector.WordVector` ### Spell - Add more spelling engine - Add TLTK (spell) - add TLTK wrapper to pythainlp functions ex ner, word_tokenize, and more. ### Generate - Add pythainlp.generate to generate a text. ### Tool - Add misspell module ### Other - Add TLTK - add TLTK wrapper to pythainlp functions ex ner, word_tokenize, and more. - Update requirements from ssg 0.0.6 to ssg 0.0.8  -  Spoonerism: Add supports words more three syllables -  Add maiyamok; This function is preprocessing MaiYaMok in a Thai sentence. ## Contributors <a href=""https://github.com/PyThaiNLP/pythainlp/graphs/contributors"">   <img src=""https://contributors-img.firebaseapp.com/image?repo=PyThaiNLP/pythainlp"" /> </a> Thanks all the [contributors](https://github.com/PyThaiNLP/pythainlp/graphs/contributors). (Image made with [contributors-img](https://contributors-img.firebaseapp.com)) If you want to contributing to PyThaiNLP, you can read [Contributing to PyThaiNLP](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md). > This year is the 6th year's PyThaiNLP, and PyThaiNLP has more than one million downloads. I started to develop PyThaiNLP to help me do Thai language processing tasks. Now, PyThaiNLP has been used in many research and works worldwide. PyThaiNLP can't be grown if it doesn't have contributors, sponsors, and users. > > Thank you for all supporting. > > Thank you for using PyThaiNLP. Wannaphong Phatthiyaphaibun PyThaiNLP Founder 27 January 2022"
https://api.github.com/repos/PyThaiNLP/pythainlp,640,-0.06549087166786194,0,"Start PyThaiNLP v3.0.0-beta0"
https://api.github.com/repos/PyThaiNLP/pythainlp,635,-0.22341081500053406,0,"### What does this changes Add Thai-French Machine Translation Trained by OPUS Corpus Model from Language Technology Research Group at the University of Helsinki BLEU 20.4 - GitHub: https://github.com/Helsinki-NLP/OPUS-MT-train/tree/master/models/th-fr - Huggingface https://huggingface.co/Helsinki-NLP/opus-mt-th-fr ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,634,0.08631608635187149,0,"### What does this changes Add new Thai words from Thai Royal Society & cryptocurrency"
https://api.github.com/repos/PyThaiNLP/pythainlp,631,-0.24639897048473358,0,"### What does this changes Spoonerism: Add supports words more 3 syllables ### What was wrong From https://web.facebook.com/groups/thainlp/posts/1455899381458214/, I get feedback about rule for words more 3 syllables to spoonerism. Now, It's finish code. ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,630,0.10669628530740738,0,"### What does this changes Upgrade to nlpo3-python v1.2.2 to fix issue when using a dictionary file with blank lines. See https://github.com/PyThaiNLP/nlpo3/issues/51 ### What was wrong Trim function was previously unable to handle a string with only whitespaces. This makes an error when it got a string with only one ""newline"" char in it (from a blank line in a text file). ### How this fixes it Update to nlpo3-python 1.2.2 where it already got fixed. See https://github.com/PyThaiNLP/nlpo3/pull/54 ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [ ] Passed code styles and structures - [ ] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,628,-0.06056680157780647,0,"### What does this changes Delete python-crfsuite from requirements ### What was wrong From  #626, I delete python-crfsuite from requirements. ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,624,-0.20436476171016693,0,"Add pythainlp.transliterate.puan #620 ![ภาพ](https://user-images.githubusercontent.com/8536487/140553387-4cb9bc31-897c-4ada-a754-81336ecb15c4.png) ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,623,-0.4754478633403778,0,"### What does this changes MaiYaMok (ๆ) is the mark of duplicate word in Thai language. This function is preprocessing MaiYaMok in Thai sentence. ```python from pythainlp.util import maiyamok maiyamok(""เด็กๆชอบไปโรงเรียน"") # output: ['เด็ก', 'เด็ก', 'ชอบ', 'ไป', 'โรงเรียน'] maiyamok([""ทำไม"",""คน"",""ดี"","" "",""ๆ"",""ๆ"","" "",""ถึง"",""ทำ"",""ไม่ได้""]) # output: ['ทำไม', 'คน', 'ดี', 'ดี', 'ดี', ' ', 'ถึง', 'ทำ', 'ไม่ได้'] ``` original code from https://web.facebook.com/groups/thainlp/posts/663608874020606/ ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,622,0.05511865392327309,0,"### What does this changes Add nlpo3 to part of `word_tokenize` function. ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,619,1.2987346649169922,1,"Hi there and thanks for using pyup.io! Since you are using a non-default config I've created one for you. There are a lot of things you can configure on top of that, so make sure to check out the [docs](https://pyup.io/docs/configuration/) to see what I can do for you."
https://api.github.com/repos/PyThaiNLP/pythainlp,614,0.034360118210315704,0,"### What does this changes This PR implements #549  Note for self: - To run the test:  `pytest  ./tests/test_misspell.py` - implement an command line to produce a misspelled version of a file (line by line) - using the command line to generate multiple files with different datasets and see how word segmentations performance are. ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,610,-0.10573635250329971,0,"`PyThaiNLP v2.3.2` is This release is a bug fix release of PyThaiNLP 2.3. **Bug Fixed** - Fixed clause_tokenize returns an empty list. #609 Documentation: [https://pythainlp.github.io/docs/2.3/index.html](https://pythainlp.github.io/docs/2.3/index.html ) Report bug: [https://github.com/PyThaiNLP/pythainlp/issues](https://github.com/PyThaiNLP/pythainlp/issues) You can install or upgrade using *pip install -U pythainlp* See [PyThaiNLP 2.3 change log](https://github.com/PyThaiNLP/pythainlp/issues/445) #445"
https://api.github.com/repos/PyThaiNLP/pythainlp,608,0.2779048681259155,0,"### What does this changes Start PyThaiNLP 3.0.0-dev0 from #605 #604 #545 ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,607,0.06377184391021729,0,"### What does this changes Add OSKut to word_tokenize engine OSKut: https://github.com/mrpeerat/OSKut ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,603,-0.03393006697297096,0,"### What does this changes I retrain a thai postag model from Parallel Universal Dependencies (PUD) treebanks because It has update and The old model was 3 years old. Parallel Universal Dependencies (PUD) treebanks (Thai): https://github.com/UniversalDependencies/UD_Thai-PUD Notebook for retrained: https://github.com/PyThaiNLP/pythainlp_notebook/blob/master/postag/train_ud_thai_pud_pythainlp-v0.2.ipynb ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,602,-0.14054222404956818,0,"Update add-ner-class from dev"
https://api.github.com/repos/PyThaiNLP/pythainlp,600,0.22210575640201569,0,"### What does this changes Add NER class for Named-entity recognizer ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/PyThaiNLP/pythainlp,599,-0.05161480978131294,0,"### What does this changes Add tltk engine to pythainlp ### What was wrong Add tltk engine ### Function - [x] Sentence tokenizer - [x] word segment - [x] syllable_tokenize - [x] romanize - [x] tltk_g2p - Thai Grapheme-to-Phoneme - [x] tltk_ipa - tltk, output is International Phonetic Alphabet (IPA) - [x] pos_tag - [x] spell - [x] ner TLTK Homepage: https://pypi.org/project/tltk/ ### Your checklist for this pull request 🚨Please review the [guidelines for contributing](https://github.com/PyThaiNLP/pythainlp/blob/dev/CONTRIBUTING.md) to this repository. - [x] Passed code styles and structures - [x] Passed code linting checks and unit test "
https://api.github.com/repos/cloudfoundry/python-buildpack,718,-1.2039240598678589,-1,"None"
https://api.github.com/repos/cloudfoundry/python-buildpack,715,0.012295174412429333,0,"Release to include `github.com/Dynatrace/libbuildpack-dynatrace` bumps "
https://api.github.com/repos/cloudfoundry/python-buildpack,706,0.3319671154022217,0," * [x] I have viewed signed and have submitted the Contributor License Agreement * [x] I have made this pull request to the `develop` branch * [ ] I have added an integration test "
https://api.github.com/repos/cloudfoundry/python-buildpack,703,0.28861576318740845,0,"Slight difference in naming between the directories in the python 3.7 dependency vs other versions (3.7 has a dir named `include/python3.7m` vs `include/python3.x`) results in build failures when using `pip` dependencies which rely on `CFLAGS` being set. These changes allow the buildpack to account for that difference when setting `CFLAGS`. * [x] I have viewed signed and have submitted the Contributor License Agreement * [x] I have made this pull request to the `develop` branch * [ ] I have added an integration test "
https://api.github.com/repos/cloudfoundry/python-buildpack,701,-0.2623119056224823,0,"Bump github.com/Dynatrace/libbuildpack-dynatrace to v1.5.2 https://github.com/Dynatrace/libbuildpack-dynatrace/releases/tag/v1.5.2"
https://api.github.com/repos/cloudfoundry/python-buildpack,695,-1.2039240598678589,-1,"None"
https://api.github.com/repos/cloudfoundry/python-buildpack,694,-0.471179336309433,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,693,-1.2039240598678589,-1,"None"
https://api.github.com/repos/cloudfoundry/python-buildpack,691,-0.471179336309433,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,690,-1.2039240598678589,-1,"None"
https://api.github.com/repos/cloudfoundry/python-buildpack,689,-0.471179336309433,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,688,-0.471179336309433,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,684,-0.08893169462680817,0,"# Changes - Revert the change until Go Buildpack (cflinuxfs4) is available on cf environments. - Update integration tests to reflect the changes introduced in #638 when an app is not fully vendored."
https://api.github.com/repos/cloudfoundry/python-buildpack,683,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,682,1.046591877937317,1,"Thanks for contributing to the buildpack. To speed up the process of reviewing your pull request please provide us with: * A short explanation of the proposed change: * An explanation of the use cases your change solves * [x] I have viewed signed and have submitted the Contributor License Agreement * [x] I have made this pull request to the `develop` branch * [x] I have added an integration test "
https://api.github.com/repos/cloudfoundry/python-buildpack,680,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,672,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,669,0.31066152453422546,0,"* [x] I have viewed signed and have submitted the Contributor License Agreement * [x] I have made this pull request to the `develop` branch "
https://api.github.com/repos/cloudfoundry/python-buildpack,667,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,665,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,664,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,663,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,660,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,659,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,658,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,656,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,652,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,650,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,647,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,646,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,645,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,643,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,642,0.47842854261398315,0,"This helps with debugging * [x] I have viewed signed and have submitted the Contributor License Agreement * [x] I have made this pull request to the `develop` branch * [ ] I have added an integration test "
https://api.github.com/repos/cloudfoundry/python-buildpack,641,-0.42873790860176086,0,"Previously done in https://github.com/cloudfoundry/python-buildpack/commit/26a4729ffda0f1d6c3081fd269d1c7f391be6179 Co-authored-by: Arjun Sreedharan <asreedharan@vmware.com>"
https://api.github.com/repos/cloudfoundry/python-buildpack,639,0.8688610196113586,1,"To be able to debug problems when using pip it's handy to know which version of pip is actually being used Thanks for contributing to the buildpack. To speed up the process of reviewing your pull request please provide us with: * [x] I have viewed signed and have submitted the Contributor License Agreement * [x] I have made this pull request to the `develop` branch * [x] I have added an integration test (I've updated the existing ones) "
https://api.github.com/repos/cloudfoundry/python-buildpack,638,-0.562330961227417,-1,"Falling back to unvendored installs is an anti-feature. In general this is the tool saying ""I know you have explicitly requested to do X, but now that this has failed I will do the exact opposite of what you requested"". In general, when a user explicitly requests X and this fails the correct course of action is to provide an error message. Specifically: * When vendored installs fail, unvendored installs will often also fail, but   may fail for different reasons. Example: build dependencies may not be available in the buildpack. This sends the user off on a wild goose chase (fixing the second problem, rather than the original one) * When unvendored installs will in fact not fail (i.e. the intention of the now-removed code) the user's expectation that whatever is in the ""vendor"" directory is what's actually installed is violated. This violates reproducability of installs, and opens a can of worms security-wise (e.g. the vendored packages may have been scanned previously, whereas arbitrary downloads are generally not). History: The anti-feature was introduced in https://github.com/cloudfoundry/python-buildpack/commit/518f933f15deb7bf8973796ea0dac54f36250b14, without providing reasoning why this is desirable. * [x] I have viewed signed and have submitted the Contributor License Agreement * [x] I have made this pull request to the `develop` branch * [ ] I have added an integration test "
https://api.github.com/repos/cloudfoundry/python-buildpack,637,0.8991917371749878,1,"Thanks for contributing to the buildpack. To speed up the process of reviewing your pull request please provide us with: * A short explanation of the proposed change: This makes debugging easier. Vendored and unvendored installs are not the same, so they should not show up the same way in the logs. * [x] I have viewed signed and have submitted the Contributor License Agreement * [x] I have made this pull request to the `develop` branch * [ ] I have added an integration test "
https://api.github.com/repos/cloudfoundry/python-buildpack,636,-1.2039240598678589,-1,"None"
https://api.github.com/repos/cloudfoundry/python-buildpack,635,-1.2039240598678589,-1,"None"
https://api.github.com/repos/cloudfoundry/python-buildpack,634,-1.2039240598678589,-1,"None"
https://api.github.com/repos/cloudfoundry/python-buildpack,632,-0.47117945551872253,0,"This is default description of the PR"
https://api.github.com/repos/cloudfoundry/python-buildpack,631,-1.2039240598678589,-1,"None"
https://api.github.com/repos/cloudfoundry/python-buildpack,630,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/cloudfoundry/python-buildpack,629,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/cloudfoundry/python-buildpack,628,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/cloudfoundry/python-buildpack,627,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/cloudfoundry/python-buildpack,626,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/cloudfoundry/python-buildpack,625,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/cloudfoundry/python-buildpack,624,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/cloudfoundry/python-buildpack,623,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/cloudfoundry/python-buildpack,621,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/cloudfoundry/python-buildpack,619,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/cloudfoundry/python-buildpack,618,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/cloudfoundry/python-buildpack,617,-1.2039240598678589,-1,"None"
https://api.github.com/repos/cloudfoundry/python-buildpack,616,-1.2039240598678589,-1,"None"
https://api.github.com/repos/cloudfoundry/python-buildpack,614,-1.2039240598678589,-1,"None"
https://api.github.com/repos/cloudfoundry/python-buildpack,613,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/cloudfoundry/python-buildpack,611,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/cloudfoundry/python-buildpack,610,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/cloudfoundry/python-buildpack,609,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/cloudfoundry/python-buildpack,608,-1.2039240598678589,-1,"None"
https://api.github.com/repos/cloudfoundry/python-buildpack,607,0.1426142007112503,0,"This PR is made automatically by release engineering bot. [#181074448]"
https://api.github.com/repos/StellarCN/py-stellar-base,705,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,703,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,702,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,698,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,688,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,670,-0.10885448008775711,0,"see https://github.com/stellar/stellar-protocol/pull/1324"
https://api.github.com/repos/StellarCN/py-stellar-base,669,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,668,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,667,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,665,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,664,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,662,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,649,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,648,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,638,-0.24253533780574799,0,"```python import time from stellar_sdk import * from stellar_sdk import xdr as stellar_xdr from stellar_sdk.soroban import SorobanServer kp1 = Keypair.from_secret(""SAAPYAPTTRZMCUZFPG3G66V4ZMHTK4TWA6NS7U4F7Z3IMUD52EK4DDEV"") soroban_server = SorobanServer(""http://127.0.0.1:8000/soroban/rpc"") acc = soroban_server.get_account(kp1.public_key) source = Account(kp1.public_key, acc.sequence) op1 = InvokeHostFunction(     contract_id=""ca08ea2c19bd47d9e04de0cc86e1440866f6c7f8634095872c38000e1a7cbcd9"",     method=""hello"",     params=[stellar_xdr.SCVal(type=stellar_xdr.SCValType.SCV_SYMBOL,                               sym=stellar_xdr.SCSymbol(sc_symbol=""world"".encode('utf-8')))],     footprint=stellar_xdr.LedgerFootprint([], []),     source=kp1.public_key ) tx1 = TransactionBuilder(source, network_passphrase='Standalone Network ; February 2017').set_timeout(     300).append_operation(op1).build() data1 = soroban_server.simulate_transaction(tx1) print(data1) fp = stellar_xdr.LedgerFootprint.from_xdr(data1.footprint) print('-' * 32) source.sequence -= 1  # build transaction increments sequence op2 = InvokeHostFunction(     contract_id=""ca08ea2c19bd47d9e04de0cc86e1440866f6c7f8634095872c38000e1a7cbcd9"",     method=""hello"",     params=[stellar_xdr.SCVal(type=stellar_xdr.SCValType.SCV_SYMBOL,                               sym=stellar_xdr.SCSymbol(sc_symbol=""world"".encode('utf-8')))],     footprint=fp,     source=kp1.public_key ) tx2 = TransactionBuilder(source, network_passphrase='Standalone Network ; February 2017').set_timeout(     300).append_operation(op2).build() tx2.sign(kp1) print(tx2.to_xdr()) print('-' * 32) data2 = soroban_server.send_transaction(tx2) print(tx2.transaction.sequence) print(data2) print('-' * 32) time.sleep(5) data3 = soroban_server.get_transaction_status(data2.id) print(data3) print('-' * 32) contract_id = '14f87b7e89361a6dd159f71726cd1eb14422995f7bdd57b5885ba446c6ae7de7' key = stellar_xdr.SCVal(type=stellar_xdr.SCValType.SCV_SYMBOL,                         sym=stellar_xdr.SCSymbol(sc_symbol=""COUNTER"".encode('utf-8'))) data4 = soroban_server.get_contract_data(contract_id, key) print(data4) counter = stellar_xdr.SCVal.from_xdr(data4.xdr).u32.uint32 print(f""COUNTER: {counter}"") ```"
https://api.github.com/repos/StellarCN/py-stellar-base,637,-0.6424803137779236,-1,"#603 "
https://api.github.com/repos/StellarCN/py-stellar-base,630,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,620,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,611,-0.04884405806660652,0,"fix #610"
https://api.github.com/repos/StellarCN/py-stellar-base,601,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,600,-0.2821829915046692,0,"Opening a new PR as #599 was accidentally closed. This one also includes the requested change in 599 before it was closed. @overcat "
https://api.github.com/repos/StellarCN/py-stellar-base,597,0.3820088505744934,0,"The following functions are affected: - `PayStellarUri.__init__` - `Server.strict_receive_paths` - `Server.strict_send_paths` - `AsyncServer.strict_receive_paths` - `AsyncServer.strict_send_paths` #596  #594 "
https://api.github.com/repos/StellarCN/py-stellar-base,595,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,592,-1.203924536705017,-1,"None"
https://api.github.com/repos/StellarCN/py-stellar-base,591,-0.019826579838991165,0,"There are some endpoints where if the cursor is set to now the program will never receive new messages. ex. https://horizon.stellar.org/accounts/{account_id}/offers"
https://api.github.com/repos/StellarCN/py-stellar-base,590,-1.203924536705017,-1,"None"
https://api.github.com/repos/openlawlibrary/pygls,321,0.28950202465057373,0,"Hi! We just finished the migration to v1.0.0, so I thought it would be useful for others to include it into known migrations docs :) .  PS: I hope I got the .rst syntax right ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [/] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [x] Standalone docs have been updated accordingly - [/] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [/] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,319,-1.203924536705017,-1,"None"
https://api.github.com/repos/openlawlibrary/pygls,318,0.017085742205381393,0,"Fixes #270 (again) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [/] Tests have been included and/or updated, as appropriate - [/] Docstrings have been included and/or updated, as appropriate - [/] Standalone docs have been updated accordingly - [/] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,316,-1.203924536705017,-1,"None"
https://api.github.com/repos/openlawlibrary/pygls,315,-0.043925728648900986,0,"This started in https://github.com/openlawlibrary/pygls/issues/305 Highlights: * [Quickstart example in README](https://github.com/openlawlibrary/pygls/tree/update-example-server/README.md) is simpler and more intuitive, in my opinion. * [Quickstart example is included in the examples folder](https://github.com/openlawlibrary/pygls/tree/update-example-server/examples/hello-world) with configs for _more than just VSCode_. * Existing examples have had ""vscode"" added to their folder names. * README now contains an [Alternatives](https://github.com/openlawlibrary/pygls/blob/update-example-server/README.md#alternatives) section. * A [HISTORY.md](https://github.com/openlawlibrary/pygls/blob/update-example-server/HISTORY.md) file has been added that relates the inception of Pygls. * Some folder structure changes. Most notable `pyodide_testrunner` is under tests now.  - [ ] This will also complete all the issues in https://github.com/openlawlibrary/pygls/issues/281 ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [/] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [/] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [/] Changelog has been updated, as needed (see [CHANGELOG.md][changelog])"
https://api.github.com/repos/openlawlibrary/pygls,314,-0.0005947509780526161,0,"I've update the [Implementations.md](https://github.com/openlawlibrary/pygls/blob/add-microsoft-implementations/Implementations.md) file with Micorsoft's extensions, and Ruff too. Relates to #281  And added a thank you in the README to our first sponsor.   ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,310,0.0038573769852519035,0,"## Description (e.g. ""Related to ..."", etc.) It turns out the `workspace/configuration` request requires a `WorkspaceConfigurationParams` object, rather than a plain `ConfigurationParams` object.  This PR - Fixes the `AttributeErrors` seen in the various `get_configuration_xxx` commands in the example json extension, as well as adding test cases to cover them going forward.   - Fixes the type annotations in the various `get_configuration_xxx` methods in the pygls codebase - Updates the documentation to match Fixes #307  ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [/] Docstrings have been included and/or updated, as appropriate - [/] Standalone docs have been updated accordingly - [/] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,309,0.05197164788842201,0,"## Description (e.g. ""Related to ..."", etc.) Add Helios to example implementations ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,308,0.00029247161000967026,0,"## Description (e.g. ""Related to ..."", etc.) _Please replace this description with a concise description of this Pull Request._ ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [x] Standalone docs have been updated accordingly - [x] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,303,0.06752048432826996,0,"Fixes #211 Includes deprecation warning for old method signature I don't know if I'm being too clever here? Also, does anybody know why there are often 2 public methods to do the same thing like this? Therefore, we can call both `pygls.server.LanguageServer.publish_diagnostics` and `pygls.protocol.LanguageServerProtocol.publish_diagnostics`. I assume it's because `pygls.server.LanguageServer` is the more friendly user-facing class, whilst `pygls.protocol.LanguageServerProtocol` is internal and has to be comprehensive. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,301,0.013793285004794598,0,"## Description (e.g. ""Related to ..."", etc.) Fixes the code example in the README ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,299,0.03215363249182701,0,"## Description (e.g. ""Related to ..."", etc.) Fix missing links in changelog ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,298,0.4223688244819641,0,"A handful of type-checking fixes. There's lots more that could be done - try `mypy --strict pygls` if you want to see.  But this covers enough of the public API that typechecking from jedi-language-server is happy."
https://api.github.com/repos/openlawlibrary/pygls,297,-0.19333498179912567,0,"Little fixes for v1 migration page. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,295,-0.07870253920555115,0,"## Description (e.g. ""Related to ..."", etc.) I think in #274  we said we wanted to make the `name` and `version` arguments to a `LanguageServer` object mandatory? This PR removes the warning and default arguments meaning they now have to be provided by the language server author. ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [x] Standalone docs have been updated accordingly - [x] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,294,0.17424936592578888,0,"Add doc/README updates to recommend the v1 alpha release for new projects. This came up in #293 where a missing feature was identified in the current release, but is fixed in the v1 alpha release. Whereas we're only _probably_ ready to release v1, we're _definitely_ ready to recommend it for new projects.  Missing feature notes: Strictly, Pygls only currently supports LSP v3.15, but this feature was added in 3.17. Ideally we wouldn't mix and match features from different versions. Ideally we should wholesale support a version. Anyway, we're soon to release a breaking change version of Pygls that follows Microsofts own Python LSP types #273. Fixes #293 ## Description (e.g. ""Related to ..."", etc.) _Please replace this description with a concise description of this Pull Request._ ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [x] Standalone docs have been updated accordingly - [x] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,290,-0.17841066420078278,0,"## Description (e.g. ""Related to ..."", etc.) **This is for the unreleased 1.0 branch** - Update main CI workflow to test on the released version of Python 3.11 - Update version of Pyodide used in tests to latest release - Update glue code in example fountain extension to align with changes on the 1.0 branch ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,289,-0.03104935586452484,0,"## Description (e.g. ""Related to ..."", etc.) Here's an initial attempt at a migration guide for the 1.0 branch. - The table of renamed types and constants was manually generated so I may have missed some and there could be errors.   There's a also a few types I couldn't find obvious replacements for (I probably didn't look hard enough) so some help reviewing this table in particular would be appreciated :slightly_smiling_face:  - Have I missed anything obvious? ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,288,0.02448771893978119,0,"## Description (e.g. ""Related to ..."", etc.) This fixes the construction of the `workspace.fileOperations` fields of the server's capabilities by passing through the `FileOperationRegistrationOptions` provided when registering features like `WORKSPACE_DID_DELETE_FILES` This also resolves [the issue](https://github.com/openlawlibrary/pygls/pull/273#issuecomment-1301546322) I was having with the runtime type checking of the given options  Closes #278  ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,287,-0.027781549841165543,0,"## Description - The `mypy` issues identified by @dimbleby should now be resolved - By replacing the `attrs.field()` definitions in the `JsonRPCXXX` type definitions with structure hooks, custom messages should no longer be corrupted, while still retaining the existing `dict_to_object` behavior. Closes #285  - The module level `converter` in `pygls/protocol.py` has been replaced with one attached to the `JsonRPCProtocol` object's instance which can now be overriden by passing a  custom `converter_factory` to the `Server` object's constructor. Closes #286  ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [/] Standalone docs have been updated accordingly - [/] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [/] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,284,-0.1976642608642578,0,"A minor version bump here, because there are 2 behaviour changes, namely more error messages being sent to the client, and a warning log line if `LanguageServer(""my-server-name"", ""0.0.1"")` is instantiated without the server name and version. Added: - Add `name` and `version` arguments to the constructor of `LanguageServer` ([#274]) [#274]: https://github.com/openlawlibrary/pygls/issues/274 Changed: - Default behaviour change: uncaught errors are now sent as `showMessage` errors to client. Overrideable in `LanguageServer.report_server_error()`: https://github.com/openlawlibrary/pygls/pull/282 Fixed: - `_data_recevied()` JSONRPC message parsing errors now caught - Fix ""Task attached to a different loop"" error in `Server.start_ws` ([#268]) "
https://api.github.com/repos/openlawlibrary/pygls,282,0.04097267612814903,0,"This includes a notable, perhaps even controversial, behaviour change: All errors other than LSP requests are now sent to the client as `showMessage.type = MessageType.Error` messages. This may result in existing custom LSP servers showing errors that were not seen before, these aren't new errors, just previously undisplayed errors. Another advantage to this is that it is now easier to test error handling. When running end to end tests, all errors are now accessible in the client. Also, `JsonRPCProtocol.data_receieved()` now catches unhandled errors. Fixes #277. - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [x] Standalone docs have been updated accordingly - [x] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,280,-0.02860787883400917,0,"## Description (e.g. ""Related to ..."", etc.) Currently the restriction on pydantic does not allow us select a single version that works for python 3.7-3.11. This PR removes the upper bound on python version <3.11. This allows pygls to select a single version of pydantic that works on all python versions. ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [x] Standalone docs have been updated accordingly - [x] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,279,0.19680435955524445,0,"This finally gives us Python 3.11 support. See #234 for more discussion. - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [x] Standalone docs have been updated accordingly ~~- [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate~~ - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog])"
https://api.github.com/repos/openlawlibrary/pygls,276,-0.005171653814613819,0,"These are sent as serverInfo in InitializeResult Close #274 ## Description (e.g. ""Related to ..."", etc.) Although we discussed the possibility of mandating these arguments in #274, this PR does not make the new `name` and `version` arguments of the constructor of class `LanguageServer` mandatory.  So, it can be merged to the current master before the release of v1.0.0. When the name is not set, the server still sends the serverInfo as null.  I'm not sure that's the right thing to do.  I can update the code to omit the serverInfo field altogether in this case.  What do you think? ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [x] Standalone docs have been updated accordingly - [x] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,273,0.3807935416698456,0,"With huge thanks and kudos to [Esbonio](https://github.com/swyddfa/esbonio)'s @alcarney and Microsoft's @karthiknadig we now have a pre release version of Pygls that migrates away from Pydantic and to [lsprotocol](https://github.com/microsoft/lsprotocol). ⚠ This involves breaking changes. Existing projects depending on Pygls will need to update their code. Testers are welcome. You can try it by explicitly setting your dependency to `pygls=1.0.0a2`. The migration guide is at: [docs/pages/migrating-to-v1.rst](https://github.com/openlawlibrary/pygls/blob/v1-lsprotocol-breaking-alpha/docs/source/pages/migrating-to-v1.rst) `lsprotocol` is mostly just a module that officially and comprehensively defines the data structures and types that make up the LSP specification. Therefore, what it offers are upstream (from Microsoft, the creators of LSP) guarantees on adherence to the formal behaviour and expectations of the specification.  TODO: * [x] ~~Write~~ Publish guide on how to make the required changes. * [x] Isolate a commit in a sample LSP server project that demonstrates the changes. Eg; [jedi-language-server already has a PR](https://github.com/pappasam/jedi-language-server/pull/230/commits). Or maybe make a verbose commit in the new [""Pygls Starter project""](https://github.com/tombh/cli-tools-lsp) I'm working on. * [x] Get feedback from people that have successfully made the migration:   * https://github.com/pappasam/jedi-language-server/pull/230.   * https://github.com/charliermarsh/vscode-ruff/pull/37 * [x] @alcarney what else would you like to see happen before the final release? * [x] Remove advice to start new projects with v1 alpha This may also be a good opportunity to introduce other breaking changes, such as in #274 Notes: * Issues that this release should either address or fix:   * #221   * #243    * #234    * #101   * #275 * See [the original ""lsprotocol"" PR](https://github.com/openlawlibrary/pygls/pull/264) for further discussion. Edit: added line about taking advantage of a breaking change release"
https://api.github.com/repos/openlawlibrary/pygls,270,0.10171498358249664,0,"Fixes #266 ## Description (e.g. ""Related to ..."", etc.) _Please replace this description with a concise description of this Pull Request._ ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) ~- [] Tests have been included and/or updated, as appropriate~ ~- [ ] Docstrings have been included and/or updated, as appropriate~ ~- [ ] Standalone docs have been updated accordingly~ ~- [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate~ - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,269,0.09298050403594971,0,"This is an attempt at fixing #268 First this commit introduces a test that runs a websocket server in a separate thread. **Note:** While the test appears to work as intended, due to running the server in a separate thread I'm unable to reproduce the exact error I see in the original issue. I instead get a different error about there not being an event loop. ``` $ pytest tests/test_server_connection.py::test_ws_server =============================================== test session starts ================================================ platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 rootdir: /var/home/alex/Projects/pygls, configfile: pyproject.toml plugins: typeguard-2.13.3, timeout-2.1.0, cov-3.0.0, asyncio-0.19.0, lsp-0.1.2 asyncio: mode=auto collected 1 item                                                                                                    tests/test_server_connection.py ^C ================================================= warnings summary ================================================= tests/test_server_connection.py::test_ws_server   /var/home/alex/Projects/esbonio/.env/lib64/python3.10/site-packages/websockets/legacy/server.py:1006: DeprecationWarning: There is no current event loop     loop = asyncio.get_event_loop() tests/test_server_connection.py::test_ws_server   /var/home/alex/Projects/esbonio/.env/lib64/python3.10/site-packages/_pytest/threadexception.py:73: PytestUnhandledThreadExceptionWarning: Exception in thread Thread-3 (start_ws)      Traceback (most recent call last):     File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner       self.run()     File ""/usr/lib64/python3.10/threading.py"", line 953, in run       self._target(*self._args, **self._kwargs)     File ""/var/home/alex/Projects/pygls/pygls/server.py"", line 308, in start_ws       start_server = websockets.serve(connection_made, host, port)     File ""/var/home/alex/Projects/esbonio/.env/lib64/python3.10/site-packages/websockets/legacy/server.py"", line 1006, in __init__       loop = asyncio.get_event_loop()     File ""/usr/lib64/python3.10/asyncio/events.py"", line 656, in get_event_loop       raise RuntimeError('There is no current event loop in thread %r.'   RuntimeError: There is no current event loop in thread 'Thread-3 (start_ws)'.        warnings.warn(pytest.PytestUnhandledThreadExceptionWarning(msg)) -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! KeyboardInterrupt !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! /usr/lib64/python3.10/selectors.py:469: KeyboardInterrupt (to show a full traceback on KeyboardInterrupt use --full-trace) =============================================== 2 warnings in 4.15s ================================================ Task was destroyed but it is pending! task: <Task pending name='Task-3' coro=<test_ws_server() done, defined at /var/home/alex/Projects/pygls/tests/test_server_connection.py:78> wait_for=<Future pending cb=[Task.task_wakeup()]>> ``` Next, the fix appears to work as I'm able to use websocket based servers with it, but it appears to rely on deprecated features. ``` ================================================= warnings summary ================================================= tests/test_server_connection.py::test_ws_server   /var/home/alex/Projects/esbonio/.env/lib64/python3.10/site-packages/websockets/legacy/server.py:1009: DeprecationWarning: remove loop argument     warnings.warn(""remove loop argument"", DeprecationWarning) tests/test_server_connection.py::test_ws_server   /var/home/alex/Projects/esbonio/.env/lib64/python3.10/site-packages/websockets/legacy/protocol.py:203: DeprecationWarning: remove loop argument     warnings.warn(""remove loop argument"", DeprecationWarning) tests/test_server_connection.py::test_ws_server   /var/home/alex/Projects/pygls/pygls/server.py:148: RuntimeWarning: coroutine 'WebSocketCommonProtocol.close' was never awaited     self._ws.close()   Enable tracemalloc to get traceback where the object was allocated.   See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info. -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html ========================================== 1 passed, 3 warnings in 0.60s =========================================== ``` ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,267,0.44717279076576233,0,"## Description Pygls has been really helpful in the development of the CrossHair LSP server - thank you! This PR adds CrossHair to list of implementations, if you'd like. ## Code review checklist - [X] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [X] Title summarizes what is changing - [X] Commit messages are meaningful (see [this][commit messages] for details) - [ ] [N/A] Tests have been included and/or updated, as appropriate - [ ] [N/A] Docstrings have been included and/or updated, as appropriate - [ ] [N/A] Standalone docs have been updated accordingly - [ ] [N/A] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] [N/A] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,265,0.8204229474067688,1,"Hello :wave: - [we](https://www.github.com/avast) have released a new language server called YLS - https://www.github.com/avast/yls - we would like to feature it in this list, with hopes that it will serve the community     - as inspiration/reference/how to use it/... Thanks for pygls :) "
https://api.github.com/repos/openlawlibrary/pygls,262,-0.07287949323654175,0,"## Description (e.g. ""Related to ..."", etc.) _Please replace this description with a concise description of this Pull Request._ ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) ~- [] Tests have been included and/or updated, as appropriate~ ~- [ ] Docstrings have been included and/or updated, as appropriate~ ~- [ ] Standalone docs have been updated accordingly~ ~- [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate~ - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,258,0.007396492175757885,0,"## Description (e.g. ""Related to ..."", etc.) /cc @tombh  ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,254,0.05179192125797272,0,"## Description (e.g. ""Related to ..."", etc.) If something is wrong with the test running on CI and selenium get a timeout, the test output was not displayed. ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [/] Docstrings have been included and/or updated, as appropriate - [/] Standalone docs have been updated accordingly - [/] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [/] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,252,0.07677464187145233,0,"## Description (e.g. ""Related to ..."", etc.) This ensures that `pygls` remembers the `language_id` of text documents opened by the client. Closes #212  ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [/] Standalone docs have been updated accordingly - [/] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,250,0.05045430734753609,0,"By ignoring CI workflow when json extension is changed, we have a problem that the tests are not run and stay in *Expected — Waiting for status to be reported* state as we could see in https://github.com/openlawlibrary/pygls/pull/230 Json extension tests were not run when only pygls code is changed, but it can also be interesting to run the test for the extension every time, because it acts as an integration test for pygls. This change the workflow to run all tests for every pull request or push, regardless of what code is changed. ## Description (e.g. ""Related to ..."", etc.) problem discussed in https://github.com/openlawlibrary/pygls/pull/230#issuecomment-1173888949 and in https://github.com/openlawlibrary/pygls/pull/230#issuecomment-1175478551 @tombh suggested removing the path filter ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [/] Docstrings have been included and/or updated, as appropriate - [/] Standalone docs have been updated accordingly - [/] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [/] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,249,-0.11537788808345795,0,"Fixing a couple of deprecation warnings ```   /home/dch/pygls/pygls/server.py:168: DeprecationWarning: There is no current event loop     self.loop = loop or asyncio.get_event_loop() ``` and ```   /home/dch/.virtualenvs/pygls/lib/python3.10/site-packages/pytest_asyncio/plugin.py:191: DeprecationWarning: The 'asyncio_mode' default value will change to 'strict' in future, please explicitly use 'asyncio_mode=strict' or 'asyncio_mode=auto' in pytest configuration file.     config.issue_config_time_warning(LEGACY_MODE, stacklevel=2) ```"
https://api.github.com/repos/openlawlibrary/pygls,248,-0.020581457763910294,0,"This is my first release. There isn't any documentation on how to release, and I'm having some trouble with the version number. So I'm putting this up for some feedback. Even though I'm explicitly setting `__version__` to `0.12-rc1`, the build process always automatically decides on this version: `pygls-0.12rc2.dev0+g96bc69d.d20220704`, based on the git tag. I've noted my steps in a new `RELEASING.md` file in the root. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,247,0.052769776433706284,0,"## Description (e.g. ""Related to ..."", etc.) This undoes the change in #236 as well as bring back the explicit setting of non `None` default fields as suggested in [this comment](https://github.com/openlawlibrary/pygls/issues/245#issuecomment-1173166210) This commit also introduces serialization test cases that hopefully cover all the scenarios raised in #245, #231 and #198 Let me know if you think there are any other scenarios that should be covered by the new tests. Closes #245 ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,242,0.3602328300476074,0,"## Description  Hi!  I found myself re-writing slight variations of `Document.word_at_position` for ""words"" which aren't alphanumeric, but allowing regular expressions to be passed to the method in question means I can re-use it.  So this PR just adds a couple of parameters to `Document.word_at_position`. Hopefully the exact behaviour should be clear from the docstrings. The new parameters have default values set to the previous hard-coded patterns so I think this should be fully backward compatible with the same behaviour. Thanks! :slightly_smiling_face:  ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,241,0.4459910988807678,0,"## Description First of all thanks, I've found this package really useful.  This small PR just fixes a few bits of (I think) outdated documentation in `getting_started` and in a few docstrings. Possibly related is https://github.com/openlawlibrary/pygls/pull/94, though I'm a bit confused by that PR since the diff appears to be the opposite of what the PR title says? Thanks :slightly_smiling_face:   ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [x] Standalone docs have been updated accordingly - [x] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,239,0.19060347974300385,0,"## Description (e.g. ""Related to ..."", etc.) Closes #238  TLDR: I have the existing `pygls` test suite running but failing in a Pyodide environment and thought it's probably at a convenient place to start getting some feedback. :smile:   ![image](https://user-images.githubusercontent.com/2675694/173125496-5b1612f4-6907-4b56-baff-062c06fcd15b.png) ---- After doing some more research towards #238, I came across [this issue](https://github.com/pyodide/pyodide/issues/1791) in the pyodide repo that basically says as long as your tests are packaged, you can use `pytest` from within pyodide.  Running with this idea, this PR implements a proof of concept pyodide test suite for `pygls`, with the following workflow. 1. Build a local wheel containing `pygls` and its test suite. 1. Copy the wheel into the new `pyodide_testrunner/` folder 1. Spin up a local `http.server` pointed at the `pyodide_testrunner` folder 1. Open `http://localhost:8000` in your web browser, the tests should start running once pyodide has bootstrapped itself. In order to get this running in CI I'm assuming we'd be able to script steps 1-3 and stand up a headless browser session somehow (selenium?) as a replacement for 4. Now for some notes on the implementation. --- The implementation breaks down into three main steps/commits - Rename `tests/` -> `pygls_testsuite/`.   This is purely to get the test suite included in the wheel when packaging, I don't particularly care about this step so happy to change it back/tweak packaging rules/include it as a sub package of `pygls` - whatever we decide the best approach to be  - Add proof of concept test runner   The `pyodide_testrunner/` folder contains just enough glue code to get the tests loaded and executing under pyodide.   - It runs the tests in a web worker to keep the web page responsive while the tests run.   - It overides `sys.stdout` in the pyodide environment so the test output can be redirected to the DOM - a nice to have but not necessary for the tests to run.   - Invokes pytest using the [`--pyargs`](https://docs.pytest.org/en/7.1.x/how-to/usage.html#specifying-which-tests-to-run) option, which is what allows us to load tests via the `pygls_testsuite` package - Attempt to provide `ClientServer` implementation for pyodide   Up til now everything has worked suprisingly well! Unfortunately upon running the test suite for the first time everything errored out as the `ClientServer` object used to drive the majority of the test suite relies on threads - which are not available in pyodide!   So this final commit is a (failing) attempt at providing an implementation of `ClientServer` compatible with the pyodide runtime.   It works on the same principal as the glue code in the exmaple web extension from #218, but it doesn't quite work yet and I'd like to see if anyone has a better way we can handle this. - See code comments - What doesn't work?      There is a mismatch between the arguments being passed to `send_request` and what the pyodide implementation expects.   ```   =================================== FAILURES ===================================   ______________________________ test_bf_initialize ______________________________   client_server = (<Mock id='28467504'>, <pygls.server.LanguageServer object at 0x1b60698>)       def test_bf_initialize(client_server):           client, server = client_server           root_uri = pathlib.Path(__file__).parent.as_uri()           process_id = 1234                response = client.lsp.send_request(               INITIALIZE,               {                   ""processId"": process_id,                   ""rootUri"": root_uri,                   ""capabilities"": ClientCapabilities(),               }           ).result(timeout=CALL_TIMEOUT)         >       assert server.process_id == process_id   E       assert 12345 == 1234   E        +  where 12345 = <pygls.server.LanguageServer object at 0x1b60698>.process_id   /lib/python3.10/site-packages/pygls_testsuite/test_language_server.py:54: AssertionError   ------------------------------ Captured log call -------------------------------   ERROR    pygls.protocol:protocol.py:338 Failed to handle request 80d5e54f-42bf-4edd-8f3d-dfac26750d9b initialize {'processId':   1234, 'rootUri': 'file:///lib/python3.10/site-packages/pygls_testsuite', 'capabilities': ClientCapabilities(workspace=None, text_document=None, window=None, general=None, experimental=None)}   Traceback (most recent call last):     File ""/lib/python3.10/site-packages/pygls/protocol.py"", line 332, in _handle_request       self._execute_request(msg_id, handler, params)     File ""/lib/python3.10/site-packages/pygls/protocol.py"", line 261, in _execute_request       method_name, method_type, msg_id, handler(params))     File ""/lib/python3.10/site-packages/pygls/protocol.py"", line 74, in decorator       ret_val = base_func(self, *args, **kwargs)     File ""/lib/python3.10/site-packages/pygls/protocol.py"", line 601, in lsp_initialize       self._server.process_id = params.process_id   AttributeError: 'dict' object has no attribute 'process_id'   ```    I think this is because the pyodide implementation is bypassing the parsing machinery in `pygls` and is expected to be given objects - not sure if this is a good thing or not... ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,237,0.40474557876586914,0,"## Description Related to the recent flakey timeout errors we've been seeing on Windows CI runs, I discovered that when a test randomly raises a `TimeoutError` the test server could not be stopped, thus preventing the entire test suite from exiting, and ultimately preventing us from seeing the underlying problem. This commit does not resolve any reasons why a test might occasionally exceed its timeout, but it does allow the test suite to exit, which then allows us to identify problematic tests. However, the current WIP fix does not work on Windows! But at least it's a step in the right direction as CI is actually exiting and giving us an error now, namely that Windows more often than not does not raise `TimeoutError` even when set to `1e-50` seconds. Any ideas welcome... ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [x] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) "
https://api.github.com/repos/openlawlibrary/pygls,236,0.1481218785047531,0,"This addresses #217 and #231. I am still new to the project, so I may not have the full story. But it started with a somewhat far-reaching merge to remove defaults from all serialisable fields in the API: #198. This had the knock-on effect of regressing progress notifications, as reported by @MatejKastak in #217. One of their suggestions is to not use `exclude_unset=True`. Some months later @dimbleby suggested that `exclude_none=True` would also fix the issue[1]. Considering those 2 suggestions, let's replace `exclude_unset=True` with `exclude_none=True`. 1. https://github.com/openlawlibrary/pygls/pull/198#issuecomment-1086864429 ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [x] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,230,-0.05635960027575493,0,"The spec [1] and pygls implementation [2] need the token to be unique. By using an hardcoded token like this, the progress works only one time, the second time there's an error that token is already registered. [1]: https://microsoft.github.io/language-server-protocol/specifications/specification-current/#serverInitiatedProgress [2]: https://github.com/openlawlibrary/pygls//blob/ee17487e4f40f971e7ec6f7711fa8334c5b7b127/pygls/progress.py#L28 ## Description (e.g. ""Related to ..."", etc.) _Please replace this description with a concise description of this Pull Request._ ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [x] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,227,-0.011208576150238514,0,"## Description when it comes to setting correct Python path for lanuching a vsc, it should be python.interpreterPath instead of python.pythonPath ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,223,-0.19981145858764648,0,"## Description (e.g. ""Related to ..."", etc.) Update dependencies. I had intended just to pick up the 1.9.0 release of pydantic; but then while I was here, why not also update all the other things too? I also shuffled mypy configuration so that it all happens in a single file, which seems to me less confusing than spreading it across two (one of them hidden). And then, because I was double-checking that the sphinx upgrade didn't break anything, I fixed a couple of typos and a missing reference in the docs. ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [x] Standalone docs have been updated accordingly - [x] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,220,0.5509400963783264,1,"## Description (e.g. ""Related to ..."", etc.) Thanks to your library. It's great for python developers. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,218,0.11869572103023529,0,"## Description With the recent releases of [github.dev](https://github.dev/openlawlibrary/pygls) and [vscode.dev](https://vscode.dev/github/openlawlibrary/pygls) I wanted to see if it was possible to use [Pyodide](https://pyodide.org/en/stable/) to have a `pygls` powered language server running in a web browser. - Turns out it is! :smile:  It's worth noting that due to the `multiprocessing` module [not being available](https://pyodide.org/en/stable/usage/wasm-constraints.html#included-but-not-working-modules) in Pyodide, `@server.thread()` methods will not work in the browser, but so far everything else appears to work. This PR makes the few tweaks required to get `pygls` running in a browser context (see commit messages for details) as well as adding a new example extension that demonstrates how to get a simple language server up and running in a web version of VSCode. This isn't quite ready to be merged yet as ~`mypy` isn't happy about the import from Pyodide's `js` module and~ I should probably update the docs with some notes on Pyodide, but I thought I'd open it now so that there's an opportunity for feedback :smile:  ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,216,-0.03794765844941139,0,"## Description (e.g. ""Related to ..."", etc.) ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,215,-0.016005460172891617,0,"## Description (e.g. ""Related to ..."", etc.) Fix json extension build pipeline. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,213,-0.16757263243198395,0,"## Description (e.g. ""Related to ..."", etc.) Related to #204  - Update `LSP_METHODS_MAP` so that semantic token methods now accept just the `SemanticTokensLengend` - The remaining fields of `SemanticTokensOptions` are computed in `ServerCapabilitiesBuilder` based on which features are present. - If a legend is passed to multiple semantic token methods, only the first is used. - Update the `json-extension` example to include an implementation for `TEXT_DOCUMENT_SEMANTIC_TOKENS_FULL` ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,210,0.008352953009307384,0,"## Description (e.g. ""Related to ..."", etc.) Update example extension to detect debug mode better ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,208,-0.03873990476131439,0,"## Description (e.g. ""Related to ..."", etc.) The instructions on the `README` tell the user to create an environment called `env`. I guess we should match the `.gitignore`. ## Code review checklist (for code reviewer to complete) - [X] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [X] Title summarizes what is changing - [X] Commit messages are meaningful (see [this][commit messages] for details) - [X] Tests have been included and/or updated, as appropriate - [X] Docstrings have been included and/or updated, as appropriate - [X] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,207,0.6591736674308777,1,"## Description (e.g. ""Related to ..."", etc.) Thanks for creating such a great library! :smile:  ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,205,-0.03794765844941139,0,"## Description (e.g. ""Related to ..."", etc.) ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,203,-0.1224316954612732,0,"## Description (e.g. ""Related to ..."", etc.) Fix adding help attributes to registered feature/command handlers. This fix makes sure that [this](https://github.com/openlawlibrary/pygls/blob/master/pygls/protocol.py#L206) piece of code is properly executed and handler's return values are type-checked. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,202,-0.023186739534139633,0,"## Description (e.g. ""Related to ..."", etc.) This replaces all references to `localhost` with `127.0.0.1`. I've verified this locally this as a patch to the conda-forge feedstock, which builds under Docker: I'm not a huge Docker fan, but it is _a thing_, and it seemed like updating the docs along with the tests might save someone some trouble in the future. ### References - fixes #165 ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,200,-0.03794765844941139,0,"## Description (e.g. ""Related to ..."", etc.) ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,199,-0.03794765844941139,0,"## Description (e.g. ""Related to ..."", etc.) ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,198,-0.02273840829730034,0,"## pygls is serializing too many fields pygls 0.11.0 serializes certain optional fields, regardless of whether the server has explicitly set them - or whether the client has declared support for them. Updating [jedi-language-server to take pygls 0.11.0](https://github.com/pappasam/jedi-language-server/pull/151) I see that we are now returning various fields that we previously didn't eg on `CompletionItem` we always set `deprecated` and `preselect`.  I'm pretty sure that this is wrong: not least, there are `deprecatedSupport` and `preselectSupport` on `CompletionClientCapabilities`: if the client has not declared support for these things then presumably we're not supposed to return them. The approach I have taken is to remove all defaults for Optional fields: - when the default was not `None`, this had the effect of making the field not optional after all, as above - when the default was `None` it was redundant to declare it as such, so it's just more compact not to bother This pull request partially undoes f248002a2fb8a10fb9a5d2bd5a0160a04a6189aa.  I'm not sure what the motivation for that was, but flagging it in case I've broken something. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md"
https://api.github.com/repos/openlawlibrary/pygls,197,-0.010305558331310749,0,"## Description (e.g. ""Related to ..."", etc.) Related to #196. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,195,-0.015754222869873047,0,"## Description (e.g. ""Related to ..."", etc.) Related to #194. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,192,-0.13650274276733398,0,"## Description (e.g. ""Related to ..."", etc.) - [x] Progress bar support - [x] Trace log support - [X] LSP 3.16 model updates - [x] Tests Closes #170, #162, #115. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,191,0.07489338517189026,0," ## Description (e.g. ""Related to ..."", etc.) Related to: #189 ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [x] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,190,-0.09949656575918198,0,"## Description (e.g. ""Related to ..."", etc.) Update Tox and GitHub Actions to test against Python 3.9. Also add the appropriate trove classifier. Required updating mypy. Closes #186  ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [x] Standalone docs have been updated accordingly - [x] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [x] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,188,0.059882599860429764,0,"## Description (e.g. ""Related to ..."", etc.) This fixes #187. By raising the exception stored in the future and then handling it `sys.exc_info()` is able to see the exception and provide the details which can then be logged. With this change I now see a detailed traceback in the log. ```python ERROR:pygls.protocol:Exception occurred in notification: ""{'code': -32602, 'message': 'ZeroDivisionError: division by zero', 'data': '{\'traceback\': [\'  File ""/home/alex/Code/pygls/pygls/protocol.py"", line 246, in _execute_notification_callback\\n    raise future.exception()\\n\', \'  File ""/home/alex/Code/pygls/pygls/feature_manager.py"", line 68, in wrapped\\n    return await f(server, *args, **kwargs)\\n\', \'  File ""/home/alex/Code/pygls/examples/json-extension/server/server.py"", line 149, in did_open\\n    x = 1 / 0\\n\']}'}"" Traceback (most recent call last):   File ""/home/alex/Code/pygls/pygls/protocol.py"", line 246, in _execute_notification_callback     raise future.exception()   File ""/home/alex/Code/pygls/pygls/feature_manager.py"", line 68, in wrapped     return await f(server, *args, **kwargs)   File ""/home/alex/Code/pygls/examples/json-extension/server/server.py"", line 149, in did_open     x = 1 / 0 ZeroDivisionError: division by zero ``` ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,185,-0.07535028457641602,0,"## Description (e.g. ""Related to ..."", etc.) - Bump version - Update changelog ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,184,0.11025847494602203,0,"## Description (e.g. ""Related to ..."", etc.) I've just published Hy language server that built using pygls. I added it to the implementations.md table. Thanks. ## Code review checklist (for code reviewer to complete) - [X] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [X] Title summarizes what is changing - [X] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,183,0.03754311427474022,0,"## Description (e.g. ""Related to ..."", etc.) - [x] remove `azure-pipelines.yml` - [x] remove pipeline from Azure - [x] change github branch settings ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,182,-0.02266392484307289,0,"## Description (e.g. ""Related to ..."", etc.) Introduce GitHub Actions for CI. This will run all tests and linting on each PR and push to the repository. It will also build the example JSON extension as appropriate. This required introducing an ESLint configuration file which checks for errors and common mistakes. Closes #172  ## Code review checklist (for code reviewer to complete) - [X] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [X] Title summarizes what is changing - [X] Commit messages are meaningful (see [this][commit messages] for details) - [X] Tests have been included and/or updated, as appropriate - [X] ~Docstrings have been included and/or updated, as appropriate~ - [X] ~Standalone docs have been updated accordingly~ - [X] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [X] ~Changelog has been updated, as needed (see [CHANGELOG.md][changelog])~ [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,181,0.0423014797270298,0,"## Description (e.g. ""Related to ..."", etc.) Closes #179. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,178,0.24135474860668182,0,"## Description (e.g. ""Related to ..."", etc.) Fixes #173. I agree with recent comments saying that receiving an empty header at readline tells you that you're done: per <https://docs.python.org/3/tutorial/inputoutput.html#methods-of-file-objects> > If the end of the file has been reached, f.read() will return an empty string ('') ... > ... if f.readline() returns an empty string, the end of the file has been reached ... So that's what this does. If this looks good, I wonder whether it's time for a 0.10.3 release?  There have been a handful of bug fixes that it would be nice to see published. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,177,0.007251388393342495,0,"## Adds kind filed to CreateFile, RenameFile and DeleteFile Closes #176 . Missing kind causes error in VS Code when renaming packages. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,175,-0.15820832550525665,0,"## Description (e.g. ""Related to ..."", etc.) - [x] updated npm packages - [x] use `eslint` instead of deprecated `tslint` - [x] re-formatted `extension.ts` ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,174,-0.24533715844154358,0,"## Description (e.g. ""Related to ..."", etc.) Only the `uri` and `version` attributes of `text_doc` are used. Therefore `text_doc` can be a `VersionedTextDocumentIdentifier` and does not have to be a `TextDocumentItem`. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,169,-0.08419293910264969,0,"Commit 8b08673 (""Don't install the tests to site-packages"") added 'tests' to the exclude list, but later an 'lsp' subdirectory was added to tests/ (d0157a5 (""Add test for code completions"")). Exclude 'tests*' to avoid installing 'tests/lsp' to site-packages."
https://api.github.com/repos/openlawlibrary/pygls,167,-0.1111302301287651,0,"## Description (e.g. ""Related to ..."", etc.) Recent changes made the example code invalid. I replaced the problematic imports with their new names. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,166,-0.35740265250205994,0,"## Description (e.g. ""Related to ..."", etc.) Avoid setting fields in server capabilities to `None`, because explicitly setting them causes pydantic to serialize them, which is not what is wanted. See https://github.com/pappasam/jedi-language-server/issues/108 ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,164,-0.053745172917842865,0,"## Description (e.g. ""Related to ..."", etc.) Updated versions and the changelog. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,163,0.03618203103542328,0,"## Description (e.g. ""Related to ..."", etc.) Closes #161. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,160,0.030633509159088135,0,"## Description (e.g. ""Related to ..."", etc.) Closes #159. The reason I couldn't do this: ```python class JsonRPCRequestMessage(JsonRpcMessage):     """"""A class that represents json rpc request message.""""""     id: Union[int,str]     method: str     params: Any ``` is that in the case of `Union`, `pydantic` tries to convert the input to the first valid type, so, if you pass `id='1'`, an object will have a field of type `int` `id=1`... ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,158,-0.11692927777767181,0,"## Description (e.g. ""Related to ..."", etc.) Closes #155. More info is in the issue comments. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,157,-0.02247040346264839,0,"## Moved the metadata into setup.cfg setup.cfg is a declarative format of metadata available since Dec 2016. So, can be parsed without code execution and can be modified ahtomatically by scripts. `pyproject.toml` allows the package to be build using `python3 -m build`, also stores settings for `setuptools_scm` that can get and populate precise version information from git. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [x] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,156,0.01092564221471548,0,"## Description (e.g. ""Related to ..."", etc.) _Please replace this description with a concise description of this Pull Request._ ## Code review checklist (for code reviewer to complete) - [x] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [x] Title summarizes what is changing - [x] Commit messages are meaningful (see [this][commit messages] for details) - [x] Tests have been included and/or updated, as appropriate - [x] Docstrings have been included and/or updated, as appropriate - [x] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,154,-0.09335938096046448,0,"## Description (e.g. ""Related to ..."", etc.) Closes #153. - Updated versions and changelog for hotfix ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,152,-0.009281651116907597,0,"## Description (e.g. ""Related to ..."", etc.) Related to #151. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,150,-0.143498495221138,0,"## Description (e.g. ""Related to ..."", etc.) Closes #126. I just cherry-picked commits and resolved conflicts from PR #141. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,149,-0.01525344792753458,0,"## Description (e.g. ""Related to ..."", etc.) Closes #118, #130. Ensures that `pygls` process will terminate if the client process is not alive. ## Code review checklist (for code reviewer to complete) - [ ] Pull request represents a single change (i.e. not fixing disparate/unrelated things in a single PR) - [ ] Title summarizes what is changing - [ ] Commit messages are meaningful (see [this][commit messages] for details) - [ ] Tests have been included and/or updated, as appropriate - [ ] Docstrings have been included and/or updated, as appropriate - [ ] Standalone docs have been updated accordingly - [ ] [CONTRIBUTORS.md][contributors] was updated, as appropriate - [ ] Changelog has been updated, as needed (see [CHANGELOG.md][changelog]) [changelog]: https://github.com/openlawlibrary/pygls/blob/master/CHANGELOG.md [commit messages]: https://chris.beams.io/posts/git-commit/ [contributors]: https://github.com/openlawlibrary/pygls/blob/master/CONTRIBUTORS.md "
https://api.github.com/repos/openlawlibrary/pygls,148,0.24806927144527435,0,"## Description (e.g. ""Related to ..."", etc.) Related to #139 (and this pull request is against that branch). I have: - allowed pydantic and typeguard versions to go higher.  typeguard declares that it follows semantic versioning, so 2.x should be safe.  pydantic seems to make breaking changes at minor releases; however 1.8 works just fine so I've allowed 1.7.x and 1.8.x - tweaked `ClientCapabilities.has_capability()` along the lines I suggested in https://github.com/openlawlibrary/pygls/pull/139#issuecomment-798347921 ie added a type annotation, and allowed it to return a default value.  I've also renamed it to `get_capability()`, since it handles not only boolean values (eg `text_document.completion.completion_item.documentation_format` is a list of `MarkupKind`)."
https://api.github.com/repos/openai/openai-python,217,-1.2039244174957275,-1,"None"
https://api.github.com/repos/openai/openai-python,216,-0.13803206384181976,0,"I was able to reproduce #184 where sometimes calling `Completion.acreate(stream=True)` would result in a JSON parsing issue.  This was happening because our code was trying to parse incomplete JSON objects. It was receiving chunks that looked like this (notice the incomplete line at the end): ``` data: {""id"": ""cmpl-6hDMH0KtbEmSdkAvX4xEHy7be8XMz"", ""object"": ""text_completion"", ""created"": 1675757473, ""choices"": [{""text"": ""\\n"", ""index"": 0, ""logprobs"": null, ""finish_details"": null}], ""model"": ""text-davinci-003""}\n\ndata: {""id"": ""cmpl-6hDMH0KtbEmSdkAvX4xEHy7be8XMz"", ""object"": ""text_completion"", ""created"": 1675757473, ""choices"": [{""text"": ""Hello"", ""index"": 0, ""logprobs"": null, ""finish_details"": null, ""model"": ""text-davinci-003""}\n\ndata: {""id"": ""cmpl-6hDMH0KtbEmSdkAvX4xEHy7be8XMz"", ""object"": ""text_completion"", ""created"": 1675757473, ""choices"": [{""text"": "" again"", ""index"": 0, ""logprobs"": null, ""finish_details"": null, ""model"": ""text-davinci-003""}\n\ndata: {""id"": ""cmpl-6hDMH0KtbEmSdkAvX4xEHy7be8XMz"", ""object"": ""text_completion"", ""created"": 1675757473, ""choices"": [{""text"": ""!"", ""index"": 0, ""logprobs"": null, ""finish_details"": null, ""model"": ""text-davinci-003""}\n\ndata: {""id"": ""cmpl-6hDMH0KtbEmSdkAvX4xEHy7be8XMz"", ""object"": ""text_completion"", ""created"": 1675757473, ""choices"": [{""text"": "" Is"", ""index"": 0, ""logprobs"": null, ""finish_details"": null, ""model"": ""text-davinci-003""}\n\ndata: {""id"": ""cmpl-6hDMH0KtbEmSdkAvX4xEHy7be8XMz"", ""object"": ""text_completion"", ""created"": 1675757473, ""choices"": [{""text"": "" there"", ""index"": 0, ""logprobs"": null, ""finish_details"": null, ""model"": ""text-davinci-003""}\n\ndata: {""id"": ""cmpl-6hDMH0KtbEmSdkAvX4xEHy7be8XMz"", ""object"": ""text_completion"", ""created"": 1675757473, ""choices"": [{""text"": "" something"", ""index"": 0, ""logprobs"": null, ""finish_details"": null, ""model"": ""text-davinci-003""}\n\ndata: {""id"": ""cmpl-6hDMH0KtbEmSdkAvX4xEHy7be8XMz"", ""object"": ""text_completion"", ""c ``` It looks like we were using the wrong function from `aiohttp` to parse streaming bodies. Instead of `rbody.iter_chunks()` we should be using `async for line in rbody` instead. See docs here: https://docs.aiohttp.org/en/stable/streams.html#asynchronous-iteration-support. This change immediately fixed the issue in my code. "
https://api.github.com/repos/openai/openai-python,215,-1.2039244174957275,-1,"None"
https://api.github.com/repos/openai/openai-python,214,-1.2039244174957275,-1,"None"
https://api.github.com/repos/openai/openai-python,211,0.27168816328048706,0,"This PR updates the code to use ""cls"" as the first argument for class methods for improved readability and consistency with community conventions."
https://api.github.com/repos/openai/openai-python,207,-0.0681062564253807,0,"`File.__find_matching_files()` can't correctly detect matching files because of missing file size info. It compares remote file size with the `bytes` builtin. Regression: 0abf64137c18b45925d5015bae80429adb46fac6. This PR adds `bytes` argument to the `File.__find_matching_files()`. PS: Better to rename `bytes -> bytes_` to not shadow builtin name and prevent such issues in the future."
https://api.github.com/repos/openai/openai-python,204,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,201,0.3064888119697571,0,"The `[project]` section of a `pyproject.toml` file *has* to include both a `name` and a `version`, that we were missing. However, rather than adding more stuff to `pyproject.toml`, I've moved the license info to the setup file and pointed `pyproject.toml` to use `setuptools` for building (the `pyproject.toml` file is really only needed to integrated with `black`, that doesn't support setup files...) While I was at it I decided to migrate to a `setup.cfg` file rather than `setup.py` since its declaritive config is usally preferred these days (and it's a bit easier to load from version/license files than with a `setup.py` file). I tested `python setup.py install` and `pip install -e .` and both work now."
https://api.github.com/repos/openai/openai-python,200,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,198,0.10208950936794281,0,"Add license metadata for pypi. Please see the documentation at: https://packaging.python.org/en/latest/specifications/declaring-project-metadata/?highlight=license Having this would make it easier to use this package in a corporate environment where python package licenses need to be approved."
https://api.github.com/repos/openai/openai-python,197,-0.009562221355736256,0,"Fixes https://github.com/openai/openai-python/issues/196, and probably https://github.com/openai/openai-python/pull/185 and https://github.com/openai/openai-python/pull/183 This MR reverts the change in https://github.com/openai/openai-python/pull/146/files#r1084884786 so that the requests hit the `/content` url of the api again. cc @Andrew-Chen-Wang @ddeville  To reproduce, on the older openai==0.25.0 ` ``` openai api fine_tunes.results -i <job_id_here> ``` You'll get the output of the actual CSV file E.g. step,elapsed_tokens,elapsed_examples,training_loss,training_sequence_accuracy,training_token_accuracy 1,22048,32,0.011019098009307718,0.0,0.0 1,32288,32,0.007613447834811513,0.0,0.0 On the current openai==0.26.2 You get instead {   ""object"": ""file"",   ""id"": ""file-66NnpqAXzw3In27fROPIU03P"",   ""purpose"": ""fine-tune-results"",   ""filename"": ""compiled_results.csv"",   ""bytes"": 386756,   ""created_at"": 1674504271,   ""status"": ""processed"",   ""status_details"": null } "
https://api.github.com/repos/openai/openai-python,193,0.4389943480491638,0,"Right now, it is a bit confusing where the docs live for this repo (ideally we would have something deployed with an open source tool like read the docs) but in the interim, this should help make it clear right away where people should look for resources."
https://api.github.com/repos/openai/openai-python,190,0.04166329652070999,0,"* add more descriptive error handling regarding poorly formatted files * update version * add dot prefix to json file extentions and ensure list of allowable file types is complete * cleanup error messages and add comments to explain jsonl/json loading logic * cleanup csv/tsv reading allowing use of elif for other file extensions, add comments, and remove unnecessary re-attempt to parse as json * run fillna immediately upon DataFrame creation so that an additional switch is not needed * use only 1 try-except block to catch parsing errors + cleanup error message * separate the json and jsonl cases while still maintaining the same functionality, also include a message to user if jsonl appears to be json or vice versa * fix bug in csv path * use index -1 to get extension from split * black formatting apply * fix black Co-authored-by: joe-at-openai <joe@openai.com>"
https://api.github.com/repos/openai/openai-python,188,-0.18833015859127045,0,"Just caught some minor typos in Readme "
https://api.github.com/repos/openai/openai-python,187,-0.1533801406621933,0,"* Adds a `fine_tunes.delete -i <ID>`  command to delete fine-tunes using the CLI"
https://api.github.com/repos/openai/openai-python,182,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,179,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,178,-0.0848517119884491,0,"Fixes https://github.com/openai/openai-python/issues/141 Co-authored-by: andrewpeng@openai.com <Andrew Peng>"
https://api.github.com/repos/openai/openai-python,177,0.01329136174172163,0,"There were a bunch of mypy issues when I applied this internally so fixing them here. Also deal with async stream line parsing a bit more robustly (iterating over an `aiohttp.StreamReader` by chunks could still return multiple lines so let's keep using the regular one and deal with multiple lines separately). Finally make sure that we correctly close the underlying session if an exception is raised while we're making the raw request."
https://api.github.com/repos/openai/openai-python,176,0.2826741933822632,0,"We incorrectly changed the original method to be async rather than making a new async version. This PR fixes that. Fixes #173."
https://api.github.com/repos/openai/openai-python,175,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,172,0.25021857023239136,0,"#171  Note that as per the issue above, even after the two fixes below this test still fails, as the 2nd chunk of the stream never arrives"
https://api.github.com/repos/openai/openai-python,170,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,169,-0.05342787876725197,0,"* Add optional mask for dalle's edit api"
https://api.github.com/repos/openai/openai-python,168,-0.018248487263917923,0,"Removed since these endpoints no longer exist"
https://api.github.com/repos/openai/openai-python,167,0.49873512983322144,0,"When a global session wasn't set in `openai.aiosession`, we would create a temp `ClientSession` on the fly. Unfortunately, this session wasn't scoped correctly since it was closed upon returning from `arequest_raw` but `_interpret_async_response` would later call `await result.read()` on the response, which would hang since the backing session had already been closed. This patch ensures that the session is kept open for the duration of the request *and* the entire parsing of the response."
https://api.github.com/repos/openai/openai-python,165,0.10648124665021896,0,"* Add `deployments.list`,  `deployments.get`, `deployments.delete` and `deployments.create` commands to manage deployments for azure endpoints To use the CLI with azure endpoints: ```bash export OPENAI_API_BASE=""..."" export OPENAI_API_TYPE=""azure"" export OPENAI_API_KEY=""..."" ```"
https://api.github.com/repos/openai/openai-python,163,-0.03430119529366493,0,"Fixes https://github.com/openai/openai-python/issues/160 in the style of all of the other image calls"
https://api.github.com/repos/openai/openai-python,159,-0.08900463581085205,0,"* Set default azure `api_version` to `2022-12-01` * Remove search example from README because search is not longer supported * Changed token authority (see https://github.com/openai/openai-cookbook/commit/3c334e70ddd3f7b9e63e1136bb583d02bd8127bc)"
https://api.github.com/repos/openai/openai-python,158,0.22977785766124725,0,"mypy doesn't correctly handle try except blocks, so it's necessary to import from the correct module based on the python version. I accidentally broke this in https://github.com/openai/openai-python/pull/154, I am sorry about that cc @ddeville "
https://api.github.com/repos/openai/openai-python,157,-0.05518181994557381,0,"Currently, there is no 'long' description of the project, i.e., the project page on pypi is empty. ![image](https://user-images.githubusercontent.com/4815944/208649913-3a2ef8e6-ab47-4469-9d78-f9ca62d7b90e.png) This PR uses the content of the `README.md` as long description."
https://api.github.com/repos/openai/openai-python,154,0.06302285939455032,0,"typing_extensions are only used for Literal which is available in the standard library since Python 3.8"
https://api.github.com/repos/openai/openai-python,153,0.2072484940290451,0,"This PR makes data libraries like `numpy` and `pandas` optional dependencies. These libraries add up to 146MB, which makes it challenging to deploy applications using this library in environments with code size constraints, such as AWS Lambda. Since the primary use case of this library (talking to the OpenAI API) doesn’t generally require data libraries, it’s safe to make them optional. The rare case when the data libraries are needed in the API client is handled through assertions with instructive error messages.  ## Requirements before Installing `openai-python` requires the `numpy`, `pandas`, and `openpyxl` data libraries that add up to 146MB: ```bash $ pip install -e . $ du -sh $VIRTUAL_ENV/lib/python*/site-packages/ 167M /Users/jakub/.virtualenvs/openai-python/lib/python3.11/site-packages/ ``` ## Requirements after Installing `openai-python` doesn’t require the data libraries by default, **resulting in ~7 times smaller aggregate size of dependencies:** ```bash $ pip install -e . $ du -sh $VIRTUAL_ENV/lib/python*/site-packages/ 23M /Users/jakub/.virtualenvs/openai-python/lib/python3.11/site-packages/ ``` Data libraries can be installed manually using the new `datalib` extras, if needed: ``` $ pip install -e .[datalib] $ du -sh $VIRTUAL_ENV/lib/python*/site-packages/ 167M /Users/jakub/.virtualenvs/openai-python/lib/python3.11/site-packages/ ``` And they are now also included in the existing `embeddings` and `wantdb` extras: ``` $ pip install -e .[embeddings] $ pip install -e .[wantdb] ```"
https://api.github.com/repos/openai/openai-python,148,0.1364540308713913,0,"Default encoding on Windows is not `utf-8` which creates issues with the fine-tunes. Updated artifact encoding and forced it to correct formatting. fix #143 "
https://api.github.com/repos/openai/openai-python,146,0.18431511521339417,0,"Fixes #98  Adds asyncio support for API. Does not support CLI (does not make sense). I haven't tested file upload. aiohttp does not include the files parameter like requests, so I'm using requests' private utility function in the ApiRequestor Usage (notice the `a` prefix, used in CPython lib, Django, and other libs): ```python import openai openai.api_key = ""sk-..."" async def main():     await openai.Completion.acreate(prompt=""This is a test"", engine=""text-ada-001"") ``` Installation of aiohttp can include speedups that aren't included in setup.py. aiohttp is a required package, but it doesn't have to be. We'd just need to remove the typing."
https://api.github.com/repos/openai/openai-python,138,-0.02702098712325096,0,"* Add Moderation endpoint to readme * add basic example"
https://api.github.com/repos/openai/openai-python,137,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,135,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,134,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,131,0.0023412657901644707,0,"Added a first version of dalle support"
https://api.github.com/repos/openai/openai-python,127,-0.7553195357322693,-1,"Minor changes to sentence structure to avoid repetitious language."
https://api.github.com/repos/openai/openai-python,126,-0.17605634033679962,0,"resolves https://github.com/openai/openai-python/issues/124"
https://api.github.com/repos/openai/openai-python,125,0.5524699091911316,1,"### Description KeyError occurs when running `openai tools fine_tunes.prepare_data -f training_file.jsonl` when `training_file.jsonl` contains a prompt/completion that is BOTH a duplicate and a long example. Without trying to change too much, this fix would: - wrap the retrieval of `long_examples` and `long_indexes` into a function, calling it preemptively within `long_examples_validator` to provide analysis information about how many rows are long examples, then calling it when actually dropping rows within `optional_fn` and providing info to the user if the keys that are being dropped have changed.  ### Related Issue Fixes #121  ### Other Notes I am also happy to provide a file that can be used to reproduce this error. ### Example Output: When the error would normally occur, instead you would see: ``` ❯ openai tools fine_tunes.prepare_data -f training_file_0927.jsonl Analyzing... - There are 2 duplicated prompt-completion sets. These are rows: [5, 6] - There are 2 examples that are very long. These are rows: [3, 6] Based on the analysis we will perform the following actions: - [Recommended] Remove 2 duplicate rows [Y/n]: y - [Recommended] Remove 2 long examples [Y/n]: y The indices of the long examples has changed as a result of a previously applied recommendation. The 1 long examples to be dropped are now at the following indices: [3] - [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: y  ```"
https://api.github.com/repos/openai/openai-python,123,0.16879427433013916,0,"Fixes https://github.com/openai/openai-python/issues/122 This PR enables making moderation endpoint calls without setting API key as environment variable or binding API key to `openai` module globally."
https://api.github.com/repos/openai/openai-python,118,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,116,0.09544041007757187,0,"* Adds support for url timeouts with the `request_timeout` flag * Adds logging of the request_id  * Wandb import warning only occurs if the wandb package isn't installed AND user requests the wandb tools via the CLI. Previously a warning would appear if the wandb package wasn't installed for all CLI commands. * Drops specifying the numpy version * Bumps version to 0.23.0"
https://api.github.com/repos/openai/openai-python,114,0.006214703433215618,0,"0.22.0 was deployed incorrectly with extra breakpoint statements. 0.22.1 fixes this"
https://api.github.com/repos/openai/openai-python,112,-0.06739188730716705,0,"Primarily, this PR removes the examples from the openai-python library to help keep the library simple and lightweight. - Removes all the code examples, and replaces them with short messages link to the new location in OpenAI Cookbook (this way people don't hit annoying 404s if they're following an outside link) - Removes the small data files - Updates the text and links in the README.md (all links have been doublechecked to work) Secondly, this PR: - Updates numpy requirements due to a vulnerability in 1.21.6 - Adds api_type to ErrorObject - formats the repo with Black (hopefully not too annoying for folks - will likely start to require this in the future, just to keep formatting consistent)"
https://api.github.com/repos/openai/openai-python,109,0.3371775150299072,0,"This PR adds support for a deployment_id parameter for azure. The ""deployment_id"" parameter overloads the engine parameter. (Similar to as ""model"" overloads the ""engine"" parameter for openai) Parameter checks and exceptions are refactored and moved into the EngineApiResource base class."
https://api.github.com/repos/openai/openai-python,107,-0.28082048892974854,0,"- [x] 3rd argument in refresh_from is `api_type`. Passing these arguments in order (*args) instead of using keyworded arguments causes setting `api_type` value to `organization` value and `organization` value to `response_ms` value.  - [x] Removed unused imported module ""email"""
https://api.github.com/repos/openai/openai-python,104,-0.05383380874991417,0,"This PR removes invalid inheritances (ListableAPIResource, DeletableAPIResource) from Embedding and Completion. Additionally, a simple jupyter notebook demonstrating the use of embeddings using azure is added."
https://api.github.com/repos/openai/openai-python,103,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,102,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,101,-0.1976327896118164,0,"* Add moderation endpoint * Add version * version to model * s/version/model * fix formatting * model default to None * fix test * update value error message"
https://api.github.com/repos/openai/openai-python,99,-0.23002183437347412,0,"Add missing dependency scikit-learn"
https://api.github.com/repos/openai/openai-python,97,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,94,0.08059043437242508,0,"Fix reusing of HTTP Connection `return` while reading lines will close Generator and cause `GeneratorExit` exception, that will close connection & socket In this case system will produce TCP RST packet. Closes https://github.com/openai/openai-python/issues/95"
https://api.github.com/repos/openai/openai-python,92,0.05473971739411354,0,"This PR adds support for authentication using azure active directory. For azure_ad authentication the api_type needs to be set to ""azure_ad"" (or alternatively ""azuread"") and the credentials token needs to be passed to api_key. Similar to the azure key-based authentication, the api_version has to be specified ``` from azure.identity import DefaultAzureCredential import openai default_credential = DefaultAzureCredential(     exclude_interactive_browser_credential=False) token = default_credential.get_token(""https://cognitiveservices.azure.com"") openai.api_type = ""azure_ad"" openai.api_key = token.token openai.api_version = ""2022-03-01-preview"" openai.api_base = ""https://your-endpoint.openai.azure.com/"" ``` "
https://api.github.com/repos/openai/openai-python,88,0.20882780849933624,0,"The `model` param is not required for Azure, and its presence results in an authentication error. Removing it enables it to succeed. Example error: ``` --------------------------------------------------------------------------- AuthenticationError                       Traceback (most recent call last) <ipython-input-49-6182fea6bc5b> in <module>       1 print('Sending a test completion job')       2 start_phrase = 'When I go to the store, I want a' ----> 3 response = openai.Completion.create(engine=deployment_id, model=model, prompt=start_phrase, max_tokens=4)       4 text = response['choices'][0]['text'].replace('\n', '').replace(' .', '.').strip()       5 print(f'""{start_phrase} {text}""') ~/miniconda3/envs/gpt/lib/python3.9/site-packages/openai/api_resources/completion.py in create(cls, *args, **kwargs)      29         while True:      30             try: ---> 31                 return super().create(*args, **kwargs)      32             except TryAgain as e:      33                 if timeout is not None and time.time() > start + timeout: ~/miniconda3/envs/gpt/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py in create(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)      98         )      99         url = cls.class_url(engine, api_type, api_version) --> 100         response, _, api_key = requestor.request(     101             ""post"",     102             url, ~/miniconda3/envs/gpt/lib/python3.9/site-packages/openai/api_requestor.py in request(self, method, url, params, headers, files, stream, request_id)     118             request_id=request_id,     119         ) --> 120         resp, got_stream = self._interpret_response(result, stream)     121         return resp, got_stream, self.api_key     122  ~/miniconda3/envs/gpt/lib/python3.9/site-packages/openai/api_requestor.py in _interpret_response(self, result, stream)     325         else:     326             return ( --> 327                 self._interpret_response_line(     328                     result.content, result.status_code, result.headers, stream=False     329                 ), ~/miniconda3/envs/gpt/lib/python3.9/site-packages/openai/api_requestor.py in _interpret_response_line(self, rbody, rcode, rheaders, stream)     358         stream_error = stream and ""error"" in resp.data     359         if stream_error or not 200 <= rcode < 300: --> 360             raise self.handle_error_response(     361                 rbody, rcode, resp.data, rheaders, stream_error=stream_error     362             ) AuthenticationError: Incorrect API key provided: dummy-key. You can find your API key at https://beta.openai.com./ ``` "
https://api.github.com/repos/openai/openai-python,87,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,83,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,82,-0.03823499009013176,0,"* Add support for edit call * Add version bump (0.16.0)"
https://api.github.com/repos/openai/openai-python,81,-0.659778356552124,-1,"- run isort - run black"
https://api.github.com/repos/openai/openai-python,80,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,79,0.12529121339321136,0,"Reverts openai/openai-python#76 Seeing a couple unit tests (test_file_upload, test_engine_search_url_composition_azure_no_operation) failing with this change."
https://api.github.com/repos/openai/openai-python,77,0.3299444019794464,0,"Datasets are saved as wandb artifacts using original file names. However, some characters are not allowed to be used as artifact name. This PR sanitizes the name used as wandb artifact. It also ensures results are present even when a run is marked as `succeeded`."
https://api.github.com/repos/openai/openai-python,76,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,75,0.445980966091156,0,"* Add fine tune creation suffix arg to openai cli * Bump minor version to 0.15.0 due to the addition of a new arg"
https://api.github.com/repos/openai/openai-python,74,-0.1604897528886795,0,"Fixes issue where we tried to access a results file even when finetune status was not ""succeeded"""
https://api.github.com/repos/openai/openai-python,72,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,71,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,68,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,67,0.43235066533088684,0,"- Adds new example notebook demonstrating embeddings for recommendations - Adds link to new example on readme - Updates other embedding examples - Adds new functions to embedding_utils.py - Increments version number"
https://api.github.com/repos/openai/openai-python,66,0.19990511238574982,0,"Changes in this version: * Deprecating `openai.Engine.embeddings`.  Instead, please use `openai.Embedding.create` * Uses the new embedding engine names in all examples * Delete the ca certificates that aren't needed anymore * Makes all openai exceptions pickle-able"
https://api.github.com/repos/openai/openai-python,64,-0.07670325040817261,0,"### Usage - CLI ``` $ openai wandb sync --help usage: openai wandb sync [-h] [-i ID] [-n N_JOBS] [--project PROJECT] [--entity ENTITY] [--force] optional arguments:   -h, --help            show this help message and exit   -i ID, --id ID        The id of the fine-tune job   -n N_JOBS, --n_jobs N_JOBS                         Number of most recent fine-tune jobs to log when an id is not provided   --project PROJECT     Name of the project where you're sending runs. By default, it is ""GPT-3"".   --entity ENTITY       Username or team name where you're sending runs. By default, your default entity is used, which is usually your username.   --force               Forces logging and overwrite existing wandb run of the same finetune job. ``` ### Usage - Python ```python from openai.logger import Logger Logger.sync(     id=None,     n_jobs=10,     project='GPT-3',     entity=None,     force=False,     **kwargs_wandb_init ) ``` ### Reference - [Documentation](https://docs.wandb.ai/guides/integrations/other/openai) - [Demo Report](https://wandb.ai/borisd13/gpt-3-backup/reports/GPT-3-exploration-fine-tuning-tips--VmlldzoxMTAxNDE2) - [Demo Colab](https://colab.research.google.com/drive/1xu2CDJdIybC_65PRNeGP5ZmBbnY3PYDB?usp=sharing)"
https://api.github.com/repos/openai/openai-python,63,-0.020437415689229965,0,"* Add get_embeddings() * Add Visualize_in_3d notebook * Add dbpedia_samples.jsonl"
https://api.github.com/repos/openai/openai-python,62,0.23859235644340515,0,"Edited line 597 to match condition in line 242, ""classifications"". Also edited line 243 to match documentation (""label"", not ""labels""). With these changes `openai tools classifications.prepare_data -f <FILENAME>` works to convert files to JSONL."
https://api.github.com/repos/openai/openai-python,60,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,55,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,54,0.3079979419708252,0,"* Answers and Classification endpoints now have their own prepare_data functions, similar to search * Moved the utils file used in the embeddings examples to embeddings_utils.  This will allow the code to be imported * Changed the default api_prefix to be """" and instead moved that logic into __init__.py.  You might need to update any local OPENAI_API_BASE that you've set."
https://api.github.com/repos/openai/openai-python,52,-0.010010560043156147,0,"This PR updates the repo to use the more modern `entry_points`. Ref: https://packaging.python.org/guides/distributing-packages-using-setuptools/#scripts Closes #48"
https://api.github.com/repos/openai/openai-python,51,-0.1831640750169754,0,"(missed this earlier due to git conflicts...)"
https://api.github.com/repos/openai/openai-python,50,0.44267135858535767,0,"also a few fixes: setting the correct filename for file uploads using files.create, reinstating the progress meter for uploading files in conjunction with the fine-tuning endpoint, standardizing punctuation on FT help strings"
https://api.github.com/repos/openai/openai-python,49,-0.2549329698085785,0,"- Add Q&A fine-tuning tutorials - Add embedding tutorials"
https://api.github.com/repos/openai/openai-python,45,-1.2039240598678589,-1,"None"
https://api.github.com/repos/openai/openai-python,44,0.03371468931436539,0,"These were passed as positional arguments, but in the wrong position, which meant they were passed into [the `json_body` parameter](https://github.com/openai/openai-python/blob/62f8d40ffc6d3a723f5f1d99fee7febfd47026b5/openai/error.py#L10) of the `OpenAIError` constructor."
https://api.github.com/repos/openai/openai-python,42,-0.17974361777305603,0,"- Add `.isort.cfg` and fix imports to match. - Exit with status 1 instead of 0 on error in `openai`. - Support `openai.api_key_path` variable to make it easy to have long-running processes with auto-updated keys. - Drop support for unverified SSL connections. - Substantially simplify HTTP client code. Now that we use `requests` for everything, we do not need distinct `HTTPClient` and `APIRequestor` abstractions, and we can use the `requests` implementation for multipart data, rather than our own. - Drop vestigial code originally from the Stripe client. For example, there was a bunch of code related to an idempotency framework; OpenAI does not have an idempotency framework. - Drop support for `APIResource.delete` as an instance method; it is just a class method now. - Drop support for `APIResource.save`; use `APIResource.modify` instead. This substantially simplifies API resources, since they no longer need to track changed fields, and there's less risk of race conditions. And the only thing it could be used for is changing the number of replicas an engine had, which does not justify the complexity of the code. - Drop the request-metrics code. It is unused."
https://api.github.com/repos/amaranth-lang/amaranth,747,0.17173424363136292,0,"This PR implements explicit naming of properties (Assert/Assume/Cover) as asked in #744. The name is specified through the use of a new optional parameter ""name"". With the following code example: ```python from amaranth import * from amaranth.asserts import * from amaranth.back import rtlil m = Module() a = Signal() m.d.sync += Assert(a != 0, name=""foobar"") print(rtlil.convert(m, ports=(a,))) ``` The `$assert` cell picks up the proper name: ``` [...]   cell $assert \foobar     connect \A $assert$check     connect \EN $assert$en   end [...] ``` Fixes #744."
https://api.github.com/repos/amaranth-lang/amaranth,739,0.39630818367004395,0,"Example code that can make use of such changes: ```py class Something(IntEnum):     A = 0b1000     B = 0b0000 ... class Component(Elaboratable):     def elaborate(self, platform):         m = Module()         with m.Switch(...):              with m.Case(Cat(Something.A, Something.B)):                  ... ``` The first commit is more important to me than the second one (you can always work it around using `Case(Cat(...)._as_const())`), but they are pretty much independent, so if it is desirable to only merge one of them, you can do it."
https://api.github.com/repos/amaranth-lang/amaranth,738,-1.2039241790771484,-1,"None"
https://api.github.com/repos/amaranth-lang/amaranth,737,-0.06154373660683632,0,"fixes #735 "
https://api.github.com/repos/amaranth-lang/amaranth,736,0.18182769417762756,0,"Adds support for parts used in Digilent CMOD boards."
https://api.github.com/repos/amaranth-lang/amaranth,731,0.1439923644065857,0,"The symbiflow tools in f4pga have changed the required arguments. This PR fixes the xilinx toolchain (at least for Arty A35)."
https://api.github.com/repos/amaranth-lang/amaranth,729,0.6212429404258728,1,"See #728 and #687. Having done this, though, I wonder if having the toolchain env vars be uppercase would be better in general, even if we maintain an old/deprecated mixed-case name? All the tool overrides are already in uppercase, and using all-uppercase environment variables is a widely used convention. We could extend `deprecated_toolchain_env_var` to cover both `NMIGEN_ENV_Diamond` and `AMARANTH_ENV_Diamond`, with `AMARANTH_ENV_DIAMOND` being the nominal name, used first if multiple are set. I don't especially mind, happy to just take this as-is (or with whatever changes you want), but maybe it would be more consistent to deliberately change to all-uppercase for 0.4."
https://api.github.com/repos/amaranth-lang/amaranth,726,0.04520365968346596,0,"While developing a prototype for #704 at 052647445772cfe83767b0c55dd47c196763ac82, I discovered that bits of `Graydecoder.o` are combinationally dependent on each other. When each bit is thought of as an individual signal, this is no problem, but a comb loop detection pass would be slowed down by that assumption. Regardless of if it's within the scope of the language's ""no *indirect* comb loops"" policy, it is easily rewritable to never have assignments that have the output signal both on the left and righ-hand sides. That is what this PR contains. All tests pass, including the formal check of gray encoding reversibility, proving correctness of this PR."
https://api.github.com/repos/amaranth-lang/amaranth,724,-1.2039241790771484,-1,"None"
https://api.github.com/repos/amaranth-lang/amaranth,723,0.060125913470983505,0,"Note that CI will still fail without #722."
https://api.github.com/repos/amaranth-lang/amaranth,722,0.27911368012428284,0,"Starting with setuptools 64.0.2, the monkeypatching process performed as part of its bootstrap no longer imports distutils.ccompiler, causing an AttributeError."
https://api.github.com/repos/amaranth-lang/amaranth,720,-1.2039241790771484,-1,"None"
https://api.github.com/repos/amaranth-lang/amaranth,716,0.050445154309272766,0,"Hi, some of my code recently started failing with this exception after a Python version bump: ``` Traceback (most recent call last): [...]   File ""/usr/lib/python3.10/site-packages/amaranth/hdl/xfrm.py"", line 209, in on_statement     new_stmt = self.on_Assign(stmt)   File ""/usr/lib/python3.10/site-packages/amaranth/sim/_pyrtl.py"", line 349, in on_Assign     gen_rhs = f""({(1 << len(stmt.rhs)) - 1} & {gen_rhs_value})"" ValueError: Exceeds the limit (4300) for integer string conversion ``` Here's a small reproducer: ```python from amaranth import Module, Signal, sim dut = Module() dut.d.sync += Signal(1).eq(Signal(1) << Signal(14)) sim.Simulator(dut) ``` This fails because the generated code uses a large mask value, which raises an ValueError during decimal formatting in Python versions that include a mitigation for CVE-2020-10735. Formatting to hexadecimal instead avoids the algorithmic complexity and is not impacted by the new conversion limits. I'm not sure if this is worth merging as affected modules are already near the [existing value limits](https://github.com/amaranth-lang/amaranth/blob/db49294cf722e9463666bd06f81a86f930b8707c/amaranth/sim/_pyrtl.py#L75) enforced by pyrtl, so feel free to close/reject this patch ^^ Note: There's an open proposal that changes int's `repr` implementation to hex for large values and would make this patch a bit more self-explanatory (`{v!r}` vs `{v:#x}`): https://github.com/python/cpython/issues/96601"
https://api.github.com/repos/amaranth-lang/amaranth,712,0.3278837203979492,0,"Current the value compiler translates ArrayProxy into if-elif trees which can cause the compiler to crash due to deep recursion (#359). This patch instead translates them into pattern matching when it is supported (Python >= 3.10) to avoid this problem."
https://api.github.com/repos/amaranth-lang/amaranth,710,-1.2039241790771484,-1,"None"
https://api.github.com/repos/amaranth-lang/amaranth,697,-1.2039241790771484,-1,"None"
https://api.github.com/repos/amaranth-lang/amaranth,695,-0.37703219056129456,0,"Missed this in the first PR. "
https://api.github.com/repos/amaranth-lang/amaranth,694,0.11195613443851471,0,"Currently `get_override()` does not have a well defined interface and is not well designed for handling things like a flag to *disable* a feature cleanly. This PR implements `get_override_flag()` to provide this functionality while `get_override()` additionally gains improved type checking for keyword arguments. This is used to implement #623 which is now possible by providing a ""false-like"" value `(""0"", ""no"", ""n"", ""false"", """")` to it (case-insensitive)."
https://api.github.com/repos/amaranth-lang/amaranth,689,0.2434447854757309,0,"This PR fixes #688 by upgrading the Jinja2 dependency to minimum of major version 3, which does not have the issue with it's markupsafe dependency being  incorrect. In order to do this, update the uses of `@jinja2.contextfunction` to use the non-deprecated `@jinja2.pass_context` name instead, as this name will be removed in Jinja2 versions `>=3.1.0`."
https://api.github.com/repos/amaranth-lang/amaranth,687,0.3230586349964142,0,"This allows `Platform.toolchain` to contain '+' or  '-' characters."
https://api.github.com/repos/amaranth-lang/amaranth,680,0.1756633222103119,0,"Yosys + nextpnr-xilinx + prjXray may be used as toolchain to build bitstream for artix and zynq devices. This PR add support for this combo and introduce since Symbiflow and this new toolchain have a similar support for Xilinx's primitives it introduce `self.oss_toolchain` to avoid dupplicates same test. Tested with - arty A35t - arty A100t - arty z7 10 - arty z7 20"
https://api.github.com/repos/amaranth-lang/amaranth,679,-0.002739069052040577,0,"Now more in line with the documentation, which states that the process will wait ``phase`` seconds. Ref: https://github.com/amaranth-lang/amaranth/blob/c83b51db6daf3b73fb2406fdeecf6ef7486bb0be/amaranth/sim/core.py#L104-L106 This was not true so far. One had to give the clock phase wait time in ps."
https://api.github.com/repos/amaranth-lang/amaranth,678,0.00460455846041441,0,"Fix the strip_internal_attrs parameter to verilog.convert by passing it down the call stack as intended. Signed-off-by: Alyssa Rosenzweig <alyssa@rosenzweig.io>"
https://api.github.com/repos/amaranth-lang/amaranth,677,0.5315093994140625,1,"For me also latest Jinja2 version is working fine and strict requirement of old version is conflicting with other libs using nmigen, e.g. https://github.com/lambdaconcept/lambdasoc/blob/master/setup.py"
https://api.github.com/repos/amaranth-lang/amaranth,667,0.10626611113548279,0,"Avoiding emission of sync processes in RTLIL allows us to avoid a dependency on matching the behavior expected by Yosys, which generally expects sync processes in RTLIL to match those emitted by the output from it's own Verilog parser. This also simplifies the logic used in emitting RTLIL overall. Combinatorial processes are still emitted however. Without these the RTLIL does not have a high-level understanding of `Switch` statements, which significantly diminishes the quality of emitted Verilog, as these are converted to `$mux` cells in Yosys, which become `?` constructs when converted back to Verilog. Fixes #603."
https://api.github.com/repos/amaranth-lang/amaranth,664,0.13499048352241516,0,"Fixes #561."
https://api.github.com/repos/amaranth-lang/amaranth,662,-0.3422093391418457,0,"Fixes user local `pip install -e` This is a horrible hack and I hate it."
https://api.github.com/repos/amaranth-lang/amaranth,658,0.029118310660123825,0,"Fixes #630."
https://api.github.com/repos/amaranth-lang/amaranth,654,0.22295276820659637,0,"This adds initial documentation of the vendor platform modules."
https://api.github.com/repos/amaranth-lang/amaranth,653,-1.2039241790771484,-1,"None"
https://api.github.com/repos/amaranth-lang/amaranth,651,0.22012768685817719,0,"Actually represent time internally without using floating point numbers.  This is mostly important for after simulation API changes result in an API that allows user facing code to specify these parameters in exact units as well, however for now we don't wish to have a breaking change before this new API is defined.  This will make that change far more trivial and has already been tested. Fixes #535."
https://api.github.com/repos/amaranth-lang/amaranth,650,0.03159916773438454,0,"Fixes #605."
https://api.github.com/repos/amaranth-lang/amaranth,649,-0.44331422448158264,0,"Closes #606."
https://api.github.com/repos/amaranth-lang/amaranth,643,-1.2039241790771484,-1,"None"
https://api.github.com/repos/amaranth-lang/amaranth,634,0.08847106248140335,0,"Using sum(lst, []) to flatten a list of lists has quadratic time complexity. Use chain.from_iterable() instead. While not strictly necessary to improve performance, convert to map(). A test case writing out verilog for a 512k entry FIFO is 120x faster with this applied."
https://api.github.com/repos/amaranth-lang/amaranth,633,0.21657080948352814,0,"This patch was proposed by whitequark originally: https://freenode.irclog.whitequark.org/nmigen/2021-04-10#29646879 I came across an issue when instantiating a PLL inside a submodule. The generated clock constraint by nMigen would  have `/` characters in the string, which caused errors in ISE. Changing the character to `__` fixed the problem."
https://api.github.com/repos/amaranth-lang/amaranth,632,-0.09364939481019974,0,"The `test_toolchain_cxx.py` tests definitely use compiler and linker set with `_so_cxx`-suffixed parameters. After this change tests use a proper executable instead of `c++`."
https://api.github.com/repos/amaranth-lang/amaranth,626,-1.2039241790771484,-1,"None"
https://api.github.com/repos/amaranth-lang/amaranth,622,0.06727607548236847,0,"`tool_env_var(""g++"")` returns `""G++""`, which is not a valid environment variable name."
https://api.github.com/repos/amaranth-lang/amaranth,613,-0.5511960983276367,-1,"Split off from #612"
https://api.github.com/repos/amaranth-lang/amaranth,612,0.5287608504295349,1,"Opened the nmigen codebase with a language server for the first time and saw some unused imports :) Also found two small bugs while going through the files :) The commit messages should speak for themselves. If you want I can also split this into multiple PRs."
https://api.github.com/repos/amaranth-lang/amaranth,610,0.22756333649158478,0,"This patch generalizes the fixes to #500 to correctly raise `SyntaxError` instead of silently doing the wrong thing for the statements `Elif` inside `If`, `Else` inside `If`, `Elif` inside `Elif`, and `Else` inside `Else`. There are also new tests for these cases. Additionally there are new tests to verify the correct SyntaxError for `Case` inside `Case`, `State` outside of `FSM`, and `State` inside `State` (though their behavior was already correct and was not changed)."
https://api.github.com/repos/amaranth-lang/amaranth,609,-0.3829210102558136,0,"Closes #604, cc @cr1901."
https://api.github.com/repos/amaranth-lang/amaranth,593,0.4545760452747345,0,"The UART example code currently sets `rx_rdy` high when data has been received. I had assumed that setting `rx_ack` to high would clear this until data is ready again, but in the existing implementation `rx_rdy` only goes low when new data arrives. This small diff changes `rx_ack` to clear `rx_rdy` so that a user can acknowledge data after the first byte and then waits on `rx_rdy` for the next one. It also updates the simulation to verify that the right thing happens. I suppose this could've been designed with the intent that the user strobes out a signal when `rx_rdy` goes from low to high, but I'm not sure what the use of `rx_ack` is if this was the intended design. Sorry if I'm being oblivious, but if I am, feel free to close out this diff."
https://api.github.com/repos/amaranth-lang/amaranth,589,0.140254408121109,0,"This fixes some missing imports in the code introduced in commit 20f9ab9"
https://api.github.com/repos/amaranth-lang/amaranth,584,0.20080430805683136,0,"Prefix ""tools"" with symbiflow_ as is done for the QuickLogic Symbiflow toolchain. Installing symbiflow gives me the tools with the preifx, so I guess this is the correct way to move forward. I tested this by adding `toolchain=Symbiflow` to the constructor of basys3 (not upstreamed yet) and arty_a7 platform. ~There is a slight issue, but possibly with my symbiflow env where I see:~ ``` FileNotFoundError: [Errno 2] No such file or directory: '/home/nickoe/symbiflow_install/xc7/conda/envs/xc7/share/symbiflow/prjxray-db/xc7a35tcsg324-1/tilegrid.json' ``` ~There should be artix7 prefixed the chip name there. I assume this is an issue in the prjxray* or something. Possibly related to https://github.com/SymbiFlow/symbiflow-arch-defs/pull/1947.~ Maybe @mglb wants to have a quick look at this as he submitted the original support for symbiflow in https://github.com/nmigen/nmigen/pull/463 ?"
https://api.github.com/repos/amaranth-lang/amaranth,582,0.29491668939590454,0,"This fixes a logic bug introduced in 6ce2b21e196a0f93b82748ed046098331d20b3bf."
https://api.github.com/repos/amaranth-lang/amaranth,579,-0.04599059000611305,0,"nmigen/docs/_code/up_counter.py:44: DeprecationWarning: instead of nmigen.back.pysim.*, use nmigen.sim.*   from nmigen.back.pysim import Simulator"
https://api.github.com/repos/amaranth-lang/amaranth,578,0.3959463834762573,0,"My design has a SDR 16-bit bidirectional I/O, and currently nmigen emits a single OFS1P3DX instance for the OE signal, and its output is used for all 16 BB instances. nextpnr then complains:     ERROR: Failed to pack flipflop 'pin_adc_0__db.U$$32' with 'syn_useioff' set into IOLOGIC. The problem seems to be having one instance of OFS1P3DX, which yosys marks syn_useioff, but it can't be packed because it's needed in 16 places. This PR updates `lattice_ecp5.py` to generate n OFS1P3DX for the OE (well, T) signal instead, which nextpnr does then pack into IOLOGIC successfully. I've also tried this with DDR OE outputs which were also packed successfully, so I removed that comment too. Happy to hear if you'd rather make a wider OE signal and use the normal `get_oreg` with it instead, or anything like that."
https://api.github.com/repos/amaranth-lang/amaranth,577,0.23666147887706757,0,"Starting with nextpnr c6401413a, nextpnr does pack *FS1P3DX into IOLOGIC cells."
https://api.github.com/repos/amaranth-lang/amaranth,575,-0.19482050836086273,0,"This PR adds support for the internal high-speed oscillator on MachXO2/XO3L devices, called OSCH. Migen had support for the oscillator, but nMigen doesn't have it yet. It essentially replicates the changes that https://github.com/nmigen/nmigen/pull/530 made on Intel Cyclone V devices and https://github.com/nmigen/nmigen/pull/338 on the iCE40, with the difference that MachXO2/XO3 devices have a configurable frequency and a list of allowed freqs, as opposed to the Cyclone V which has a fixed frequency with a maximum of 100MHz, and the iCE40 which uses a fixed 48MHz oscillator and a divider. This PR is accompanied by (and would allow) PR https://github.com/nmigen/nmigen-boards/pull/136 in nmigen-boards, which changes the TinyFPGAAX2Platform to use the internal clock (at 2.08 MHz) by default, since the TinyFPGA AX2 has no external clock and thus no better default alternative for the clock signal."
https://api.github.com/repos/amaranth-lang/amaranth,571,0.18562419712543488,0,"This includes a number of fixes for `{r,w}_level` in AsyncFIFOBuffered. 1. The accounting for the output register used `AsyncFFSynchronizer` instead of `FFSynchronizer`. This is wrong as we want to synchronize both edges 2. Use the proper clock domains in the tests (not really a bug in the fifo logic obviously) 3. The FFSynchronizer should have a latency of 4 to match the latency of `consume_w_bin` / `w_level`. Two cycles for the `FFSynchronizer` from the read to the write domain of `consume_w_gry`, one for the `GrayDecoder` and one for the `w_level` calculation. 4. Fix the output register accounting. If the user asserts `r_en` even if `r_rdy` is low, we get `-1` in the intermediate calculation which overflows to `1` as we have a unsigned `Signal` Let me know if I should split this into multiple PRs or elaborate more on the fixes. The last two include additional testcases that fail without the fix. I did not include a testcase for the `AsyncFFSynchronizer` to `FFSynchronizer` change, as this is obviously wrong and would be hard to properly test without proper multi clock support in formal."
https://api.github.com/repos/amaranth-lang/amaranth,563,0.1832563430070877,0,"This merges existing code, and also adds support for: - Virtex, Virtex E (also known as Spartan 2, Spartan 2E) - Virtex 2, Virtex 2 Pro - Spartan 3, Spartan 3E (in addition to existing Spartan 3A, Spartan 3A   DSP support) - Virtex 4 - Virtex 5 - Virtex 6 - ISE synthesis for Series 7 Fixes #552."
https://api.github.com/repos/amaranth-lang/amaranth,545,-0.06559628248214722,0,"Record lost shape() in the migration to ValueCastable. This PR restores it."
https://api.github.com/repos/amaranth-lang/amaranth,544,0.20326541364192963,0,"Otherwise it behaves funny when it's eg. the result of operator ~."
https://api.github.com/repos/amaranth-lang/amaranth,543,-0.48343196511268616,0,"Related PR: https://github.com/nmigen/nmigen-boards/pull/117 Signed-off-by: Jan Kowalewski <jkowalewski@antmicro.com>"
https://api.github.com/repos/amaranth-lang/amaranth,541,0.20505231618881226,0,"Proxy Operator calls on Record through to Value implementation, using explicit enumeration to avoid depending on future changes to Value. Fixes #533 ."
https://api.github.com/repos/amaranth-lang/amaranth,530,0.2790302038192749,0,"When using the default clock ""cyclonev_oscillator"" on Cyclone V devices, the internal oscillator will be used."
https://api.github.com/repos/amaranth-lang/amaranth,529,0.37970882654190063,0,"This PR migrates Record from being based on UserValue to being based on ValueCastable, clearing the way to deprecate UserValue. Would close #528 ."
https://api.github.com/repos/amaranth-lang/amaranth,524,-0.10300329327583313,0,"This is the split out stuff from #512 that affects AsyncFIFO and not AsyncFIFOBuffered"
https://api.github.com/repos/amaranth-lang/amaranth,523,0.29480186104774475,0,"The Zynq driver in the FPGA Manager framework on Linux expects bitstreams that are byte swapped with respect to what the Vivado command `write_bitstream -bin_file` produces. Thus, use the `write_cfgmem` command with appropriate options to generate the bitstream (.bin file). Fixes #519."
https://api.github.com/repos/amaranth-lang/amaranth,521,0.06412385404109955,0,"Fixes #520"
https://api.github.com/repos/amaranth-lang/amaranth,518,-0.19890658557415009,0,"The PR introduces two general changes: * Fixing the nomenclature of the toolchain according to the latest SymbiFlow QuickLogic toolchain package * Adding a possibility to utilize internal SoC clock Related PR: https://github.com/nmigen/nmigen-boards/pull/117"
https://api.github.com/repos/amaranth-lang/amaranth,517,0.1127861738204956,0,"wasted more time than I would like to admit due to this :)"
https://api.github.com/repos/amaranth-lang/amaranth,516,0.4895799458026886,0,"I'm working on setting up a Nix shell environment, which builds nmigen from a checkout that does not contain a full .git directory. In the this scenario, setuptools_scm is installed correctly, but `parse`/`parse_git` returns `None` because there's no active git checkout. As a fix, I check to see if `git` is falsey and, if so, return a blank version string.  I've verified that this installs properly from nix via `fetchFromGithub`"
https://api.github.com/repos/amaranth-lang/amaranth,513,0.04373534768819809,0,"This is the split out commit with testcase as requested for #512 in IRC"
https://api.github.com/repos/amaranth-lang/amaranth,512,0.10169801861047745,0,"This Fixes #485 as per discussion in https://freenode.irclog.whitequark.org/glasgow/2020-10-22#1603367304-1603369561"
https://api.github.com/repos/amaranth-lang/amaranth,511,0.3940950930118561,0,"This PR improves the internal version of FHDLTestCase by trying to get the last stack frame that is still inside the nmigen codebase when creating names for the spec file. This helps to make the FIFO test cases produce all distinct spec directories and makes the nmigen test suite thread-safe (can be run successfully with pytest-xdist)  "
https://api.github.com/repos/amaranth-lang/amaranth,509,0.4329787492752075,0,"67b957d moved the tests from `nmigen/test/` to `tests/`, and removed the `exclude=` parameter from `find_packages()` in setup.py. However, even if the new location is not inside the module tree, it is still found by `find_packages()`, resulting in a stray ""tests"" module on the system."
https://api.github.com/repos/amaranth-lang/amaranth,508,-0.37452200055122375,0,"Signed-off-by: Jan Kowalewski <jkowalewski@antmicro.com>"
https://api.github.com/repos/amaranth-lang/amaranth,506,0.001044335775077343,0,"48d4ee4 added the option to specify attributes using Instance arguments, but the error message wasn't updated accordingly."
https://api.github.com/repos/amaranth-lang/amaranth,504,0.2892444133758545,0,"This PR introduces a support for QuickLogic EOS-S3 platform."
https://api.github.com/repos/amaranth-lang/amaranth,499,-0.008083646185696125,0,"Fixes #496."
https://api.github.com/repos/amaranth-lang/amaranth,493,0.09949114918708801,0,"Diamond does not provide ""`diamond_env.bat`"" on Windows. It is up to the user to create their own and point `NMIGEN_ENV_Diamond` to the correct location. I've added an example (with the default install directory `lscc`) of a working script to the documentation."
https://api.github.com/repos/amaranth-lang/amaranth,490,-0.1791924685239792,0,"Fixes #438 (again)."
